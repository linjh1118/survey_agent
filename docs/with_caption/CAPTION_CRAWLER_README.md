# arXiv Caption Crawler ä½¿ç”¨æŒ‡å—

## ğŸ“‹ åŠŸèƒ½æ¦‚è¿°

æ­¤åŠŸèƒ½æ‰©å±•äº† survey_agentï¼Œå¢åŠ äº†ä»¥ä¸‹èƒ½åŠ›ï¼š
1. **çˆ¬å– arXiv HTML è®ºæ–‡**ï¼šæå–æ ‡é¢˜ã€æ‘˜è¦ã€å›¾ç‰‡å’Œå¯¹åº”çš„ Caption
2. **æ‰¹é‡å¤„ç†**ï¼šè‡ªåŠ¨å¤„ç† survey_result.md ä¸­çš„æ‰€æœ‰è®ºæ–‡
3. **ç”Ÿæˆå¯è§†åŒ– HTML**ï¼šå°† LLM æ€»ç»“ä¸å›¾ç‰‡ Caption æ•´åˆå±•ç¤º

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šä¸€é”®å®Œæ•´æµç¨‹

```bash
# 1. å…ˆè¿è¡Œ survey agent ç”Ÿæˆè°ƒæŸ¥æŠ¥å‘Š
./launch.sh

# 2. è¿è¡Œ caption crawlerï¼ˆè‡ªåŠ¨çˆ¬å–å›¾ç‰‡å¹¶ç”ŸæˆHTMLï¼‰
./launch_with_caption.sh
```

### æ–¹å¼äºŒï¼šå•ç‹¬çˆ¬å–ç‰¹å®šè®ºæ–‡

```python
python3 -c "
import sys
sys.path.insert(0, 'src')
from survey_agent.arxiv_tools import crawl_arxiv_html

# çˆ¬å–å•ç¯‡è®ºæ–‡
crawl_arxiv_html('https://arxiv.org/html/2512.16149', 'outputs')
"
```

### æ–¹å¼ä¸‰ï¼šæ‰‹åŠ¨æ‰¹é‡çˆ¬å–

```python
python3 -c "
import sys
sys.path.insert(0, 'src')
from survey_agent.arxiv_tools import batch_crawl_arxiv_ids

# çˆ¬å–å¤šç¯‡è®ºæ–‡
arxiv_ids = ['2512.16149', '2512.03794', '2511.15370']
batch_crawl_arxiv_ids(arxiv_ids, 'outputs')
"
```

## ğŸ“ è¾“å‡ºç»“æ„

è¿è¡Œ `./launch_with_caption.sh` åä¼šç”Ÿæˆï¼š

```
survey_agent/
â”œâ”€â”€ paper_captions/              # çˆ¬å–çš„è®ºæ–‡æ•°æ®
â”‚   â”œâ”€â”€ {Title}_{ID}/
â”‚   â”‚   â”œâ”€â”€ crawled_data.json   # å…ƒæ•°æ®
â”‚   â”‚   â””â”€â”€ images/              # ä¸‹è½½çš„å›¾ç‰‡
â”‚   â”‚       â”œâ”€â”€ figure_1.png
â”‚   â”‚       â”œâ”€â”€ figure_2.png
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ paper_captions.html          # å¯è§†åŒ– HTML æ–‡ä»¶
â””â”€â”€ survey_result_xxx.md         # LLM ç”Ÿæˆçš„è°ƒæŸ¥æŠ¥å‘Š
```

## ğŸ¨ HTML åŠŸèƒ½ç‰¹æ€§

ç”Ÿæˆçš„ `paper_captions.html` åŒ…å«ï¼š

### 1. LLM æ€»ç»“å±•ç¤ºï¼ˆå¯æŠ˜å å¡ç‰‡ï¼‰
- ğŸ“Œ **èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº** - é»˜è®¤å±•å¼€
- ğŸš€ **æ ¸å¿ƒæ–¹æ³•** - é»˜è®¤å±•å¼€
- ğŸ“ˆ **å®éªŒç»“æœ** - é»˜è®¤æŠ˜å 
- ğŸ’¬ **å¯å€Ÿé‰´ä¹‹å¤„** - é»˜è®¤æŠ˜å 

### 2. å›¾ç‰‡å’Œ Caption å±•ç¤º
- ç½‘æ ¼å¸ƒå±€å±•ç¤ºæ‰€æœ‰å›¾ç‰‡
- æ¯ä¸ªå›¾ç‰‡åŒ…å« Figure ID å’Œå¯¹åº”çš„ Caption
- é»˜è®¤æŠ˜å ï¼Œç‚¹å‡»å±•å¼€æŸ¥çœ‹

### 3. è§†è§‰è®¾è®¡
- ç´«è‰²æ¸å˜èƒŒæ™¯
- å“åº”å¼å¸ƒå±€ï¼ˆæ¡Œé¢/ç§»åŠ¨é€‚é…ï¼‰
- å¹³æ»‘åŠ¨ç”»æ•ˆæœ
- å½©è‰²è¾¹æ¡†å¡ç‰‡ï¼ˆæ©™ã€è“ã€ç»¿ã€ç´«ï¼‰

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### æ–°å¢æ¨¡å—

#### 1. `caption_crawler.py`
çˆ¬å– arXiv HTML è®ºæ–‡çš„æ ¸å¿ƒæ¨¡å—

**ä¸»è¦å‡½æ•°**ï¼š
- `crawl_arxiv_html(url, output_dir)` - çˆ¬å–å•ç¯‡è®ºæ–‡
- `batch_crawl_arxiv_ids(arxiv_ids, output_dir)` - æ‰¹é‡çˆ¬å–
- `clean_filename(text)` - æ¸…ç†æ–‡ä»¶å
- `get_paper_title(soup)` - æå–è®ºæ–‡æ ‡é¢˜

**ç‰¹æ€§**ï¼š
- è‡ªåŠ¨ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°
- æå–å›¾ç‰‡å¯¹åº”çš„ Caption
- æ™ºèƒ½ç›®å½•å‘½åï¼ˆæ ‡é¢˜ + IDï¼‰
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

#### 2. `html_generator.py`
ç”Ÿæˆå¯è§†åŒ– HTML çš„æ¨¡å—

**ä¸»è¦å‡½æ•°**ï¼š
- `generate_html_with_summary(papers, summaries, output_path)` - ç”Ÿæˆ HTML
- `parse_markdown_summaries(md_path)` - è§£æ survey_result.md
- `find_all_papers(outputs_dir)` - æŸ¥æ‰¾çˆ¬å–çš„è®ºæ–‡æ•°æ®
- `parse_summary_sections(summary)` - è§£ææ€»ç»“ä¸ºå››ä¸ªå°èŠ‚
- `encode_image_to_base64(image_path)` - å›¾ç‰‡è½¬ base64

**ç‰¹æ€§**ï¼š
- æ‰€æœ‰å›¾ç‰‡ä»¥ base64 åµŒå…¥ï¼Œå•æ–‡ä»¶åˆ†å‘
- å¯æŠ˜å çš„å¡ç‰‡å¼å¸ƒå±€
- è‡ªåŠ¨åŒ¹é… arXiv ID å’Œæ€»ç»“å†…å®¹
- ç¦»çº¿å¯ç”¨ï¼Œæ— éœ€ç½‘ç»œ

### ä¾èµ–è¦æ±‚

```bash
# Python åŒ…
pip install requests beautifulsoup4

# æˆ–ä½¿ç”¨é¡¹ç›® requirements.txt
pip install -r requirements.txt
```

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šå®Œæ•´æµç¨‹

```bash
# 1. è¿è¡Œ survey agent
./launch.sh
# ï¼ˆåœ¨ç•Œé¢ä¸­è¾“å…¥æœç´¢å…³é”®è¯ï¼Œç­‰å¾…ç”Ÿæˆ survey_result.mdï¼‰

# 2. çˆ¬å–å›¾ç‰‡å¹¶ç”Ÿæˆ HTML
./launch_with_caption.sh

# 3. æŸ¥çœ‹ç»“æœ
open paper_captions.html
```

### ç¤ºä¾‹ 2ï¼šåªçˆ¬å–å›¾ç‰‡ï¼ˆä¸ç”Ÿæˆ HTMLï¼‰

```bash
# æå– arXiv IDs
grep -oP 'arxiv\.org/pdf/\K[0-9]{4}\.[0-9]{5}' survey_result_xxx.md | sort -u > ids.txt

# æ‰¹é‡çˆ¬å–
python3 -c "
import sys
sys.path.insert(0, 'src')
from survey_agent.arxiv_tools import batch_crawl_arxiv_ids

with open('ids.txt') as f:
    ids = [line.strip() for line in f]

batch_crawl_arxiv_ids(ids, 'outputs')
"
```

### ç¤ºä¾‹ 3ï¼šåªç”Ÿæˆ HTMLï¼ˆå·²æœ‰çˆ¬å–æ•°æ®ï¼‰

```bash
python3 -c "
import sys
sys.path.insert(0, 'src')
from survey_agent.arxiv_tools import (
    parse_markdown_summaries,
    find_all_papers,
    generate_html_with_summary
)

summaries = parse_markdown_summaries('survey_result_xxx.md')
papers = find_all_papers('outputs')
generate_html_with_summary(papers, summaries, 'output.html')
"
```

## ğŸ¯ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆæœ‰äº›è®ºæ–‡æ²¡æœ‰å›¾ç‰‡ï¼Ÿ
A: å¹¶éæ‰€æœ‰ arXiv è®ºæ–‡éƒ½æä¾› HTML ç‰ˆæœ¬ï¼Œæˆ–è€… HTML ç‰ˆæœ¬ä¸­æ²¡æœ‰å›¾ç‰‡ã€‚è¿™æ˜¯æ­£å¸¸ç°è±¡ã€‚

### Q2: çˆ¬å–å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
A: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–è€…å•ç‹¬é‡æ–°çˆ¬å–å¤±è´¥çš„è®ºæ–‡ï¼š
```bash
python3 src/survey_agent/arxiv_tools/caption_crawler.py <arxiv_id>
```

### Q3: HTML æ–‡ä»¶å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ
A: ç”Ÿæˆçš„ HTML åŒ…å« base64 ç¼–ç çš„å›¾ç‰‡ï¼Œæ–‡ä»¶è¾ƒå¤§ï¼ˆå‡ ç™¾ MBï¼‰æ˜¯æ­£å¸¸çš„ã€‚å¯ä»¥å‹ç¼©ï¼š
```bash
gzip -9 paper_captions.html
# å‹ç¼©åçº¦ 30-50 MB
```

### Q4: å¦‚ä½•è‡ªå®šä¹‰è¾“å‡ºç›®å½•ï¼Ÿ
A: ä¿®æ”¹ `launch_with_caption.sh` ä¸­çš„å˜é‡ï¼š
```bash
OUTPUT_DIR="my_custom_dir"
HTML_FILE="my_output.html"
```

### Q5: èƒ½å¦åªçˆ¬å–ç‰¹å®šè®ºæ–‡çš„å›¾ç‰‡ï¼Ÿ
A: å¯ä»¥ï¼Œåˆ›å»ºä¸€ä¸ªåŒ…å« arXiv ID çš„æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨ Python APIï¼š
```python
from survey_agent.arxiv_tools import batch_crawl_arxiv_ids

ids = ['2512.16149', '2511.15370']  # æ‚¨æ„Ÿå…´è¶£çš„è®ºæ–‡
batch_crawl_arxiv_ids(ids, 'outputs')
```

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-12-26)
- âœ… åˆå§‹ç‰ˆæœ¬
- âœ… æ”¯æŒ arXiv HTML è®ºæ–‡çˆ¬å–
- âœ… æ‰¹é‡å¤„ç†åŠŸèƒ½
- âœ… ç”Ÿæˆå¯æŠ˜å å¡ç‰‡å¼ HTML
- âœ… Base64 å›¾ç‰‡åµŒå…¥
- âœ… å“åº”å¼è®¾è®¡

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ License

éµå¾ª survey_agent ä¸»é¡¹ç›®çš„ License

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰
