#!/usr/bin/env python3
"""
ä»å®é™…ç¼“å­˜æ•°æ®ç”ŸæˆGitHub Pagesæ¼”ç¤ºæ•°æ®
"""

import json
import os
from datetime import datetime
from collections import OrderedDict

def load_actual_cache():
    """åŠ è½½å®é™…çš„ç¼“å­˜æ•°æ®"""
    cache_file = "cache/paper_summaries.json"
    if os.path.exists(cache_file):
        with open(cache_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def truncate_summary(summary, max_length=500):
    """æˆªæ–­æ‘˜è¦åˆ°æŒ‡å®šé•¿åº¦ï¼Œä¿æŒæ ¼å¼"""
    if len(summary) <= max_length:
        return summary
    
    # å°è¯•åœ¨å¥å·å¤„æˆªæ–­
    truncated = summary[:max_length]
    last_period = truncated.rfind('ã€‚')
    last_newline = truncated.rfind('\n')
    
    # ä¼˜å…ˆåœ¨å¥å·å¤„æˆªæ–­ï¼Œå…¶æ¬¡åœ¨æ¢è¡Œå¤„
    if last_period > max_length * 0.7:
        truncated = summary[:last_period + 1]
    elif last_newline > max_length * 0.7:
        truncated = summary[:last_newline]
    
    return truncated + "..."

def filter_papers_for_demo(papers_data, max_count=20):
    """ç­›é€‰ç”¨äºæ¼”ç¤ºçš„è®ºæ–‡"""
    # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰ç¼“å­˜æ—¶é—´æ’åº
    papers_list = []
    for arxiv_id, paper_info in papers_data.items():
        paper_info['arxiv_id'] = arxiv_id
        papers_list.append(paper_info)
    
    # æŒ‰ç¼“å­˜æ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
    papers_list.sort(key=lambda x: x.get('cached_at', ''), reverse=True)
    
    # åªå–å‰max_countç¯‡
    selected_papers = papers_list[:max_count]
    
    # è½¬å›å­—å…¸æ ¼å¼ï¼Œå¹¶å¤„ç†æ‘˜è¦
    demo_data = OrderedDict()
    for paper in selected_papers:
        arxiv_id = paper['arxiv_id']
        # ç§»é™¤é‡å¤çš„arxiv_idå­—æ®µ
        paper_copy = paper.copy()
        if 'arxiv_id' in paper_copy:
            del paper_copy['arxiv_id']
        
        # æˆªæ–­æ‘˜è¦ä»¥å‡å°‘æ–‡ä»¶å¤§å°
        if 'summary' in paper_copy:
            paper_copy['summary'] = truncate_summary(paper_copy['summary'])
        
        demo_data[arxiv_id] = paper_copy
    
    return demo_data

def generate_demo_cache():
    """ç”Ÿæˆæ¼”ç¤ºç¼“å­˜æ–‡ä»¶"""
    print("æ­£åœ¨åŠ è½½å®é™…ç¼“å­˜æ•°æ®...")
    actual_cache = load_actual_cache()
    
    if not actual_cache:
        print("æœªæ‰¾åˆ°å®é™…ç¼“å­˜æ•°æ®ï¼Œå°†åˆ›å»ºæœ€å°æ¼”ç¤ºæ•°æ®...")
        # åˆ›å»ºæœ€å°çš„æ¼”ç¤ºæ•°æ®
        demo_data = {
            "2506.19767": {
                "title": "SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning",
                "summary": "## ğŸŒŸ è®ºæ–‡è§£è¯» | SRFTï¼šå¤§è¯­è¨€æ¨¡å‹æ¨ç†å¾®è°ƒçš„åˆ›æ–°å•é˜¶æ®µæ–¹æ³•\n\n### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº\nå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æœ€ä½³æ•´åˆä»æ˜¯ä¸€ä¸ªæ ¹æœ¬æ€§æŒ‘æˆ˜...\n\n### ğŸš€ æ ¸å¿ƒæ–¹æ³•\nğŸ’¡ æå‡ºå•é˜¶æ®µå¾®è°ƒæ–¹æ³•SRFTï¼Œå°†SFTæ•´åˆåˆ°RLä¸­ï¼Œä½¿ç”¨ç†µä½œä¸ºæŒ‡æ ‡æ¥æ§åˆ¶ä¸¤ç§èŒƒå¼ä¹‹é—´çš„å¹³è¡¡ã€‚",
                "content_hash": "c22b21b0970fe44a31634b46a37e2608",
                "cached_at": datetime.now().isoformat(),
                "model_info": {
                    "provider": "doubao",
                    "model_name": "ep-20250529110941-khvtx"
                }
            }
        }
    else:
        print(f"æ‰¾åˆ° {len(actual_cache)} ç¯‡ç¼“å­˜è®ºæ–‡ï¼Œæ­£åœ¨ç”Ÿæˆæ¼”ç¤ºæ•°æ®...")
        demo_data = filter_papers_for_demo(actual_cache)
        print(f"é€‰æ‹©äº† {len(demo_data)} ç¯‡è®ºæ–‡ç”¨äºæ¼”ç¤º")
    
    # å†™å…¥æ¼”ç¤ºæ–‡ä»¶
    demo_file = "cache/demo_papers.json"
    with open(demo_file, 'w', encoding='utf-8') as f:
        json.dump(demo_data, f, ensure_ascii=False, indent=2)
    
    print(f"æ¼”ç¤ºæ•°æ®å·²ä¿å­˜åˆ° {demo_file}")
    print(f"åŒ…å« {len(demo_data)} ç¯‡è®ºæ–‡")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if demo_data:
        print("\nè®ºæ–‡ç»Ÿè®¡:")
        titles = [paper.get('title', 'Unknown') for paper in demo_data.values()]
        for i, title in enumerate(titles[:5], 1):
            print(f"  {i}. {title[:60]}{'...' if len(title) > 60 else ''}")
        if len(titles) > 5:
            print(f"  ... è¿˜æœ‰ {len(titles) - 5} ç¯‡è®ºæ–‡")

def generate_summary_reports():
    """ç”Ÿæˆè°ƒç ”æŠ¥å‘Šåˆ—è¡¨æ¼”ç¤ºæ•°æ®"""
    output_dir = "output"
    if not os.path.exists(output_dir):
        print(f"è¾“å‡ºç›®å½• {output_dir} ä¸å­˜åœ¨")
        return
    
    reports = []
    for filename in os.listdir(output_dir):
        if filename.endswith('.md'):
            filepath = os.path.join(output_dir, filename)
            try:
                stat = os.stat(filepath)
                
                # è¯»å–æ–‡ä»¶å‰å‡ è¡Œè·å–æ ‡é¢˜
                title = filename.replace('.md', '')
                with open(filepath, 'r', encoding='utf-8') as f:
                    first_line = f.readline().strip()
                    if first_line.startswith('#'):
                        title = first_line.lstrip('# ')
                
                reports.append({
                    "filename": filename,
                    "title": title[:100],  # é™åˆ¶æ ‡é¢˜é•¿åº¦
                    "created_at": datetime.fromtimestamp(stat.st_ctime).isoformat(),
                    "modified_at": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    "size": stat.st_size
                })
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
                continue
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    reports.sort(key=lambda x: x['modified_at'], reverse=True)
    
    # ä¿å­˜æ¼”ç¤ºæŠ¥å‘Šæ•°æ®
    demo_reports_file = "cache/demo_reports.json"
    with open(demo_reports_file, 'w', encoding='utf-8') as f:
        json.dump(reports[:15], f, ensure_ascii=False, indent=2)  # åªä¿ç•™å‰15ä¸ªæŠ¥å‘Š
    
    print(f"\nè°ƒç ”æŠ¥å‘Šæ•°æ®å·²ä¿å­˜åˆ° {demo_reports_file}")
    print(f"åŒ…å« {len(reports[:15])} ä¸ªæŠ¥å‘Š")

if __name__ == "__main__":
    print("=== Survey Agent æ¼”ç¤ºæ•°æ®ç”Ÿæˆå™¨ ===")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("cache", exist_ok=True)
    
    # ç”Ÿæˆè®ºæ–‡ç¼“å­˜æ¼”ç¤ºæ•°æ®
    generate_demo_cache()
    
    # ç”Ÿæˆè°ƒç ”æŠ¥å‘Šæ¼”ç¤ºæ•°æ®
    generate_summary_reports()
    
    print("\nâœ… æ¼”ç¤ºæ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("1. æ¨é€ä»£ç åˆ°GitHubä»“åº“")
    print("2. å¯ç”¨GitHub Pages (Settings â†’ Pages â†’ GitHub Actions)")
    print("3. è®¿é—® https://your-username.github.io/survey_agent")