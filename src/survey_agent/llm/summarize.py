import os
import json
from typing import Dict, Any, List, Optional, Union

class LLMSummarizer:
    """
    Base class for LLM-based paper summarization.
    Subclass this to implement specific LLM integrations.
    """
    
    def __init__(self, model_name: str = None):
        """
        Initialize the summarizer.
        
        Args:
            model_name: Name of the LLM model to use
        """
        self.model_name = model_name or os.environ.get("SURVEY_AGENT_LLM_MODEL", "gpt-4")
    
    def get_summary_prompt(self, paper: Dict[str, Any]) -> str:
        """
        Generate the prompt for paper summarization.
        
        Args:
            paper: Paper information dictionary
            
        Returns:
            Prompt string for the LLM
        """
        # Default prompt template
        prompt = f"""### ä»»åŠ¡
ä½ æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸“å®¶ï¼Œä½ èƒ½å¤Ÿå¿«é€Ÿé˜…è¯»arxivä¸Šçš„å„ç§AIå‰æ²¿è®ºæ–‡ï¼Œå¹¶ç»™å‡ºéå¸¸å¥½çš„è®ºæ–‡æ€»ç»“ã€‚
ç°åœ¨è¯·ä½ é˜…è¯»ä»¥ä¸‹è®ºæ–‡ï¼Œå¹¶ç»™å‡ºä½ å¯¹è¿™ç¯‡è®ºæ–‡çš„è¯¦ç»†ä»‹ç»ï¼Œä»è€Œæ”¾åˆ°ä½ çš„åšå®¢ä¸Šï¼Œè®©æ›´å¤šäººäº†è§£è¿™ç¯‡è®ºæ–‡ã€‚

### è®ºæ–‡ä¿¡æ¯
###  1. è®ºæ–‡æ ‡é¢˜
```
{paper['title']}
```
#### 2. è®ºæ–‡æ‘˜è¦
```
{paper['summary']}
```

#### 3. è®ºæ–‡å…¨æ–‡
```
{paper['pdf_text'][:10000]}  # Truncate if too long
```

è¯·è¾“å‡ºè®ºæ–‡æ€»ç»“
### è¾“å‡ºæ ¼å¼ï¼ˆè¾“å‡ºè¯­è¨€ç”¨ä¸­æ–‡ï¼‰
```
## ğŸŒŸ è®ºæ–‡è§£è¯» | <æƒ³ä¸€ä¸ªï¼Œå®£ä¼ è¯¥è®ºæ–‡çš„æ–‡æ¡ˆæ ‡é¢˜>

## ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
...(ä»‹ç»è®ºæ–‡çš„èƒŒæ™¯æˆ–ç—›ç‚¹ï¼Œæˆ–è€…æœ¬æ–‡çš„åŠ¨æœº)

## ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1
...

ğŸ’¡ åˆ›æ–°ç‚¹2
...

## ğŸ“ˆ å®éªŒç»“æœ
...

## ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
...(ä»‹ç»è®ºæ–‡çš„å¯å€Ÿé‰´ä¹‹å¤„)
```
"""
        return prompt
    
    def summarize(self, paper: Dict[str, Any]) -> str:
        """
        Generate a summary for a paper using an LLM.
        This is a placeholder that should be implemented by subclasses.
        
        Args:
            paper: Paper information dictionary
            
        Returns:
            Summary string
        """
        raise NotImplementedError("Subclasses must implement this method")

class OpenAISummarizer(LLMSummarizer):
    """
    OpenAI-based paper summarizer.
    """
    
    def __init__(self, model_name: str = None, api_key: str = None, base_url: str = None):
        """
        Initialize the OpenAI summarizer.
        
        Args:
            model_name: Name of the OpenAI model to use
            api_key: OpenAI API key
        """
        super().__init__(model_name)
        self.api_key = api_key or os.environ.get("API_KEY")
        self.base_url = base_url or os.environ.get("BASE_URL")
        
        if not self.api_key:
            raise ValueError("OpenAI API key not provided")
        
        try:
            import openai
            self.client = openai.OpenAI(api_key=self.api_key, base_url=self.base_url)
        except Exception as e:
            # æ ¹æ®å†…å®¹ï¼Œè‡ªå·±è¿”å›
            raise e
    
    def summarize(self, paper: Dict[str, Any]) -> str:
        """
        Generate a summary for a paper using OpenAI.
        
        Args:
            paper: Paper information dictionary
            
        Returns:
            Summary string
        """
        prompt = self.get_summary_prompt(paper)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant that summarizes research papers."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error generating summary: {e}")
            return ""

# Factory function to get the appropriate summarizer
def get_summarizer(provider: str = "openai", model_name: str = None) -> LLMSummarizer:
    """
    Get a summarizer instance based on the provider.
    
    Args:
        provider: LLM provider (e.g., "openai", "anthropic")
        model_name: Name of the model to use
        
    Returns:
        LLMSummarizer instance
    """
    if provider.lower() == "openai":
        return OpenAISummarizer(model_name)
    else:
        raise ValueError(f"Unsupported provider: {provider}") 