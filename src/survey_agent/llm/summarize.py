import os
import json
from typing import Dict, Any, List, Optional, Union

class LLMSummarizer:
    """
    Base class for LLM-based paper summarization.
    Subclass this to implement specific LLM integrations.
    """
    
    def __init__(self, model_name: str = None, custom_prompt: str = None):
        """
        Initialize the summarizer.
        
        Args:
            model_name: Name of the LLM model to use
            custom_prompt: Custom prompt template for summarization
        """
        self.model_name = model_name or os.environ.get("SURVEY_AGENT_LLM_MODEL", "gpt-4")
        self.custom_prompt = custom_prompt
    
    def get_default_summary_prompt(self, paper: Dict[str, Any]) -> str:
        """
        Generate the default prompt for paper summarization.
        
        Args:
            paper: Paper information dictionary
            
        Returns:
            Default prompt string for the LLM
        """
        # Default prompt template
        prompt = f"""### ä»»åŠ¡
ä½ æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸“å®¶ï¼Œä½ èƒ½å¤Ÿå¿«é€Ÿé˜…è¯»arxivä¸Šçš„å„ç§AIå‰æ²¿è®ºæ–‡ï¼Œå¹¶ç»™å‡ºéå¸¸å¥½çš„è®ºæ–‡æ€»ç»“ã€‚
ç°åœ¨è¯·ä½ é˜…è¯»ä»¥ä¸‹è®ºæ–‡ï¼Œå¹¶ç»™å‡ºä½ å¯¹è¿™ç¯‡è®ºæ–‡çš„è¯¦ç»†ä»‹ç»ï¼Œä»è€Œæ”¾åˆ°ä½ çš„åšå®¢ä¸Šï¼Œè®©æ›´å¤šäººäº†è§£è¿™ç¯‡è®ºæ–‡ã€‚

### è®ºæ–‡ä¿¡æ¯
###  1. è®ºæ–‡æ ‡é¢˜
```
{paper['title']}
```
#### 2. è®ºæ–‡æ‘˜è¦
```
{paper['summary']}
```

#### 3. è®ºæ–‡å…¨æ–‡
```
{paper.get('pdf_text', '')[:10000]}  # Truncate if too long
```

è¯·è¾“å‡ºè®ºæ–‡æ€»ç»“
### è¾“å‡ºæ ¼å¼ï¼ˆè¾“å‡ºè¯­è¨€ç”¨ä¸­æ–‡ï¼‰
```
## ğŸŒŸ è®ºæ–‡è§£è¯» | <æƒ³ä¸€ä¸ªï¼Œå®£ä¼ è¯¥è®ºæ–‡çš„æ–‡æ¡ˆæ ‡é¢˜>

## ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
...(ä»‹ç»è®ºæ–‡çš„èƒŒæ™¯æˆ–ç—›ç‚¹ï¼Œæˆ–è€…æœ¬æ–‡çš„åŠ¨æœº)

## ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1
...

ğŸ’¡ åˆ›æ–°ç‚¹2
...

## ğŸ“ˆ å®éªŒç»“æœ
...

## ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
...(ä»‹ç»è®ºæ–‡çš„å¯å€Ÿé‰´ä¹‹å¤„)
```
"""
        return prompt
    
    def get_summary_prompt(self, paper: Dict[str, Any]) -> str:
        """
        Generate the prompt for paper summarization.
        Uses custom prompt if provided, otherwise uses default.
        
        Args:
            paper: Paper information dictionary
            
        Returns:
            Prompt string for the LLM
        """
        if self.custom_prompt:
            # Replace placeholders in custom prompt with paper information
            return self._format_custom_prompt(self.custom_prompt, paper)
        else:
            return self.get_default_summary_prompt(paper)
    
    def _format_custom_prompt(self, prompt_template: str, paper: Dict[str, Any]) -> str:
        """
        Format custom prompt template with paper information.
        
        Args:
            prompt_template: Custom prompt template with placeholders
            paper: Paper information dictionary
            
        Returns:
            Formatted prompt string
        """
        # Available placeholders for custom prompts
        placeholders = {
            '{title}': paper.get('title', ''),
            '{abstract}': paper.get('summary', ''),
            '{authors}': paper.get('authors', ''),
            '{year}': paper.get('year', ''),
            '{url}': paper.get('url', ''),
            '{pdf_text}': paper.get('pdf_text', '')[:10000],  # Truncate if too long
            '{full_pdf_text}': paper.get('pdf_text', ''),
            '{doi}': paper.get('doi', ''),
            '{arxiv_id}': paper.get('arxiv_id', '')
        }
        
        # Replace all placeholders in the template
        formatted_prompt = prompt_template
        for placeholder, value in placeholders.items():
            formatted_prompt = formatted_prompt.replace(placeholder, str(value))
        
        return formatted_prompt
    
    def set_custom_prompt(self, custom_prompt: str):
        """
        Set a custom prompt template for summarization.
        
        Args:
            custom_prompt: Custom prompt template with placeholders like {title}, {abstract}, etc.
        """
        self.custom_prompt = custom_prompt
    
    def get_available_placeholders(self) -> List[str]:
        """
        Get list of available placeholders for custom prompts.
        
        Returns:
            List of placeholder strings
        """
        return [
            '{title}',
            '{abstract}', 
            '{authors}',
            '{year}',
            '{url}',
            '{pdf_text}',
            '{full_pdf_text}',
            '{doi}',
            '{arxiv_id}'
        ]
    
    def summarize(self, paper: Dict[str, Any]) -> str:
        """
        Generate a summary for a paper using an LLM.
        This is a placeholder that should be implemented by subclasses.
        
        Args:
            paper: Paper information dictionary
            
        Returns:
            Summary string
        """
        raise NotImplementedError("Subclasses must implement this method")

class OpenAISummarizer(LLMSummarizer):
    """
    OpenAI-based paper summarizer.
    """
    
    def __init__(self, model_name: str = None, api_key: str = None, base_url: str = None, custom_prompt: str = None):
        """
        Initialize the OpenAI summarizer.
        
        Args:
            model_name: Name of the OpenAI model to use
            api_key: OpenAI API key
            base_url: OpenAI API base URL
            custom_prompt: Custom prompt template for summarization
        """
        super().__init__(model_name, custom_prompt)
        self.api_key = api_key or os.environ.get("API_KEY")
        self.base_url = base_url or os.environ.get("BASE_URL")
        
        if not self.api_key:
            raise ValueError("OpenAI API key not provided")
        
        try:
            import openai
            self.client = openai.OpenAI(api_key=self.api_key, base_url=self.base_url)
        except Exception as e:
            # æ ¹æ®å†…å®¹ï¼Œè‡ªå·±è¿”å›
            raise e
    
    def summarize(self, paper: Dict[str, Any]) -> str:
        """
        Generate a summary for a paper using OpenAI.
        
        Args:
            paper: Paper information dictionary
            
        Returns:
            Summary string
        """
        prompt = self.get_summary_prompt(paper)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant that summarizes research papers."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error generating summary: {e}")
            return ""

# Factory function to get the appropriate summarizer
def get_summarizer(provider: str = "openai", model_name: str = None, custom_prompt: str = None) -> LLMSummarizer:
    """
    Get a summarizer instance based on the provider.
    
    Args:
        provider: LLM provider (e.g., "openai", "anthropic")
        model_name: Name of the model to use
        custom_prompt: Custom prompt template for summarization
        
    Returns:
        LLMSummarizer instance
    """
    if provider.lower() == "openai":
        return OpenAISummarizer(model_name, custom_prompt=custom_prompt)
    else:
        raise ValueError(f"Unsupported provider: {provider}") 