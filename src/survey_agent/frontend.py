import streamlit as st
import os
import time
from survey_agent.survey.generator import generate_survey, generate_markdown
from survey_agent.arxiv_tools.search import search_papers
from survey_agent.arxiv_tools.download import process_paper
from survey_agent.llm.summarize import get_summarizer
os.environ["API_KEY"] = '979525e325524e629a9fe3a0d406b924.f5e8BbGc4DpMPAbm'
os.environ["BASE_URL"] = 'https://open.bigmodel.cn/api/paas/v4/'
# export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890
os.environ["https_proxy"] = "http://127.0.0.1:7890"
os.environ["http_proxy"] = "http://127.0.0.1:7890"
os.environ["all_proxy"] = "socks5://127.0.0.1:7890"
import uuid

st.set_page_config(page_title="AI è®ºæ–‡ç»¼è¿°ç”Ÿæˆå™¨", layout="wide")
st.title("ğŸŒŸ AI è®ºæ–‡ç»¼è¿°ç”Ÿæˆå™¨ ğŸ’¡")
st.markdown("""
<style>
.big-font { font-size:22px !important; }
</style>
""", unsafe_allow_html=True)

from concurrent.futures import ThreadPoolExecutor, as_completed

def process_papers_parallel(papers, process_paper, progress_placeholder, paper_list_placeholder, max_workers=4):
    processed_papers = [None] * len(papers)  # Pre-allocate list to maintain order
    
    def process_with_progress(idx_paper):
        idx, paper = idx_paper
        result = process_paper(paper)
        return idx, result
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Create list of (idx, paper) tuples for processing
        futures = [executor.submit(process_with_progress, (i, paper)) 
                  for i, paper in enumerate(papers)]
        
        for future in as_completed(futures):
            idx, result = future.result()
            processed_papers[idx] = result
            
            # Update progress display
            progress_placeholder.info(f"æ­£åœ¨ä¸‹è½½ä¸å¤„ç†è®ºæ–‡ {sum(1 for p in processed_papers if p is not None)}/{len(papers)}")
            paper_list_placeholder.markdown(
                "\n".join([
                    f"- {'ğŸ“¥ ' if processed_papers[i] is not None else 'ğŸ” '}{papers[i].title}" 
                    for i in range(len(papers))
                ])
            )
    
    return [p for p in processed_papers if p is not None]

def summarize_papers_parallel(processed_papers, summarizer, progress_placeholder, paper_list_placeholder, max_workers=4):
    summarized_papers = [None] * len(processed_papers)  # Pre-allocate list to maintain order
    
    def summarize_with_progress(idx_paper):
        idx, paper = idx_paper
        paper['llm_summary_res'] = summarizer.summarize(paper)
        return idx, paper
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(summarize_with_progress, (i, paper)) 
                  for i, paper in enumerate(processed_papers)]
        
        for future in as_completed(futures):
            idx, result = future.result()
            summarized_papers[idx] = result
            
            # Update progress display
            progress_placeholder.info(f"LLM æ€»ç»“ä¸­ {sum(1 for p in summarized_papers if p is not None)}/{len(processed_papers)}")
            paper_list_placeholder.markdown(
                "\n".join([
                    f"- {'âœ¨ ' if summarized_papers[i] is not None else 'ğŸ“¥ '}{processed_papers[i]['title']}" 
                    for i in range(len(processed_papers))
                ])
            )
    
    return [p for p in summarized_papers if p is not None]




with st.form("query_form"):
    query = st.text_input("è¯·è¾“å…¥ä½ çš„è®ºæ–‡æŸ¥è¯¢å…³é”®è¯ï¼ˆæ”¯æŒå¤šä¸ªå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼‰", "Vision Language Model, Game")
    max_results = st.slider("æœ€å¤šæ£€ç´¢è®ºæ–‡æ•°", 5, 50, 10)
    # llm_provider = st.selectbox("LLM æä¾›å•†", ["openai"])
    llm_provider = "openai"
    # model_name = st.text_input("LLM æ¨¡å‹å", "glm-4-air")
    model_name = st.selectbox("LLM æ¨¡å‹å", ["glm-4-air", "glm-4-plus"])
    submitted = st.form_submit_button("å¼€å§‹ç”Ÿæˆç»¼è¿°")

progress_placeholder = st.empty()
paper_list_placeholder = st.empty()
summary_placeholder = st.empty()
download_placeholder = st.empty()

if submitted:
    terms = [t.strip() for t in query.split(",") if t.strip()]
    progress_placeholder.info("æ­£åœ¨æ£€ç´¢è®ºæ–‡...")
    papers = search_papers(terms=terms, max_results=max_results)
    titles = [p.title for p in papers]
    paper_list_placeholder.markdown(
        "\n".join([f"- ğŸ” {t}" for t in titles]) or "æœªæ£€ç´¢åˆ°è®ºæ–‡ã€‚"
    )
    
    # ä¿®æ”¹åŸå§‹ä»£ç éƒ¨åˆ†
    processed_papers = process_papers_parallel(papers, process_paper, progress_placeholder, paper_list_placeholder)
    progress_placeholder.info("æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“...")
    summarizer = get_summarizer(llm_provider, model_name)
    processed_papers = summarize_papers_parallel(processed_papers, summarizer, progress_placeholder, paper_list_placeholder)   
        
    progress_placeholder.success("å…¨éƒ¨è®ºæ–‡å¤„ç†å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆ markdown...")
    uuid = str(uuid.uuid4())
    output_md = f"survey_result_{uuid}.md"
    markdown_content = generate_markdown(processed_papers, output_md, terms)
    # åˆ†å‰²æ¡
    
    summary_placeholder.markdown("### ç»¼è¿° Markdown é¢„è§ˆ")
    # summary_placeholder.code(markdown_content, language="markdown")
    summary_placeholder.markdown(markdown_content)
    
    # ç”Ÿæˆ HTML
    import markdown
    html_content = markdown.markdown(markdown_content, extensions=['tables', 'fenced_code'])
    download_placeholder.markdown("### ä¸‹è½½ç»“æœ")
    st.download_button("ä¸‹è½½ Markdown æ–‡ä»¶", markdown_content, file_name="survey_result.md")
    st.download_button("ä¸‹è½½ HTML æ–‡ä»¶", html_content, file_name="survey_result.html")
    progress_placeholder.success("ğŸ‰ ç»¼è¿°å·²ç”Ÿæˆï¼") 