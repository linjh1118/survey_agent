import re
from typing import List, Dict, Any, Optional
from pathlib import Path
import arxiv

class BibParser:
    """Parser for BibTeX files to extract arXiv IDs and other information"""
    
    def __init__(self):
        self.entries = []
        
    def parse_file(self, file_path: str) -> Dict[str, List]:
        """Parse a BibTeX file and return arXiv IDs and entries without arXiv IDs"""
        file_path = Path(file_path)
        if not file_path.exists():
            raise FileNotFoundError(f"BibTeX file not found: {file_path}")
        
        content = file_path.read_text(encoding='utf-8')
        return self.parse_string(content)
    
    def clean_title(self, title: str) -> str:
        """Clean title by removing special BibTeX characters"""
        if not title:
            return ""
        
        # Remove curly braces and other special characters
        cleaned = re.sub(r'[{}]', '', title)
        # Remove colons (important for arXiv search compatibility)
        cleaned = cleaned.replace(':', '')
        # Remove extra whitespace
        cleaned = ' '.join(cleaned.split())
        # Remove special BibTeX commands like \textbackslash
        cleaned = re.sub(r'\\[a-zA-Z]+\s*', '', cleaned)
        # Remove other special characters that might interfere with search
        cleaned = re.sub(r'[^\w\s\-\(\),.!?]', ' ', cleaned)
        # Clean up extra spaces
        cleaned = ' '.join(cleaned.split())
        
        return cleaned.strip()
    
    def parse_string(self, content: str) -> Dict[str, List]:
        """Parse BibTeX content string and return arXiv IDs and entries without arXiv IDs"""
        arxiv_ids = set()  # ä½¿ç”¨setåŽ»é‡
        entries_without_arxiv = []
        
        # ç§»é™¤æ³¨é‡Š
        content = re.sub(r'%.*?\n', '\n', content)
        
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½åŒ…å«arxiv IDçš„URL
        # åŒ¹é… arxiv.org/abs/XXXX.XXXXX æ ¼å¼
        url_pattern = r'arxiv\.org/(?:abs|pdf)/(\d{4}\.\d{4,5})'
        ids_from_urls = re.findall(url_pattern, content, re.IGNORECASE)
        arxiv_ids.update(ids_from_urls)
        
        # åŒ¹é… arXiv:XXXX.XXXXX æ ¼å¼
        arxiv_pattern = r'arxiv[:\.](\d{4}\.\d{4,5})'
        ids_from_arxiv = re.findall(arxiv_pattern, content, re.IGNORECASE)
        arxiv_ids.update(ids_from_arxiv)
        
        # åŒ¹é… arXiv preprint arXiv:XXXX.XXXXX æ ¼å¼
        preprint_pattern = r'arxiv preprint (?:arxiv:)?(\d{4}\.\d{4,5})'
        ids_from_preprint = re.findall(preprint_pattern, content, re.IGNORECASE)
        arxiv_ids.update(ids_from_preprint)
        
        # åŒ¹é…DOIä¸­çš„arXivæ ¼å¼: 10.48550/arXiv.XXXX.XXXXX
        doi_pattern = r'10\.48550/arxiv\.(\d{4}\.\d{4,5})'
        ids_from_doi = re.findall(doi_pattern, content, re.IGNORECASE)
        arxiv_ids.update(ids_from_doi)
        
        # åŒ¹é… abs/XXXX.XXXXX æ ¼å¼
        abs_pattern = r'abs/(\d{4}\.\d{4,5})'
        ids_from_abs = re.findall(abs_pattern, content, re.IGNORECASE)
        arxiv_ids.update(ids_from_abs)
        
        # è§£æžæ‰€æœ‰BibTeXæ¡ç›®ï¼Œæ‰¾å‡ºæ²¡æœ‰arXiv IDçš„
        # æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œèƒ½å¤Ÿæ­£ç¡®åŒ¹é…åµŒå¥—çš„å¤§æ‹¬å·
        entry_pattern = r'@\w+\s*\{([^,]+),\s*(.*?)\n\}'
        entries = re.findall(entry_pattern, content, re.DOTALL)
        
        for entry_key, entry_content in entries:
            # æ£€æŸ¥è¿™ä¸ªæ¡ç›®æ˜¯å¦åŒ…å«arXiv ID
            has_arxiv = bool(re.search(url_pattern, entry_content, re.IGNORECASE) or
                           re.search(arxiv_pattern, entry_content, re.IGNORECASE) or
                           re.search(preprint_pattern, entry_content, re.IGNORECASE) or
                           re.search(doi_pattern, entry_content, re.IGNORECASE) or
                           re.search(abs_pattern, entry_content, re.IGNORECASE))
            
            if not has_arxiv:
                # æå–æ ‡é¢˜ - æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼å¤„ç†åµŒå¥—å¤§æ‹¬å·
                title_match = re.search(r'title\s*=\s*\{(.*?)\}(?=\s*,?\s*\w+\s*=|\s*$)', entry_content, re.IGNORECASE | re.DOTALL)
                if title_match:
                    title = title_match.group(1)
                    cleaned_title = self.clean_title(title)
                    
                    # æå–ä½œè€…ï¼ˆå¯é€‰ï¼‰ - åŒæ ·å¤„ç†å¯èƒ½çš„åµŒå¥—å¤§æ‹¬å·
                    author_match = re.search(r'author\s*=\s*\{(.*?)\}(?=\s*,?\s*\w+\s*=|\s*$)', entry_content, re.IGNORECASE | re.DOTALL)
                    authors = author_match.group(1) if author_match else ""
                    
                    # æå–å¹´ä»½ï¼ˆå¯é€‰ï¼‰
                    year_match = re.search(r'year\s*=\s*\{([^}]+)\}', entry_content, re.IGNORECASE)
                    year = year_match.group(1) if year_match else ""
                    
                    entries_without_arxiv.append({
                        'key': entry_key.strip(),
                        'original_title': title,
                        'cleaned_title': cleaned_title,
                        'authors': authors,
                        'year': year,
                        'full_content': entry_content
                    })
        
        return {
            'arxiv_ids': list(arxiv_ids),
            'entries_without_arxiv': entries_without_arxiv
        }
    
    def search_paper_by_title(self, title: str, verbose: bool = False) -> Optional[Any]:
        """Search for a paper on arXiv by title"""
        if not title:
            return None
            
        # Clean title for search
        cleaned_title = self.clean_title(title)
        
        if not cleaned_title:
            return None
        
        if verbose:
            print(f"ðŸ” æ ‡é¢˜æœç´¢å¼€å§‹:")
            print(f"   åŽŸå§‹æ ‡é¢˜: {title}")
            print(f"   æ¸…ç†åŽæ ‡é¢˜: {cleaned_title}")
            
        try:
            client = arxiv.Client()
            strategy_used = ""
            
            # Strategy 1: Exact title search with quotes
            if verbose:
                print(f"   ç­–ç•¥1: ç²¾ç¡®æ ‡é¢˜æœç´¢...")
            search = arxiv.Search(
                query=f'ti:"{cleaned_title}"',
                max_results=15,
                sort_by=arxiv.SortCriterion.Relevance
            )
            
            results = list(client.results(search))
            if results:
                strategy_used = "ç²¾ç¡®æ ‡é¢˜åŒ¹é…"
            
            # Strategy 2: Flexible title search without quotes
            if not results:
                if verbose:
                    print(f"   ç­–ç•¥2: çµæ´»æ ‡é¢˜æœç´¢...")
                search = arxiv.Search(
                    query=f'ti:{cleaned_title}',
                    max_results=15,
                    sort_by=arxiv.SortCriterion.Relevance
                )
                results = list(client.results(search))
                if results:
                    strategy_used = "çµæ´»æ ‡é¢˜æœç´¢"
            
            # Strategy 3: Search with key words from title
            if not results:
                if verbose:
                    print(f"   ç­–ç•¥3: å…³é”®è¯ç»„åˆæœç´¢...")
                # Extract key words (remove common words)
                stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'been', 'be', 'have', 'has', 'had', 'will', 'would', 'could', 'should'}
                words = cleaned_title.lower().split()
                key_words = [w for w in words if len(w) > 2 and w not in stop_words]
                
                if len(key_words) >= 3:
                    # Use top 5 key words
                    search_terms = ' AND '.join([f'ti:{word}' for word in key_words[:5]])
                    if verbose:
                        print(f"   å…³é”®è¯: {key_words[:5]}")
                    search = arxiv.Search(
                        query=search_terms,
                        max_results=20,
                        sort_by=arxiv.SortCriterion.Relevance
                    )
                    results = list(client.results(search))
                    if results:
                        strategy_used = "å…³é”®è¯ç»„åˆæœç´¢"
            
            if results:
                # Find the best match using improved scoring
                best_match = None
                best_score = 0
                
                for result in results:
                    result_title_cleaned = self.clean_title(result.title)
                    
                    # Method 1: Word overlap scoring
                    title_words = set(cleaned_title.lower().split())
                    result_words = set(result_title_cleaned.lower().split())
                    
                    if title_words and result_words:
                        overlap = len(title_words.intersection(result_words))
                        overlap_score = overlap / max(len(title_words), len(result_words))
                        
                        # Method 2: Character-level similarity (simple)
                        char_score = len(set(cleaned_title.lower()) & set(result_title_cleaned.lower())) / max(len(set(cleaned_title.lower())), len(set(result_title_cleaned.lower())))
                        
                        # Method 3: Length similarity bonus
                        length_ratio = min(len(cleaned_title), len(result_title_cleaned)) / max(len(cleaned_title), len(result_title_cleaned))
                        
                        # Combined score
                        final_score = overlap_score * 0.7 + char_score * 0.2 + length_ratio * 0.1
                        
                        if final_score > best_score:
                            best_score = final_score
                            best_match = result
                
                # Lower threshold for better recall
                if best_score > 0.25:  # Reduced threshold from 0.3 to 0.25
                    if verbose:
                        print(f"   âœ… æœç´¢æˆåŠŸ ({strategy_used})")
                        print(f"   æ‰¾åˆ°è®ºæ–‡: {best_match.title}")
                        print(f"   åŒ¹é…åˆ†æ•°: {best_score:.3f}")
                        arxiv_id = best_match.entry_id.split('/')[-1].split('v')[0]
                        print(f"   arXiv ID: {arxiv_id}")
                        print()
                    return best_match
                else:
                    if verbose:
                        print(f"   âŒ æœç´¢å¤±è´¥: æœ€é«˜åŒ¹é…åˆ†æ•° {best_score:.3f} ä½ŽäºŽé˜ˆå€¼ 0.25")
                        if results:
                            print(f"   æœ€ä½³å€™é€‰: {results[0].title}")
                        print()
            else:
                if verbose:
                    print(f"   âŒ æœç´¢å¤±è´¥: æœªæ‰¾åˆ°ä»»ä½•å€™é€‰è®ºæ–‡")
                    print()
                    
        except Exception as e:
            if verbose:
                print(f"   âŒ æœç´¢å‡ºé”™: {e}")
                print()
            else:
                print(f"Error searching for paper with title '{title}': {e}")
            
        return None
    
    def get_arxiv_papers(self) -> List[Dict[str, Any]]:
        """Get paper objects from arXiv using extracted IDs"""
        try:
            parse_result = self.parse_string(self.content)
            arxiv_ids = parse_result['arxiv_ids']
        except AttributeError:
            return []
        
        client = arxiv.Client()
        papers = []
        
        for arxiv_id in arxiv_ids:
            try:
                # ä½¿ç”¨arxiv APIèŽ·å–è®ºæ–‡ä¿¡æ¯
                search = arxiv.Search(id_list=[arxiv_id])
                results = list(client.results(search))
                if results:
                    papers.append(results[0])
            except Exception as e:
                print(f"Error fetching paper {arxiv_id}: {e}")
                continue
        
        return papers

def parse_bib_file(file_path: str) -> List[Dict[str, Any]]:
    """Convenience function to parse a BibTeX file and return paper objects"""
    parser = BibParser()
    content = Path(file_path).read_text(encoding='utf-8')
    parser.content = content
    return parser.get_arxiv_papers() 