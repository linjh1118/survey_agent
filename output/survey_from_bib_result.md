# Paper List from BIB File: tmpou7by98y.bib
- [25/09] **ToolRM: Outcome Reward Models for Tool-Calling Large Language Models**  
[[Paper](http://arxiv.org/pdf/2509.11963v1)] [[Code/Page]()] [[TLDR/Notes](#toolrm--outcome-reward-models-for-tool-calling-large-language-models)]

- [25/10] **Synthesizing Agentic Data for Web Agents with Progressive Difficulty Enhancement Mechanisms**  
[[Paper](http://arxiv.org/pdf/2510.13913v1)] [[Code/Page]()] [[TLDR/Notes](#synthesizing-agentic-data-for-web-agents-with-progressive-difficulty-enhancement-mechanisms)]

- [25/10] **DeepAnalyze: Agentic Large Language Models for Autonomous Data Science**  
[[Paper](http://arxiv.org/pdf/2510.16872v1)] [[Code/Page]()] [[TLDR/Notes](#deepanalyze--agentic-large-language-models-for-autonomous-data-science)]

- [25/10] **Explore to Evolve: Scaling Evolved Aggregation Logic via Proactive Online Exploration for Deep Research Agents**  
[[Paper](http://arxiv.org/pdf/2510.14438v1)] [[Code/Page]()] [[TLDR/Notes](#explore-to-evolve--scaling-evolved-aggregation-logic-via-proactive-online-exploration-for-deep-research-agents)]

- [25/02] **Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment**  
[[Paper](http://arxiv.org/pdf/2502.16863v1)] [[Code/Page]()] [[TLDR/Notes](#leveraging-large-language-models-for-effective-and-explainable-multi-agent-credit-assignment)]

- [24/10] **ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**  
[[Paper](http://arxiv.org/pdf/2410.18447v2)] [[Code/Page]()] [[TLDR/Notes](#toolflow--boosting-llm-tool-calling-through-natural-and-coherent-dialogue-synthesis)]

- [25/04] **APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay**  
[[Paper](http://arxiv.org/pdf/2504.03601v4)] [[Code/Page](https://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4;)] [[TLDR/Notes](#apigen-mt--agentic-pipeline-for-multi-turn-data-generation-via-simulated-agent-human-interplay)]

- [24/09] **ToolACE: Winning the Points of LLM Function Calling**  
[[Paper](http://arxiv.org/pdf/2409.00920v2)] [[Code/Page](https://huggingface.co/Team-ACE.)] [[TLDR/Notes](#toolace--winning-the-points-of-llm-function-calling)]

- [25/10] **TOUCAN: Synthesizing 1.5M Tool-Agentic Data from Real-World MCP Environments**  
[[Paper](http://arxiv.org/pdf/2510.01179v1)] [[Code/Page]()] [[TLDR/Notes](#toucan--synthesizing-1-5m-tool-agentic-data-from-real-world-mcp-environments)]

- [25/05] **AutoData: A Multi-Agent System for Open Web Data Collection**  
[[Paper](http://arxiv.org/pdf/2505.15859v1)] [[Code/Page](https://github.com/GraphResearcher/AutoData.)] [[TLDR/Notes](#autodata--a-multi-agent-system-for-open-web-data-collection)]

- [25/10] **Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents**  
[[Paper](http://arxiv.org/pdf/2510.24702v1)] [[Code/Page]()] [[TLDR/Notes](#agent-data-protocol--unifying-datasets-for-diverse--effective-fine-tuning-of-llm-agents)]

- [25/08] **Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training**  
[[Paper](http://arxiv.org/pdf/2508.00414v2)] [[Code/Page](https://github.com/Tencent/CognitiveKernel-Pro)] [[TLDR/Notes](#cognitive-kernel-pro--a-framework-for-deep-research-agents-and-agent-foundation-models-training)]



# TLDR/Notes
## toolrm--outcome-reward-models-for-tool-calling-large-language-models
### Abstract
As large language models (LLMs) increasingly interact with external tools,
reward modeling for tool use has become a critical yet underexplored area.
Existing reward models, trained primarily on natural language outputs, struggle
to evaluate tool-based reasoning and execution. To quantify this gap, we
introduce FC-RewardBench, the first benchmark designed to systematically assess
reward models' performance in tool-calling scenarios. Our analysis shows that
current reward models often miss key signals of effective tool use,
highlighting the need for domain-specific modeling. To address this, we propose
a training framework for outcome-based reward models using data synthesized
from permissively licensed, open-weight LLMs. We train models ranging from 1.7B
to 14B parameters and evaluate them across seven out-of-domain benchmarks.
These models consistently outperform general-purpose baselines, achieving up to
25\% average improvement in downstream task performance and enabling
data-efficient fine-tuning through reward-guided filtering.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | ToolRMï¼šå¼€å¯å¤§è¯­è¨€æ¨¡å‹å·¥å…·è°ƒç”¨å¥–åŠ±å»ºæ¨¡æ–°ç¯‡ç« 

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå‘å±•è¿…é€Ÿï¼Œéšç€å…¶åœ¨ç°å®åœºæ™¯ä¸­åº”ç”¨çš„æ·±å…¥ï¼Œä¸å¤–éƒ¨å·¥å…·äº¤äº’çš„éœ€æ±‚æ—¥ç›Šå¢é•¿ï¼Œå·¥å…·è°ƒç”¨æˆä¸ºå…³é”®èƒ½åŠ›ã€‚å¥–åŠ±æ¨¡å‹æ˜¯è®­ç»ƒå’Œå¾®è°ƒLLMsçš„æ ¸å¿ƒç»„ä»¶ï¼Œåˆ†ä¸ºè¿‡ç¨‹å¥–åŠ±æ¨¡å‹å’Œç»“æœå¥–åŠ±æ¨¡å‹ï¼Œå…¶ä¸­ç»“æœå¥–åŠ±æ¨¡å‹å› æ›´æ˜“è®­ç»ƒã€å¯æ‰©å±•æ€§å¼ºç­‰ä¼˜åŠ¿è€Œè¢«å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¥–åŠ±æ¨¡å‹ä¸»è¦åŸºäºè‡ªç„¶è¯­è¨€è¾“å‡ºè¿›è¡Œè®­ç»ƒï¼Œåœ¨è¯„ä¼°åŸºäºå·¥å…·çš„æ¨ç†å’Œæ‰§è¡Œæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œä¸”ç¼ºä¹ä¸“é—¨çš„åŸºå‡†æ¥ç³»ç»Ÿè¯„ä¼°å·¥å…·è°ƒç”¨åœºæ™¯ä¸‹å¥–åŠ±æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œå› æ­¤éœ€è¦ç‰¹å®šé¢†åŸŸçš„å¥–åŠ±å»ºæ¨¡ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå¼•å…¥FC - RewardBench
è¿™æ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å·¥å…·è°ƒç”¨ä»»åŠ¡ä¸­å¥–åŠ±æ¨¡å‹çš„ç»¼åˆåŸºå‡†ï¼Œè¯¥åŸºå‡†æ•°æ®é›†æ¥è‡ªä¼¯å…‹åˆ©å‡½æ•°è°ƒç”¨æ’è¡Œæ¦œï¼ˆBFCLï¼‰ç‰ˆæœ¬3ï¼ŒåŒ…å«1500ä¸ªç‹¬ç‰¹çš„ç”¨æˆ·è¾“å…¥ä»¥åŠæ­£ç¡®å’Œä¸æ­£ç¡®çš„å‡½æ•°è°ƒç”¨ï¼Œç”¨äºé‡åŒ–ç°æœ‰å¥–åŠ±æ¨¡å‹åœ¨å·¥å…·è°ƒç”¨åœºæ™¯ä¸‹çš„è¯„ä¼°å·®è·ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæå‡ºToolRMåŠè®­ç»ƒæ¡†æ¶
ToolRMæ˜¯ä¸€ç»„ä¸“é—¨ç”¨äºå·¥å…·è°ƒç”¨çš„ç»“æœå¥–åŠ±æ¨¡å‹ã€‚é€šè¿‡ä»å¤šç§å¼€æºå‡½æ•°è°ƒç”¨æ¨¡å‹åˆæˆçš„åå¥½æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæå‡ºäº†ä½¿ç”¨è®¸å¯æˆæƒçš„ä¸­ç­‰è§„æ¨¡å¼€æ”¾æƒé‡LLMsç”Ÿæˆçš„æ•°æ®æ¥è®­ç»ƒå·¥å…·è°ƒç”¨ç»“æœå¥–åŠ±æ¨¡å‹çš„æ¡†æ¶ã€‚è®­ç»ƒäº†å‚æ•°èŒƒå›´ä»1.7Båˆ°14Bçš„å¤šä¸ªæ¨¡å‹ï¼Œå¹¶åœ¨ä¸ƒä¸ªåŸŸå¤–åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨FC - RewardBenchä¸Šï¼ŒToolRMä¼˜äºè®¸å¤šæ›´å¤§çš„å¥–åŠ±æ¨¡å‹å’Œä½œä¸ºè¯„åˆ¤çš„LLMsã€‚åœ¨ä¸‹æ¸¸åº”ç”¨ä¸­ï¼Œåœ¨Best - of - nè®¾ç½®ä¸‹ï¼ŒToolRMåœ¨å¤šä¸ªåŸºå‡†ä¸Šå¹³å‡æå‡é«˜è¾¾25%ï¼Œå¹¶ä¸”èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„æ•°æ®è¿‡æ»¤ï¼Œä½¿ç”¨æ›´å°‘çš„æ•°æ®å°±èƒ½å¾—åˆ°æ€§èƒ½æ›´å¥½çš„å¾®è°ƒæ¨¡å‹ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **åŸºå‡†æ„å»º**ï¼šFC - RewardBenchçš„æ„å»ºä¸ºè¯„ä¼°å·¥å…·è°ƒç”¨åœºæ™¯ä¸‹çš„å¥–åŠ±æ¨¡å‹æä¾›äº†æ–°çš„æ ‡å‡†å’Œæ–¹æ³•ï¼Œå¯¹äºå…¶ä»–ç›¸å…³ç ”ç©¶åœ¨è®¾è®¡è¯„ä¼°åŸºå‡†æ–¹é¢å…·æœ‰å€Ÿé‰´æ„ä¹‰ã€‚
2. **æ¨¡å‹è®­ç»ƒ**ï¼šåˆ©ç”¨è®¸å¯æˆæƒçš„å¼€æ”¾æƒé‡LLMsç”Ÿæˆæ•°æ®æ¥è®­ç»ƒç‰¹å®šé¢†åŸŸå¥–åŠ±æ¨¡å‹çš„æ–¹å¼ï¼Œä¸ºè§£å†³ç¼ºä¹é’ˆå¯¹æ€§è®­ç»ƒæ•°æ®çš„é—®é¢˜æä¾›äº†æ–°çš„æ€è·¯ã€‚
3. **æ€§èƒ½æå‡**ï¼šToolRMåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ€§èƒ½æå‡ä»¥åŠæ•°æ®è¿‡æ»¤æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå±•ç¤ºäº†ç‰¹å®šé¢†åŸŸå¥–åŠ±æ¨¡å‹åœ¨ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹å·¥å…·è°ƒç”¨èƒ½åŠ›ä¸Šçš„æ½œåŠ›ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æ–¹å‘ã€‚
``` 

## synthesizing-agentic-data-for-web-agents-with-progressive-difficulty-enhancement-mechanisms
### Abstract
Web-based 'deep research' agents aim to solve complex question - answering
tasks through long-horizon interactions with online tools. These tasks remain
challenging, as the underlying language models are often not optimized for
long-horizon reasoning and exploration. Prior work has proposed workflows for
constructing instruction-tuning datasets, often leveraging knowledge graphs.
However, such methods typically lack fine-grained control over difficulty and
quality, yielding synthetic data that falls short of capturing the complexity
required for long-horizon reasoning. Furthermore, many studies conflate data
and training effects by comparing models trained under different optimization
recipes, making it difficult to isolate and evaluate the effectiveness of the
data itself. We introduce a two-pronged data synthesis pipeline that generates
question - answer pairs by progressively increasing task complexity until a
frontier baseline web agent fails. The baseline agent plays multiple roles in
this process: attempting the questions, validating factuality, checking for
alternative answers, and enforcing filtering. To evaluate the effectiveness of
our synthesis methods, we adopt a controlled training setup based on
distillation from strong web agents. Experiments across multiple web-based
benchmarks show that our dataset - despite being smaller - enables the training
of more effective web agents than existing datasets. In particular, our data
exhibits twice the diversity in tool-use actions, allowing models trained on it
to achieve stronger performance while avoiding repetitive tool-calling
behaviors.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | çªç ´æ•°æ®åˆæˆéš¾é¢˜ï¼ŒåŠ©åŠ›ç½‘é¡µæ™ºèƒ½ä½“å‡çº§

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åŸºäºç½‘é¡µçš„â€œæ·±åº¦ç ”ç©¶â€æ™ºèƒ½ä½“æ—¨åœ¨é€šè¿‡ä¸åœ¨çº¿å·¥å…·çš„é•¿æœŸäº¤äº’æ¥è§£å†³å¤æ‚çš„é—®ç­”ä»»åŠ¡ï¼Œä½†åº•å±‚è¯­è¨€æ¨¡å‹å¾€å¾€æœªé’ˆå¯¹é•¿æœŸæ¨ç†å’Œæ¢ç´¢è¿›è¡Œä¼˜åŒ–ï¼Œä½¿å¾—è¿™äº›ä»»åŠ¡æå…·æŒ‘æˆ˜æ€§ã€‚å…ˆå‰æ„å»ºæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†çš„æ–¹æ³•é€šå¸¸ç¼ºä¹å¯¹éš¾åº¦å’Œè´¨é‡çš„ç²¾ç»†æ§åˆ¶ï¼Œåˆæˆçš„æ•°æ®éš¾ä»¥æ•æ‰é•¿æœŸæ¨ç†æ‰€éœ€çš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œè®¸å¤šç ”ç©¶å°†æ•°æ®å’Œè®­ç»ƒæ•ˆæœæ··ä¸ºä¸€è°ˆï¼Œéš¾ä»¥å•ç‹¬è¯„ä¼°æ•°æ®æœ¬èº«çš„æœ‰æ•ˆæ€§ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºåä¸ºProgressive Searchï¼ˆProgSearchï¼‰çš„åŒç®¡é½ä¸‹çš„æ•°æ®åˆæˆç®¡é“ï¼Œé€šè¿‡è¿­ä»£ç»†åŒ–ç”Ÿæˆé—®ç­”å¯¹ã€‚é‡‡ç”¨è‡ªé¡¶å‘ä¸‹çš„æ–¹æ³•ï¼Œæ„å»ºäº‹å®æ ‘ï¼Œæ²¿æ ‘åˆ†æ”¯é€æ­¥æ•´åˆäº‹å®æ¥åˆæˆé—®ç­”å¯¹ï¼›åŒæ—¶é‡‡ç”¨è‡ªåº•å‘ä¸Šçš„æ–¹æ³•ï¼Œä»¥å›ºå®šçš„ç¨€æœ‰å®ä½“ä¸ºåŸºç¡€äº‹å®é”šç‚¹ï¼Œé€šè¿‡æ··æ·†å’Œäº‹å®èåˆç”Ÿæˆæ›´éš¾çš„é—®é¢˜ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¼•å…¥åŸºçº¿ç½‘é¡µæ™ºèƒ½ä½“åœ¨æ¸è¿›ç»†åŒ–è¿‡ç¨‹ä¸­å‘æŒ¥å¤šé‡ä½œç”¨ï¼ŒåŒ…æ‹¬ä½œä¸ºæ±‚è§£å™¨è¡¡é‡é—®é¢˜éš¾åº¦ã€ä½œä¸ºæé—®è€…åˆæˆé—®ç­”å¯¹ã€ä½œä¸ºç ”ç©¶å‘˜ä»ç½‘é¡µæå–æ”¯æŒäº‹å®ä»¥åŠä½œä¸ºè¯„ä¼°è€…ç¡®ä¿äº‹å®å‡†ç¡®æ€§å’Œç¬¦åˆçº¦æŸæ¡ä»¶ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
é€šè¿‡åŸºäºä»å¼ºå¤§ç½‘é¡µæ™ºèƒ½ä½“è’¸é¦çš„å—æ§è®­ç»ƒè®¾ç½®æ¥è¯„ä¼°åˆæˆæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚åœ¨å¤šä¸ªåŸºäºç½‘é¡µçš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œå°½ç®¡æœ¬æ–‡æ•°æ®é›†è§„æ¨¡è¾ƒå°ï¼Œä½†ä¸ç°æœ‰æ•°æ®é›†ç›¸æ¯”ï¼Œèƒ½å¤Ÿè®­ç»ƒå‡ºæ›´æœ‰æ•ˆçš„ç½‘é¡µæ™ºèƒ½ä½“ã€‚åœ¨Qwen3 - 8Bä¸Šå¢ç›Šé«˜è¾¾8%ï¼Œåœ¨Qwen2.5 - 7Bä¸Šå¢ç›Šè¾¾23%ã€‚æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œæœ¬æ–‡æ•°æ®ä¸­çš„è½¨è¿¹åŒ…å«çš„å·¥å…·è°ƒç”¨åŠ¨ä½œæ¯”å…ˆå‰æ•°æ®é›†å¤š4å€ï¼Œä½“ç°äº†åˆæˆé—®ç­”å¯¹æ›´é«˜çš„å¤æ‚æ€§å’Œæ¨ç†æ·±åº¦ã€‚ç»è¿‡ç›‘ç£å¾®è°ƒåï¼Œåœ¨æœ¬æ–‡åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„æ£€æŸ¥ç‚¹ä¹Ÿå±•ç¤ºå‡ºæ›´å¤šæ ·åŒ–çš„å·¥å…·ä½¿ç”¨ï¼Œç›´æ¥è½¬åŒ–ä¸ºæ›´å¼ºçš„åŸºå‡†æµ‹è¯•æ€§èƒ½ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
è®ºæ–‡æå‡ºçš„åŒç®¡é½ä¸‹çš„æ•°æ®åˆæˆç®¡é“ä»¥åŠåˆ©ç”¨åŸºçº¿æ™ºèƒ½ä½“è¿›è¡Œéš¾åº¦æ§åˆ¶å’Œè´¨é‡éªŒè¯çš„æ–¹æ³•ï¼Œä¸ºæ„å»ºé«˜è´¨é‡çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†æä¾›äº†æ–°çš„æ€è·¯ã€‚åœ¨ç ”ç©¶æ•°æ®åˆæˆå¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“æ—¶ï¼Œé‡‡ç”¨çš„å—æ§è®­ç»ƒè®¾ç½®æœ‰åŠ©äºæ›´å‡†ç¡®åœ°è¯„ä¼°æ•°æ®æœ¬èº«çš„æœ‰æ•ˆæ€§ï¼Œè¿™ç§å®éªŒè®¾è®¡å€¼å¾—å€Ÿé‰´ã€‚
``` 

## deepanalyze--agentic-large-language-models-for-autonomous-data-science
### Abstract
Autonomous data science, from raw data sources to analyst-grade deep research
reports, has been a long-standing challenge, and is now becoming feasible with
the emergence of powerful large language models (LLMs). Recent workflow-based
data agents have shown promising results on specific data tasks but remain
fundamentally limited in achieving fully autonomous data science due to their
reliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,
the first agentic LLM designed for autonomous data science, capable of
automatically completing the end-toend pipeline from data sources to
analyst-grade deep research reports. To tackle high-complexity data science
tasks, we propose a curriculum-based agentic training paradigm that emulates
the learning trajectory of human data scientists, enabling LLMs to
progressively acquire and integrate multiple capabilities in real-world
environments. We also introduce a data-grounded trajectory synthesis framework
that constructs high-quality training data. Through agentic training,
DeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data
question answering and specialized analytical tasks to open-ended data
research. Experiments demonstrate that, with only 8B parameters, DeepAnalyze
outperforms previous workflow-based agents built on most advanced proprietary
LLMs. The model, code, and training data of DeepAnalyze are open-sourced,
paving the way toward autonomous data science.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | DeepAnalyzeï¼šå¼€å¯è‡ªä¸»æ•°æ®ç§‘å­¦æ–°æ—¶ä»£

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
è‡ªä¸»æ•°æ®ç§‘å­¦æ—¨åœ¨å®ç°ä»åŸå§‹æ•°æ®æºåˆ°åˆ†æå¸ˆçº§æ·±åº¦ç ”ç©¶æŠ¥å‘Šçš„è‡ªåŠ¨åŒ–ï¼Œè¿™ä¸€ç›´æ˜¯æ•°æ®ç§‘å­¦ç•Œé•¿æœŸè¿½æ±‚çš„æ ¸å¿ƒç›®æ ‡ã€‚ç„¶è€Œï¼Œè¯¥è¿‡ç¨‹æ¶‰åŠæ•°æ®å‡†å¤‡ã€åˆ†æã€å»ºæ¨¡ã€å¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆç­‰ä¸€ç³»åˆ—å¤æ‚ä¸”ç›¸äº’ä¾èµ–çš„ä»»åŠ¡ï¼Œå®ç°èµ·æ¥é¢‡å…·æŒ‘æˆ˜ã€‚å°½ç®¡å¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ä½¿å…¶å˜å¾—å¯è¡Œï¼Œä½†LLMsåœ¨åè°ƒå¤æ‚çš„å¤šé˜¶æ®µæ•°æ®ç§‘å­¦æµç¨‹ä»¥åŠå¤„ç†å„ç§ç»“æ„åŒ–æ•°æ®æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚è¿‘æœŸåŸºäºå·¥ä½œæµçš„æ•°æ®ä»£ç†åœ¨ç‰¹å®šæ•°æ®ä»»åŠ¡ä¸Šè™½æœ‰ä¸é”™è¡¨ç°ï¼Œä½†å› ä¾èµ–é¢„å®šä¹‰å·¥ä½œæµï¼Œåœ¨å®ç°å®Œå…¨è‡ªä¸»çš„æ•°æ®ç§‘å­¦æ–¹é¢å­˜åœ¨æ ¹æœ¬å±€é™ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºDeepAnalyze - 8B
è¿™æ˜¯é¦–ä¸ªä¸“ä¸ºè‡ªä¸»æ•°æ®ç§‘å­¦è®¾è®¡çš„ä»£ç†å‹å¤§è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å®Œæˆä»æ•°æ®æºåˆ°åˆ†æå¸ˆçº§æ·±åº¦ç ”ç©¶æŠ¥å‘Šçš„ç«¯åˆ°ç«¯æµç¨‹ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæå‡ºåŸºäºè¯¾ç¨‹çš„ä»£ç†è®­ç»ƒèŒƒå¼
è¯¥èŒƒå¼æ¨¡ä»¿äººç±»æ•°æ®ç§‘å­¦å®¶çš„å­¦ä¹ è½¨è¿¹ï¼Œä½¿å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåœ¨ç°å®ä¸–ç•Œç¯å¢ƒä¸­é€æ­¥è·å–å¹¶æ•´åˆå¤šç§èƒ½åŠ›ï¼Œä»¥åº”å¯¹é«˜å¤æ‚æ€§çš„æ•°æ®ç§‘å­¦ä»»åŠ¡ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå¼•å…¥åŸºäºæ•°æ®çš„è½¨è¿¹åˆæˆæ¡†æ¶
ç”¨äºæ„å»ºé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼ŒåŠ©åŠ›DeepAnalyzeé€šè¿‡ä»£ç†è®­ç»ƒå­¦ä¹ æ‰§è¡Œä»æ•°æ®é—®ç­”ã€ä¸“ä¸šåˆ†æä»»åŠ¡åˆ°å¼€æ”¾å¼æ•°æ®ç ”ç©¶ç­‰å¹¿æ³›çš„æ•°æ®ä»»åŠ¡ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
å®éªŒè¡¨æ˜ï¼Œä»…æ‹¥æœ‰80äº¿å‚æ•°çš„DeepAnalyzeåœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†å…ˆå‰åŸºäºæœ€å…ˆè¿›ä¸“æœ‰å¤§è¯­è¨€æ¨¡å‹æ„å»ºçš„åŸºäºå·¥ä½œæµçš„ä»£ç†ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **æ¨¡å‹è®¾è®¡æ€è·¯**ï¼šDeepAnalyzeçš„è®¾è®¡ä¸ºå¼€å‘é¢å‘ç‰¹å®šé¢†åŸŸçš„å¤§è¯­è¨€æ¨¡å‹æä¾›äº†æ–°çš„æ€è·¯ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦æ•´åˆå¤šç§èƒ½åŠ›ä»¥å¤„ç†å¤æ‚ä»»åŠ¡çš„åœºæ™¯ä¸­ã€‚
2. **è®­ç»ƒèŒƒå¼**ï¼šåŸºäºè¯¾ç¨‹çš„ä»£ç†è®­ç»ƒèŒƒå¼æ¨¡ä»¿äººç±»å­¦ä¹ è½¨è¿¹ï¼Œä¸ºæå‡æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å­¦ä¹ å’Œé€‚åº”èƒ½åŠ›æä¾›äº†å€Ÿé‰´ï¼Œå¯åº”ç”¨äºå…¶ä»–éœ€è¦æ¨¡å‹é€æ­¥å­¦ä¹ å’Œæˆé•¿çš„é¢†åŸŸã€‚
3. **æ•°æ®æ„å»ºæ¡†æ¶**ï¼šåŸºäºæ•°æ®çš„è½¨è¿¹åˆæˆæ¡†æ¶å¯¹äºæ„å»ºé«˜è´¨é‡è®­ç»ƒæ•°æ®å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ï¼Œæœ‰åŠ©äºè§£å†³åœ¨è®­ç»ƒæ¨¡å‹æ—¶æ•°æ®è´¨é‡ä¸é«˜çš„é—®é¢˜ã€‚
``` 

## explore-to-evolve--scaling-evolved-aggregation-logic-via-proactive-online-exploration-for-deep-research-agents
### Abstract
Deep research web agents not only retrieve information from diverse sources
such as web environments, files, and multimodal inputs, but more importantly,
they need to rigorously analyze and aggregate knowledge for insightful
research. However, existing open-source deep research agents predominantly
focus on enhancing information-seeking capabilities of web agents to locate
specific information, while overlooking the essential need for information
aggregation, which would limit their ability to support in-depth research. We
propose an Explore to Evolve paradigm to scalably construct verifiable training
data for web agents. Begins with proactive online exploration, an agent sources
grounded information by exploring the real web. Using the collected evidence,
the agent then self-evolves an aggregation program by selecting, composing, and
refining operations from 12 high-level logical types to synthesize a verifiable
QA pair. This evolution from high-level guidance to concrete operations allowed
us to scalably produce WebAggregatorQA, a dataset of 10K samples across 50K
websites and 11 domains. Based on an open-source agent framework, SmolAgents,
we collect supervised fine-tuning trajectories to develop a series of
foundation models, WebAggregator. WebAggregator-8B matches the performance of
GPT-4.1, while the 32B variant surpasses GPT-4.1 by more than 10% on GAIA-text
and closely approaches Claude-3.7-sonnet. Moreover, given the limited
availability of benchmarks that evaluate web agents' information aggregation
abilities, we construct a human-annotated evaluation split of WebAggregatorQA
as a challenging test set. On this benchmark, Claude-3.7-sonnet only achieves
28%, and GPT-4.1 scores 25.8%. Even when agents manage to retrieve all
references, they still struggle on WebAggregatorQA, highlighting the need to
strengthen the information aggregation capabilities of web agent foundations.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | æ¢ç´¢è¿›åŒ–ï¼šæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“çš„ä¿¡æ¯èšåˆæ–°èŒƒå¼

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
æ·±åº¦ç ”ç©¶ç½‘ç»œæ™ºèƒ½ä½“ä¸ä»…è¦ä»ç½‘ç»œç¯å¢ƒã€æ–‡ä»¶ã€å¤šæ¨¡æ€è¾“å…¥ç­‰å¤šæ ·æ¥æºæ£€ç´¢ä¿¡æ¯ï¼Œæ›´é‡è¦çš„æ˜¯éœ€ä¸¥æ ¼åˆ†æå’ŒèšåˆçŸ¥è¯†ä»¥å¼€å±•æœ‰æ´å¯ŸåŠ›çš„ç ”ç©¶ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¼€æºæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ä¸»è¦èšç„¦äºæå‡ç½‘ç»œæ™ºèƒ½ä½“å®šä½ç‰¹å®šä¿¡æ¯çš„ä¿¡æ¯æœç´¢èƒ½åŠ›ï¼Œå´å¿½è§†äº†ä¿¡æ¯èšåˆè¿™ä¸€å…³é”®éœ€æ±‚ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬æ”¯æŒæ·±å…¥ç ”ç©¶çš„èƒ½åŠ›ã€‚åŒæ—¶ï¼Œç°æœ‰çš„å¤šè·³é—®ç­”æ•°æ®é›†å¾ˆå°‘æ¶‰åŠçœŸå®çš„ç½‘ç»œäº¤äº’ï¼Œè¿‘æœŸçš„ç½‘ç»œæ™ºèƒ½ä½“æ•°æ®é›†åœ¨ä¿¡æ¯æ¥æºçš„åŠ¨æ€æ€§å’Œå¤æ‚æ€§ä»¥åŠå¯¹å¤æ‚èšåˆçš„éœ€æ±‚æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚å› æ­¤ï¼Œä¿ƒè¿›å’Œè¯„ä¼°èšåˆèƒ½åŠ›æ˜¯ç½‘ç»œæ™ºèƒ½ä½“ç ”ç©¶ä¸­ä¸€ä¸ªå…³é”®ä½†å°šæœªå……åˆ†æ¢ç´¢çš„æŒ‘æˆ˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºExplore to Evolveæ–¹æ³•
è¯¥æ–¹æ³•é‡‡ç”¨â€œæ¢ç´¢ï¼šä¸»åŠ¨åœ¨çº¿ç½‘ç»œæ¢ç´¢â€å’Œâ€œè¿›åŒ–ï¼šè‡ªåŠ¨èšåˆé€»è¾‘åˆæˆâ€ï¼Œå°†æ•´ä¸ªä»»åŠ¡ç»„åˆè¿‡ç¨‹è§†ä¸ºæ™ºèƒ½ä½“é©±åŠ¨çš„æµæ°´çº¿ã€‚æ™ºèƒ½ä½“é…å¤‡å…ˆè¿›çš„ç½‘ç»œå·¥å…·ï¼Œæ”¯æŒæœç´¢ã€é™æ€è§£æã€åŠ¨æ€äº¤äº’ã€æ–‡ä»¶å¤„ç†å’Œè§†è§‰è¾“å…¥ç­‰åŠŸèƒ½ï¼Œä»¥æ”¯æŒå¤šæ ·åŒ–çš„ç”¨æˆ·åœºæ™¯ã€‚åœ¨ä¸»åŠ¨åœ¨çº¿æ¢ç´¢é˜¶æ®µï¼Œæ™ºèƒ½ä½“é€šè¿‡æ¢ç´¢å®æ—¶ç½‘ç»œæ”¶é›†èµ„æºè¯­æ–™åº“ï¼›åœ¨è‡ªåŠ¨èšåˆé€»è¾‘åˆæˆé˜¶æ®µï¼Œæ™ºèƒ½ä½“åˆ©ç”¨å—å¤šè·³åˆ†æå’Œé€»è¾‘æ¨ç†ç ”ç©¶å¯å‘çš„é«˜çº§èšåˆé€»è¾‘åˆ†ç±»æ³•ï¼Œå°†é«˜çº§èšåˆæŒ‡å¯¼å®ä¾‹åŒ–å¹¶è¿›åŒ–ä¸ºå…·ä½“æ“ä½œï¼Œæ„å»ºåŸºäºæ¢ç´¢çŸ¥è¯†çš„é—®ç­”å¯¹ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæ„å»ºWebAggregatorQAæ•°æ®é›†
é€šè¿‡ä¸Šè¿°æ–¹æ³•ï¼Œå¯æ‰©å±•åœ°ç”Ÿæˆäº†WebAggregatorQAæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«è·¨è¶Š50Kä¸ªç½‘ç«™å’Œ11ä¸ªé¢†åŸŸçš„10Kä¸ªæ ·æœ¬ã€‚åŒæ—¶ï¼Œæ„å»ºäº†ä¸€ä¸ªäººå·¥æ ‡æ³¨çš„è¯„ä¼°åˆ†å‰²ä½œä¸ºå…·æœ‰æŒ‘æˆ˜æ€§çš„æµ‹è¯•é›†ï¼Œç”¨äºè¯„ä¼°ç½‘ç»œæ™ºèƒ½ä½“çš„ä¿¡æ¯èšåˆèƒ½åŠ›ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå¼€å‘WebAggregatoræ¨¡å‹ç³»åˆ—
åŸºäºå¼€æºæ™ºèƒ½ä½“æ¡†æ¶SmolAgentsï¼Œæ”¶é›†ç›‘ç£å¾®è°ƒè½¨è¿¹ï¼Œå¼€å‘äº†ä¸€ç³»åˆ—åŸºç¡€æ¨¡å‹WebAggregatorã€‚

### ğŸ“ˆ å®éªŒç»“æœ
WebAggregator - 8Båœ¨æ€§èƒ½ä¸Šä¸GPT - 4.1ç›¸å½“ï¼Œè€Œ32Bå˜ä½“åœ¨GAIA - textä¸Šè¶…è¿‡GPT - 4.1è¶…è¿‡10%ï¼Œå¹¶æ¥è¿‘Claude - 3.7 - sonnetçš„æ€§èƒ½ã€‚åœ¨æ„å»ºçš„å…·æœ‰æŒ‘æˆ˜æ€§çš„WebAggregatorQAåŸºå‡†æµ‹è¯•ä¸Šï¼ŒClaude - 3.7 - sonnetä»…è¾¾åˆ°28%ï¼ŒGPT - 4.1å¾—åˆ†ä¸º25.8%ï¼Œå³ä½¿æ™ºèƒ½ä½“æˆåŠŸæ£€ç´¢åˆ°æ‰€æœ‰å‚è€ƒæ–‡çŒ®ï¼Œåœ¨WebAggregatorQAä¸Šä»é¢ä¸´å›°éš¾ï¼Œå‡¸æ˜¾äº†åŠ å¼ºç½‘ç»œæ™ºèƒ½ä½“åŸºç¡€ä¿¡æ¯èšåˆèƒ½åŠ›çš„å¿…è¦æ€§ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **æ•°æ®æ„å»ºæ–¹æ³•**ï¼šExplore to Evolveæ–¹æ³•ä¸ºæ„å»ºæ¶µç›–å¤šæ ·åŒ–ä¿¡æ¯æ¥æºå’Œå¤æ‚èšåˆéœ€æ±‚çš„æ•°æ®é›†æä¾›äº†æ–°æ€è·¯ï¼Œå¯åº”ç”¨äºå…¶ä»–éœ€è¦æ„å»ºç±»ä¼¼æ•°æ®é›†çš„ç ”ç©¶ä¸­ã€‚
2. **æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°**ï¼šåŸºäºå¼€æºæ¡†æ¶æ”¶é›†ç›‘ç£å¾®è°ƒè½¨è¿¹å¼€å‘æ¨¡å‹ï¼Œå¹¶æ„å»ºä¸“é—¨çš„è¯„ä¼°é›†æ¥è¯„ä¼°æ¨¡å‹åœ¨ä¿¡æ¯èšåˆèƒ½åŠ›æ–¹é¢çš„è¡¨ç°ï¼Œè¿™ç§è®­ç»ƒä¸è¯„ä¼°æ–¹å¼æœ‰åŠ©äºæå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œé’ˆå¯¹æ€§ã€‚
3. **å…³æ³¨ä¿¡æ¯èšåˆ**ï¼šå¼ºè°ƒäº†ä¿¡æ¯èšåˆèƒ½åŠ›åœ¨ç½‘ç»œæ™ºèƒ½ä½“ç ”ç©¶ä¸­çš„é‡è¦æ€§ï¼Œæé†’ç ”ç©¶è€…åœ¨å¼€å‘æ™ºèƒ½ä½“æ—¶ä¸èƒ½å¿½è§†è¿™ä¸€å…³é”®èƒ½åŠ›çš„æå‡ã€‚ 
``` 

## leveraging-large-language-models-for-effective-and-explainable-multi-agent-credit-assignment
### Abstract
Recent work, spanning from autonomous vehicle coordination to in-space
assembly, has shown the importance of learning collaborative behavior for
enabling robots to achieve shared goals. A common approach for learning this
cooperative behavior is to utilize the centralized-training
decentralized-execution paradigm. However, this approach also introduces a new
challenge: how do we evaluate the contributions of each agent's actions to the
overall success or failure of the team. This credit assignment problem has
remained open, and has been extensively studied in the Multi-Agent
Reinforcement Learning literature. In fact, humans manually inspecting agent
behavior often generate better credit evaluations than existing methods. We
combine this observation with recent works which show Large Language Models
demonstrate human-level performance at many pattern recognition tasks. Our key
idea is to reformulate credit assignment to the two pattern recognition
problems of sequence improvement and attribution, which motivates our novel
LLM-MCA method. Our approach utilizes a centralized LLM reward-critic which
numerically decomposes the environment reward based on the individualized
contribution of each agent in the scenario. We then update the agents' policy
networks based on this feedback. We also propose an extension LLM-TACA where
our LLM critic performs explicit task assignment by passing an intermediary
goal directly to each agent policy in the scenario. Both our methods far
outperform the state-of-the-art on a variety of benchmarks, including
Level-Based Foraging, Robotic Warehouse, and our new Spaceworld benchmark which
incorporates collision-related safety constraints. As an artifact of our
methods, we generate large trajectory datasets with each timestep annotated
with per-agent reward information, as sampled from our LLM critics.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®ç°é«˜æ•ˆä¸”å¯è§£é‡Šçš„å¤šæ™ºèƒ½ä½“åŠŸåŠ³åˆ†é…

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨è‡ªåŠ¨é©¾é©¶è½¦è¾†åè°ƒåˆ°å¤ªç©ºè£…é…ç­‰ä¼—å¤šå®é™…åœºæ™¯ä¸­ï¼Œå­¦ä¹ åä½œè¡Œä¸ºå¯¹äºä½¿æœºå™¨äººå®ç°å…±åŒç›®æ ‡è‡³å…³é‡è¦ï¼Œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­çš„é›†ä¸­è®­ç»ƒ - åˆ†æ•£æ‰§è¡Œï¼ˆCTDEï¼‰èŒƒå¼å¸¸è¢«ç”¨äºå­¦ä¹ è¿™ç§åä½œè¡Œä¸ºã€‚ç„¶è€Œï¼Œåœ¨CTDEçš„ä¸­å¤®è®­ç»ƒé˜¶æ®µï¼Œä¸€ä¸ªå…³é”®æŒ‘æˆ˜æ˜¯å¦‚ä½•åˆ†ç¦»æ¯ä¸ªç­–ç•¥å˜åŒ–çš„å½±å“ï¼Œå¹¶è¯„ä¼°æ¯ä¸ªæ™ºèƒ½ä½“å¯¹å…¨å±€ä»»åŠ¡æ•´ä½“æˆåŠŸæˆ–å¤±è´¥çš„è´¡çŒ®ï¼Œå³ â€œåŠŸåŠ³åˆ†é…â€ é—®é¢˜ã€‚ä¼ ç»Ÿä¸Šï¼Œç¯å¢ƒä»…æ ¹æ®æ™ºèƒ½ä½“æ˜¯å¦å®ç°å…±äº«ç›®æ ‡æä¾›é›†ä½“å¥–åŠ±ï¼ŒCTDEè®­ç»ƒç®—æ³•éœ€ä»å•ä¸€å¥–åŠ±ä¸­ç¡®å®šæ¯ä¸ªæ™ºèƒ½ä½“çš„è´¡çŒ®å¹¶æ›´æ–°ç­–ç•¥ã€‚è¯¥é—®é¢˜ä¸€ç›´æœªå¾—åˆ°å¾ˆå¥½è§£å†³ï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨è¯¸å¤šå±€é™ï¼Œå¦‚åé¦ˆè´¨é‡ä½ã€è¡ŒåŠ¨å½±å“åŠ›ä½ä»¥åŠå¤„ç†å¤æ‚äº¤äº’å›°éš¾ç­‰ã€‚åŒæ—¶ï¼Œäººç±»æ‰‹åŠ¨æ£€æŸ¥æ™ºèƒ½ä½“è¡Œä¸ºå¾€å¾€èƒ½äº§ç”Ÿæ¯”ç°æœ‰æ–¹æ³•æ›´å¥½çš„åŠŸåŠ³è¯„ä¼°ï¼Œä¸”è¿‘æœŸç ”ç©¶è¡¨æ˜å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®¸å¤šæ¨¡å¼è¯†åˆ«ä»»åŠ¡ä¸­å±•ç°å‡ºäººç±»æ°´å¹³çš„æ€§èƒ½ï¼ŒåŸºäºæ­¤ï¼Œè®ºæ–‡ä½œè€…å¸Œæœ›åˆ©ç”¨LLMsæ¥è§£å†³å¤šæ™ºèƒ½ä½“åŠŸåŠ³åˆ†é…é—®é¢˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºLLM - MCAæ–¹æ³•
å°†åŠŸåŠ³åˆ†é…é‡æ–°è¡¨è¿°ä¸ºåºåˆ—æ”¹è¿›å’Œå½’å› è¿™ä¸¤ä¸ªæ¨¡å¼è¯†åˆ«é—®é¢˜ã€‚åˆ©ç”¨é›†ä¸­å¼çš„LLMå¥–åŠ± - è¯„è®ºå®¶ï¼ŒåŸºäºåœºæ™¯ä¸­æ¯ä¸ªæ™ºèƒ½ä½“çš„ä¸ªæ€§åŒ–è´¡çŒ®ï¼Œå¯¹ç¯å¢ƒå¥–åŠ±è¿›è¡Œæ•°å€¼åˆ†è§£ï¼Œç„¶åæ ¹æ®æ­¤åé¦ˆæ›´æ–°æ™ºèƒ½ä½“çš„ç­–ç•¥ç½‘ç»œã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæå‡ºLLM - TACAæ–¹æ³•
ä½œä¸ºLLM - MCAçš„æ‰©å±•ï¼Œå…¶ä¸­LLMè¯„è®ºå®¶é€šè¿‡å°†ä¸­é—´ç›®æ ‡ç›´æ¥ä¼ é€’ç»™åœºæ™¯ä¸­çš„æ¯ä¸ªæ™ºèƒ½ä½“ç­–ç•¥æ¥æ‰§è¡Œæ˜¾å¼ä»»åŠ¡åˆ†é…ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­ï¼ŒåŒ…æ‹¬åŸºäºç­‰çº§çš„è§…é£Ÿã€æœºå™¨äººä»“åº“ä»¥åŠæ–°æå‡ºçš„çº³å…¥ç¢°æ’ç›¸å…³å®‰å…¨çº¦æŸçš„ â€œSpaceworldâ€ åŸºå‡†æµ‹è¯•ï¼ŒLLM - MCAå’ŒLLM - TACAè¿™ä¸¤ç§æ–¹æ³•å‡è¿œè¶…å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œä½œä¸ºæ–¹æ³•çš„äº§ç‰©ï¼Œç”Ÿæˆäº†å¸¦æœ‰æ¯ä¸ªæ—¶é—´æ­¥é•¿çš„æ¯ä¸ªæ™ºèƒ½ä½“å¥–åŠ±ä¿¡æ¯æ³¨é‡Šçš„å¤§å‹è½¨è¿¹æ•°æ®é›†ï¼Œè¿™äº›ä¿¡æ¯ä»LLMè¯„è®ºå®¶ä¸­é‡‡æ ·å¾—åˆ°ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **é—®é¢˜è½¬æ¢æ€è·¯**ï¼šå°†åŠŸåŠ³åˆ†é…é—®é¢˜è½¬æ¢ä¸ºæ¨¡å¼è¯†åˆ«é—®é¢˜ï¼Œä¸ºè§£å†³å¤šæ™ºèƒ½ä½“åä½œä¸­çš„å¤æ‚é—®é¢˜æä¾›äº†æ–°çš„è§†è§’å’Œæ€è·¯ï¼Œå¯å‘ç ”ç©¶è€…åœ¨é¢å¯¹ç±»ä¼¼éš¾ä»¥è§£å†³çš„é—®é¢˜æ—¶ï¼Œå°è¯•ä»å…¶ä»–è§’åº¦è¿›è¡Œè½¬æ¢å’Œæ€è€ƒã€‚
2. **æ¨¡å‹åº”ç”¨**ï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æ¨¡å¼è¯†åˆ«èƒ½åŠ›æ¥å¤„ç†å¤šæ™ºèƒ½ä½“ç»“æ„åŠŸåŠ³åˆ†é…é—®é¢˜ï¼Œå±•ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åº”ç”¨æ½œåŠ›ï¼Œä¸ºå…¶ä»–ç›¸å…³ç ”ç©¶åœ¨æ¨¡å‹é€‰æ‹©å’Œåº”ç”¨ä¸Šæä¾›äº†å‚è€ƒã€‚
3. **æ•°æ®é›†è´¡çŒ®**ï¼šç”Ÿæˆçš„å¸¦æœ‰è¯¦ç»†æ³¨é‡Šçš„å¤§å‹è½¨è¿¹æ•°æ®é›†å¯ç”¨äºæœªæ¥çš„ç¦»çº¿è®­ç»ƒï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†å®è´µçš„æ•°æ®èµ„æºï¼Œæœ‰åŠ©äºæ¨åŠ¨å¤šæ™ºèƒ½ä½“åä½œç­–ç•¥ç¦»çº¿è®­ç»ƒç›¸å…³ç ”ç©¶çš„å‘å±•ã€‚
``` 

## toolflow--boosting-llm-tool-calling-through-natural-and-coherent-dialogue-synthesis
### Abstract
Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | ToolFlowï¼šå¼€å¯å¤§è¯­è¨€æ¨¡å‹å·¥å…·è°ƒç”¨æ–°å¢ƒç•Œ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å·¥å…·è°ƒç”¨èƒ½åŠ›æå‡å¸¸é‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ–¹æ³•ï¼Œå…¶è®­ç»ƒæ•°æ®å¤šä¸ºåˆæˆæ‰€å¾—ã€‚å½“å‰æ•°æ®åˆæˆè¿‡ç¨‹é€šå¸¸æ˜¯é‡‡æ ·ä¸€ç»„å·¥å…·ã€åŸºäºå·¥å…·åˆ¶å®šéœ€æ±‚å¹¶ç”Ÿæˆè°ƒç”¨è¯­å¥ã€‚ç„¶è€Œï¼Œéšæœºé‡‡æ ·çš„å·¥å…·ç¼ºä¹ç›¸å…³æ€§ï¼Œéš¾ä»¥ç»„åˆï¼Œé™ä½äº†æ•°æ®å¤šæ ·æ€§ï¼›åŒæ—¶ï¼Œç°æœ‰å·¥ä½œå¿½è§†äº†å¯¹è¯è½®æ¬¡é—´çš„è¿è´¯æ€§ï¼Œå¯¼è‡´åˆæˆæ•°æ®ä¸ç°å®åœºæ™¯å­˜åœ¨å·®è·ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šåŸºäºå›¾çš„é‡‡æ ·ç­–ç•¥ï¼ˆGraph - based Sampling strategyï¼‰
è€ƒè™‘å‚æ•°æˆ–è¿”å›å€¼ç›¸ä¼¼çš„å·¥å…·ä¸ºç›¸å…³å·¥å…·ï¼Œæ„å»ºå·¥å…·å›¾ï¼Œå›¾ä¸­èŠ‚ç‚¹ä»£è¡¨å·¥å…·ï¼Œè¾¹è¡¨ç¤ºå·¥å…·å¯¹ä¹‹é—´çš„ç›¸å…³æ€§ã€‚é‡‡æ ·å·¥å…·æ—¶ï¼Œä»å·¥å…·å›¾ä¸­éšæœºé€‰æ‹©å­å›¾ï¼Œä½¿é‡‡æ ·å·¥å…·æ›´æ˜“æœ‰æ•ˆäº¤äº’ï¼Œä¾¿äºç”Ÿæˆå¤æ‚éœ€æ±‚ï¼Œæå‡åˆæˆå·¥å…·è°ƒç”¨éœ€æ±‚çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šè§„åˆ’ç”Ÿæˆç­–ç•¥ï¼ˆPlanned - Generation strategyï¼‰
åœ¨åˆæˆå¯¹è¯å‰ï¼Œè®©LLMåŸºäºé€‰å®šçš„å·¥å…·å­é›†åˆ›å»ºè®¡åˆ’ï¼Œè¯¥è®¡åˆ’å‹¾å‹’å‡ºç”¨æˆ·åœ¨å¯¹è¯æ¯ä¸€è½®éœ€æå‡ºçš„è¯·æ±‚ã€‚æ¨¡å‹æ„å»ºè®¡åˆ’æ—¶ä¸“æ³¨äºå»ºç«‹å¯¹è¯æ¡†æ¶ï¼Œè¿˜å¯å°†éå·¥å…·è°ƒç”¨è¯·æ±‚çº³å…¥è®¡åˆ’ï¼Œå¢å¼ºå¯¹è¯å†…å®¹å¤šæ ·æ€§ï¼Œä¿ƒè¿›è¯é¢˜é—´æ— ç¼è¿‡æ¸¡ï¼Œæé«˜åˆæˆå¯¹è¯çš„è‡ªç„¶æ€§å’Œè¿è´¯æ€§ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
é€šè¿‡æœ‰é€‰æ‹©åœ°ç”Ÿæˆæ— ç›¸å…³æ¨¡å—çš„ç›¸åŒè§„æ¨¡å¯¹è¯ï¼Œå¯¹åŸºäºå›¾çš„é‡‡æ ·å’Œè§„åˆ’ç­–ç•¥è¿›è¡Œå…¨é¢æ¶ˆèç ”ç©¶ã€‚å¯¹æ•°æ®è´¨é‡è¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜ToolFlowèƒ½æœ‰æ•ˆæå‡ç”Ÿæˆå¯¹è¯çš„è‡ªç„¶æ€§ã€è¿è´¯æ€§å’Œå¤šæ ·æ€§ã€‚ä½¿ç”¨ToolFlowç”Ÿæˆçš„8000ä¸ªåˆæˆå¯¹è¯å¯¹LLaMA - 3.1 - 8Bè¿›è¡Œç›‘ç£å¾®è°ƒï¼Œæ¨¡å‹åœ¨ä¿æŒå¼ºå¤§é€šç”¨èƒ½åŠ›çš„åŒæ—¶ï¼Œå·¥å…·è°ƒç”¨æ€§èƒ½å¯åª²ç¾ç”šè‡³è¶…è¶ŠGPT - 4ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
åœ¨å¤§è¯­è¨€æ¨¡å‹å·¥å…·è°ƒç”¨è®­ç»ƒæ•°æ®åˆæˆæ–¹é¢ï¼ŒåŸºäºå›¾çš„é‡‡æ ·ç­–ç•¥ä¸ºé€‰æ‹©ç›¸å…³å·¥å…·æä¾›äº†æ–°çš„æ€è·¯ï¼Œæœ‰åŠ©äºæé«˜åˆæˆæ•°æ®çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ï¼›è§„åˆ’ç”Ÿæˆç­–ç•¥å¯¹äºæå‡åˆæˆå¯¹è¯çš„è‡ªç„¶æ€§å’Œè¿è´¯æ€§æ•ˆæœæ˜¾è‘—ï¼Œè¿™äº›æ–¹æ³•å’Œç­–ç•¥ä¸ºåç»­ç›¸å…³ç ”ç©¶å’Œå®è·µæä¾›äº†æœ‰ç›Šå‚è€ƒï¼Œå¯ç”¨äºæ”¹è¿›å¤§è¯­è¨€æ¨¡å‹å·¥å…·è°ƒç”¨èƒ½åŠ›çš„è®­ç»ƒè¿‡ç¨‹ã€‚
``` 

## apigen-mt--agentic-pipeline-for-multi-turn-data-generation-via-simulated-agent-human-interplay
### Abstract
Training effective AI agents for multi-turn interactions requires
high-quality data that captures realistic human-agent dynamics, yet such data
is scarce and expensive to collect manually. We introduce APIGen-MT, a
two-phase framework that generates verifiable and diverse multi-turn agent
data. In the first phase, our agentic pipeline produces detailed task
blueprints with ground-truth actions, leveraging a committee of LLM reviewers
and iterative feedback loops. These blueprints are then transformed into
complete interaction trajectories through simulated human-agent interplay. We
train a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B
to 70B parameters. Our models outperform frontier models such as GPT-4o and
Claude 3.5 on $\tau$-bench and BFCL benchmarks, with the smaller models
surpassing their larger counterparts, particularly in multi-turn settings,
while maintaining superior consistency across multiple trials. Comprehensive
experiments demonstrate that our verified blueprint-to-details approach yields
high-quality training data, enabling the development of more reliable,
efficient, and capable agents. We open-source 5K synthetic data trajectories
and the trained xLAM-2-fc-r models to advance research in AI agents.
  Models at
https://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4;
Dataset at https://huggingface.co/datasets/Salesforce/APIGen-MT-5k and Website
at https://apigen-mt.github.io
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | APIGen - MTï¼šå¼€å¯å¤šè½®å¯¹è¯æ•°æ®ç”Ÿæˆæ–°å¾ç¨‹

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨å„è¡Œä¸šéœ€æ±‚çš„å¢é•¿ï¼Œå…¶è§’è‰²å·²ä»ç®€å•èŠå¤©æœºå™¨äººæ‹“å±•åˆ°èƒ½æ‰§è¡Œç°å®ä»»åŠ¡çš„æ™ºèƒ½ä½“ã€‚ç„¶è€Œï¼Œè®­ç»ƒæœ‰æ•ˆçš„å¤šè½®äº¤äº’ AI ä»£ç†éœ€è¦é«˜è´¨é‡æ•°æ®æ¥æ•æ‰çœŸå®çš„äººæœºåŠ¨æ€ï¼Œä½†æ­¤ç±»æ•°æ®åœ¨å…¬å…±é¢„è®­ç»ƒè¯­æ–™åº“ä¸­ç¨€ç¼ºï¼Œä¸”æ‰‹åŠ¨æ”¶é›†å’Œæ ‡æ³¨æˆæœ¬é«˜æ˜‚ã€è€—æ—¶ã€‚ç°æœ‰æ–¹æ³•å¦‚ APIGen ä¸»è¦å…³æ³¨å•è½®äº¤äº’ï¼Œæ— æ³•ä½“ç°ç°å®ä¸­å¤šè½®äº¤äº’çš„å¤æ‚æ€§ï¼Œå…¶ä»–æ¶‰åŠå¤šè½®æ–¹é¢çš„æ–¹æ³•åˆç¼ºä¹äººæœºäº¤äº’ï¼Œé«˜è´¨é‡å¤šè½®è½¨è¿¹çš„éªŒè¯å’Œåˆæˆä»æ˜¯éš¾é¢˜ï¼Œè¿™ä¸¥é‡é˜»ç¢äº†ä»£ç†èƒ½åŠ›çš„æå‡ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡º APIGen - MT ä»£ç†æ•°æ®åˆæˆç®¡é“ï¼Œåˆ©ç”¨ç¯å¢ƒæ‰§è¡Œåé¦ˆå’Œè¯„å®¡å§”å‘˜ä¼šç¡®ä¿ç”Ÿæˆçš„å¤šè½®ä»£ç†æ•°æ®çš„é«˜è´¨é‡ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¼€å‘ä¸¤é˜¶æ®µæ¡†æ¶ã€‚ç¬¬ä¸€é˜¶æ®µï¼Œæ•°æ®ä»£ç†åˆ©ç”¨ LLM è¯„å®¡å§”å‘˜ä¼šå’Œè¿­ä»£åé¦ˆå¾ªç¯ç”Ÿæˆå¸¦æœ‰çœŸå®åŠ¨ä½œçš„è¯¦ç»†ä»»åŠ¡ â€œè“å›¾â€ï¼ŒåŒ…æ‹¬é‡‡æ ·ç›¸å…³ APIã€æ”¿ç­–ã€é¢†åŸŸæ•°æ®å’Œç”¨æˆ·è§’è‰²ä»¥åˆ›å»ºæœ‰æ ¹æ®çš„é€šç”¨ä»»åŠ¡é…ç½®ï¼Œå¹¶ä½¿ç”¨åå‘ä»»åŠ¡é‡ç»„å¢å¼ºå¤æ‚æ€§ï¼Œé€šè¿‡æ ¼å¼/æ‰§è¡Œæ£€æŸ¥å’ŒåŸºäºåå°„æœºåˆ¶çš„ LLM å§”å‘˜ä¼šå®¡æŸ¥æ¥éªŒè¯è“å›¾ï¼›ç¬¬äºŒé˜¶æ®µï¼ŒéªŒè¯åçš„è“å›¾é€šè¿‡æ¨¡æ‹Ÿäººæœºäº¤äº’å¼•å¯¼ç”Ÿæˆç°å®çš„å¤šè½®å¯¹è¯ä»£ç†è½¨è¿¹ï¼Œäº§ç”ŸåŒ…å«å¯¹è¯ã€åŠ¨ä½œå’Œç¯å¢ƒåé¦ˆçš„å®Œæ•´äº¤äº’è½¨è¿¹ç”¨äºè®­ç»ƒã€‚

### ğŸ“ˆ å®éªŒç»“æœ
è®­ç»ƒäº†ä¸€ç³»åˆ—å‚æ•°è§„æ¨¡ä» 1B åˆ° 70B çš„ xLAM - 2 - fc - r æ¨¡å‹ã€‚åœ¨ Ï„ - bench å’Œ BFCL åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¿™äº›æ¨¡å‹ä¼˜äº GPT - 4o å’Œ Claude 3.5 ç­‰å‰æ²¿æ¨¡å‹ï¼Œè¾ƒå°çš„æ¨¡å‹åœ¨å¤šè½®è®¾ç½®ä¸­å°¤å…¶è¶…è¶Šäº†è¾ƒå¤§çš„æ¨¡å‹ï¼ŒåŒæ—¶åœ¨å¤šæ¬¡è¯•éªŒä¸­ä¿æŒäº†å“è¶Šçš„ä¸€è‡´æ€§ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **æ•°æ®ç”Ÿæˆæ–¹æ³•**ï¼šAPIGen - MT çš„ä¸¤é˜¶æ®µæ•°æ®ç”Ÿæˆæ¡†æ¶ä¸ºè§£å†³é«˜è´¨é‡å¤šè½®ä»£ç†æ•°æ®ç¨€ç¼ºé—®é¢˜æä¾›äº†æ–°çš„æ€è·¯ï¼Œå…¶åˆ©ç”¨ LLM è¯„å®¡å§”å‘˜ä¼šå’Œè¿­ä»£åé¦ˆå¾ªç¯ç”Ÿæˆä»»åŠ¡è“å›¾çš„æ–¹å¼ï¼Œä»¥åŠé€šè¿‡æ¨¡æ‹Ÿäººæœºäº¤äº’ç”Ÿæˆå®Œæ•´äº¤äº’è½¨è¿¹çš„æ–¹æ³•ï¼Œå¯å¯å‘å…¶ä»–ç ”ç©¶åœ¨æ•°æ®ç”Ÿæˆæ–¹é¢çš„æ¢ç´¢ã€‚
2. **æ¨¡å‹è®­ç»ƒä¸æ€§èƒ½æå‡**ï¼šè®­ç»ƒçš„ xLAM - 2 - fc - r ç³»åˆ—æ¨¡å‹åœ¨åŸºå‡†æµ‹è¯•ä¸­çš„å‡ºè‰²è¡¨ç°è¡¨æ˜ï¼Œä½¿ç”¨é«˜è´¨é‡åˆæˆæ•°æ®èƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹åœ¨å¤šè½®äº¤äº’ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå¯¹äºè¿½æ±‚æ¨¡å‹æ€§èƒ½æå‡çš„ç ”ç©¶å…·æœ‰å€Ÿé‰´æ„ä¹‰ã€‚
3. **å¼€æºè´¡çŒ®**ï¼šå¼€æº 5K é«˜è´¨é‡åˆæˆæ•°æ®ï¼ˆAPIGen - MT - 5kï¼‰å’Œè®­ç»ƒå¥½çš„ xLAM - 2 - fc - r ç³»åˆ—æ¨¡å‹ï¼Œä¸º AI ä»£ç†é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å®è´µçš„èµ„æºï¼Œä¿ƒè¿›äº†è¯¥é¢†åŸŸçš„ç ”ç©¶å‘å±•ï¼Œè¿™ç§å¼€æºç²¾ç¥å€¼å¾—å­¦ä¹ å’Œæ¨å¹¿ã€‚
``` 

## toolace--winning-the-points-of-llm-function-calling
### Abstract
Function calling significantly extends the application boundary of large
language models, where high-quality and diverse training data is critical for
unlocking this capability. However, real function-calling data is quite
challenging to collect and annotate, while synthetic data generated by existing
pipelines tends to lack coverage and accuracy. In this paper, we present
ToolACE, an automatic agentic pipeline designed to generate accurate, complex,
and diverse tool-learning data. ToolACE leverages a novel self-evolution
synthesis process to curate a comprehensive API pool of 26,507 diverse APIs.
Dialogs are further generated through the interplay among multiple agents,
guided by a formalized thinking process. To ensure data accuracy, we implement
a dual-layer verification system combining rule-based and model-based checks.
We demonstrate that models trained on our synthesized data, even with only 8B
parameters, achieve state-of-the-art performance on the Berkeley
Function-Calling Leaderboard, rivaling the latest GPT-4 models. Our model and a
subset of the data are publicly available at https://huggingface.co/Team-ACE.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | ToolACEï¼šè§£é”å¤§è¯­è¨€æ¨¡å‹å‡½æ•°è°ƒç”¨æ–°é«˜åº¦

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å‡½æ•°è°ƒç”¨æå¤§åœ°æ‹“å±•äº†å…¶åº”ç”¨è¾¹ç•Œï¼Œé«˜è´¨é‡ä¸”å¤šæ ·çš„è®­ç»ƒæ•°æ®å¯¹äºè§£é”è¿™ä¸€èƒ½åŠ›è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œæ”¶é›†å’Œæ ‡æ³¨çœŸå®çš„å‡½æ•°è°ƒç”¨æ•°æ®é¢‡å…·æŒ‘æˆ˜ï¼Œç°æœ‰çš„åˆæˆæ•°æ®ç”Ÿæˆç®¡é“äº§ç”Ÿçš„æ•°æ®å¾€å¾€ç¼ºä¹è¦†ç›–èŒƒå›´å’Œå‡†ç¡®æ€§ã€‚å½“å‰å·¥å…·å¢å¼ºçš„LLMsä¸»è¦èšç„¦äºç®€å•çš„å‡½æ•°è°ƒç”¨ä»»åŠ¡ï¼Œå¤šæ ·æ€§å’Œå¤æ‚æ€§æœ‰é™ï¼Œä¸”ä¾èµ–ç°æœ‰å…¬å…±APIè¿›è¡Œä»»åŠ¡æ„å»ºï¼Œé™åˆ¶äº†é›¶æ ·æœ¬èƒ½åŠ›å’Œå¯¹å¤æ‚åœºæ™¯ï¼ˆå¦‚ä¾èµ–æˆ–å¤šè½®äº¤äº’ï¼‰çš„é€‚ç”¨æ€§ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ–°çš„æ–¹æ³•æ¥ç”Ÿæˆå‡†ç¡®ã€å¤šæ ·ä¸”å¤æ‚çš„å‡½æ•°è°ƒç”¨æ•°æ®ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šTool Self - Evolution Synthesisï¼ˆTSSï¼‰æ¨¡å—
æå‡ºä¸€ç§å·¥å…·è‡ªæˆ‘è¿›åŒ–åˆæˆæ–¹æ³•ï¼Œé€šè¿‡ç‰©ç§å½¢æˆã€é€‚åº”å’Œè¿›åŒ–ä¸‰ä¸ªæ­¥éª¤ï¼Œç”Ÿæˆå…·æœ‰å¤šç§æ•°æ®ç±»å‹å’Œçº¦æŸçš„APIå®šä¹‰ã€‚è¯¥æ–¹æ³•ä¸ä¾èµ–å…¬å…±APIï¼Œä»é¢„è®­ç»ƒæ•°æ®å‡ºå‘ï¼Œé€šè¿‡è¿­ä»£çš„è‡ªæˆ‘è¿›åŒ–å’ŒæŒç»­æ›´æ–°ï¼Œæ‰©å±•APIæ± çš„å¤šæ ·æ€§ï¼Œå»ºç«‹äº†ä¸€ä¸ªåŒ…å«26,507ä¸ªå¤šæ ·APIçš„å…¨é¢APIæ± ï¼Œåœ¨æ•°é‡å’Œé¢†åŸŸè¦†ç›–ä¸Šè¶…è¶Šå…¶ä»–ä»£è¡¨æ€§å·¥å…·å¢å¼ºLLMsã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šSelf - Guided Dialog Generationï¼ˆSDGï¼‰æ¨¡å—
æå‡ºè‡ªæˆ‘å¼•å¯¼å¯¹è¯ç”Ÿæˆè¿‡ç¨‹ï¼Œè®©LLMä½œä¸ºè¯„ä¼°å™¨æ¥è°ƒèŠ‚å¤æ‚æ€§ã€‚é€šè¿‡å¤šæ™ºèƒ½ä½“äº¤äº’ï¼Œéµå¾ªè‡ªæˆ‘å¼•å¯¼å¤æ‚åŒ–ç­–ç•¥ï¼Œç”Ÿæˆå››ç§ç±»å‹çš„å‡½æ•°è°ƒç”¨æ•°æ®ï¼Œä½¿æŒ‡ä»¤è·Ÿéšæ•°æ®å…·å¤‡è¶³å¤Ÿçš„å¤æ‚æ€§ä»¥åŸ¹å…»å‡½æ•°è°ƒç”¨æŠ€èƒ½ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šDual - Layer Validation Processï¼ˆDLVï¼‰æ¨¡å—
é‡‡ç”¨åŒå±‚éªŒè¯ç³»ç»Ÿï¼Œé›†æˆåŸºäºè§„åˆ™å’ŒåŸºäºæ¨¡å‹çš„æ£€æŸ¥å™¨ï¼Œä»¥ä¿è¯åˆæˆæ•°æ®çš„å¯æ‰§è¡Œæ€§å’Œä¸€è‡´æ€§ï¼Œç¡®ä¿æ•°æ®å‡†ç¡®æ€§ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨BFCLå’ŒAPIBankä¸¤ä¸ªå¹¿æ³›é‡‡ç”¨çš„åŸºå‡†ä¸Šè¿›è¡Œå®éªŒï¼Œä»…8Bå‚æ•°çš„æ¨¡å‹åœ¨ToolACEåˆæˆæ•°æ®ä¸Šè®­ç»ƒåï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰å¼€æºLLMsï¼Œæ€§èƒ½å¯ä¸æœ€æ–°çš„GPT - 4æ¨¡å‹ç›¸åª²ç¾ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **æ•°æ®ç”Ÿæˆæ–¹æ³•**ï¼šToolACEçš„è‡ªåŠ¨åŒ–æ•°æ®ç”Ÿæˆç®¡é“ä¸ºè§£å†³å‡½æ•°è°ƒç”¨æ•°æ®ç¼ºä¹çš„é—®é¢˜æä¾›äº†æ–°çš„æ€è·¯ï¼Œå…¶è‡ªæˆ‘è¿›åŒ–åˆæˆã€è‡ªæˆ‘å¼•å¯¼å¯¹è¯ç”Ÿæˆå’ŒåŒå±‚éªŒè¯çš„æ–¹æ³•å¯ç”¨äºç”Ÿæˆé«˜è´¨é‡ã€å¤šæ ·åŒ–å’Œå¤æ‚çš„æ•°æ®ï¼Œå¯¹å…¶ä»–ç±»ä¼¼çš„æ•°æ®ç”Ÿæˆä»»åŠ¡æœ‰å€Ÿé‰´æ„ä¹‰ã€‚
2. **å¤æ‚æ€§è°ƒèŠ‚**ï¼šåˆ©ç”¨LLMä½œä¸ºå¤æ‚æ€§è¯„ä¼°å™¨æ¥å¼•å¯¼ç”Ÿæˆæ•°æ®çš„å¤æ‚æ€§ï¼Œè¿™ç§è‡ªæˆ‘å¼•å¯¼çš„æ–¹å¼æœ‰åŠ©äºç”Ÿæˆæ›´ç¬¦åˆæ¨¡å‹å­¦ä¹ éœ€æ±‚çš„æ•°æ®ï¼Œå¯åº”ç”¨äºå…¶ä»–éœ€è¦è°ƒèŠ‚æ•°æ®å¤æ‚æ€§çš„åœºæ™¯ã€‚
3. **å¤šæ™ºèƒ½ä½“åä½œ**ï¼šé€šè¿‡å¤šæ™ºèƒ½ä½“äº¤äº’ç”Ÿæˆå¯¹è¯æ•°æ®ï¼Œå±•ç¤ºäº†å¤šæ™ºèƒ½ä½“åä½œåœ¨æ„å»ºå¤æ‚æ•°æ®æ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºç›¸å…³ç ”ç©¶æä¾›äº†æ–°çš„åä½œæ¨¡å¼å‚è€ƒã€‚
``` 

## toucan--synthesizing-1-5m-tool-agentic-data-from-real-world-mcp-environments
### Abstract
Large Language Model (LLM) agents are rapidly emerging as powerful systems
for automating tasks across domains. Yet progress in the open-source community
is constrained by the lack of high quality permissively licensed tool-agentic
training data. Existing datasets are often limited in diversity, realism, and
complexity, particularly regarding multi-tool and multi-turn interactions. To
address this gap, we introduce Toucan, the largest publicly available
tool-agentic dataset to date, containing 1.5 million trajectories synthesized
from nearly 500 real-world Model Context Protocols (MCPs). Unlike prior work,
Toucan leverages authentic MCP environments to generate diverse, realistic, and
challenging tasks with trajectories involving real tool execution. Our pipeline
first produces a broad spectrum of tool-use queries using five distinct models,
applies model-based quality filtering, and then generates agentic trajectories
with three teacher models using two agentic frameworks. Rigorous rule-based and
model-based validation ensures high-quality outputs. We also introduce three
extension mechanisms to further diversify tasks and simulate multi-turn
conversations. Models fine-tuned on Toucan outperform larger closed-source
counterparts on the BFCL V3 benchmark and push the Pareto frontier forward on
MCP-Universe Bench.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | TOUCANï¼šå¼€å¯å·¥å…· - ä»£ç†æ•°æ®æ–°æ—¶ä»£

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†æ­£è¿…é€Ÿæˆä¸ºè·¨é¢†åŸŸè‡ªåŠ¨åŒ–ä»»åŠ¡çš„å¼ºå¤§ç³»ç»Ÿï¼Œä½†å¼€æºç¤¾åŒºçš„å‘å±•å—åˆ°ç¼ºä¹é«˜è´¨é‡ã€è®¸å¯å®½æ¾çš„å·¥å…· - ä»£ç†è®­ç»ƒæ•°æ®çš„é™åˆ¶ã€‚ç°æœ‰æ•°æ®é›†åœ¨å¤šæ ·æ€§ã€çœŸå®æ€§å’Œå¤æ‚æ€§æ–¹é¢å¾€å¾€å­˜åœ¨å±€é™ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šå·¥å…·å’Œå¤šè½®äº¤äº’æ–¹é¢ã€‚ç›®å‰æ€¥éœ€èƒ½å¤Ÿæ¶µç›–ç”Ÿäº§ç¯å¢ƒä¸­å·¥å…· - ä»£ç†å®Œæ•´äº¤äº’èŒƒå›´çš„é«˜è´¨é‡æ•°æ®é›†ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ„å»ºå¤§è§„æ¨¡çœŸå®æ•°æ®é›†
TOUCANæ˜¯ç›®å‰æœ€å¤§çš„å…¬å¼€å¯ç”¨å·¥å…· - ä»£ç†æ•°æ®é›†ï¼ŒåŒ…å«ä»è¿‘500ä¸ªçœŸå®ä¸–ç•Œçš„æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä¸­åˆæˆçš„150ä¸‡æ¡è½¨è¿¹ã€‚ä¸å…ˆå‰ä¾èµ–æ¨¡æ‹Ÿæˆ–æœ‰é™å·¥å…·é›†çš„æ–¹æ³•ä¸åŒï¼ŒTOUCANåˆ©ç”¨å…·æœ‰2000å¤šç§å·¥å…·çš„çœŸå®MCPç¯å¢ƒï¼Œç”Ÿæˆæ¶µç›–å¹¶è¡Œå’Œå¤šæ­¥éª¤å·¥å…·è°ƒç”¨ä»¥åŠå¤šè½®å¯¹è¯çš„å¤šæ ·åŒ–ã€ç°å®ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç‹¬ç‰¹çš„æ•°æ®ç”Ÿæˆä¸ç­›é€‰æµç¨‹
æ•°æ®ç”Ÿæˆç®¡é“é¦–å…ˆä½¿ç”¨äº”ä¸ªä¸åŒæ¨¡å‹ç”Ÿæˆå¹¿æ³›çš„å·¥å…·ä½¿ç”¨æŸ¥è¯¢ï¼Œåº”ç”¨åŸºäºæ¨¡å‹çš„è´¨é‡è¿‡æ»¤ä»¥ç¡®ä¿ç›¸å…³æ€§å’Œéš¾åº¦ï¼›ç„¶åä½¿ç”¨ä¸‰ä¸ªæ•™å¸ˆæ¨¡å‹å’Œä¸¤ä¸ªä»£ç†æ¡†æ¶ç”Ÿæˆä»£ç†è½¨è¿¹ï¼Œå¹¶é€šè¿‡ä¸¥æ ¼çš„åŸºäºè§„åˆ™å’ŒåŸºäºæ¨¡å‹çš„éªŒè¯æ¥ç¡®ä¿é«˜è´¨é‡è¾“å‡ºï¼ŒåŒ…æ‹¬éªŒè¯å·¥å…·æ‰§è¡Œå’Œå“åº”å‡†ç¡®æ€§ï¼›è¿˜å¼•å…¥äº†ä¸‰ç§æ‰©å±•æœºåˆ¶ï¼Œä»¥è¿›ä¸€æ­¥ä½¿ä»»åŠ¡å¤šæ ·åŒ–å¹¶æ¨¡æ‹Ÿå¤šè½®å¯¹è¯ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨BFCL V3åŸºå‡†æµ‹è¯•ä¸­ï¼Œåœ¨TOUCANä¸Šå¾®è°ƒçš„æ¨¡å‹ä¼˜äºæ›´å¤§çš„é—­æºæ¨¡å‹ï¼Œåœ¨å•è½®å’Œå¤šè½®åœºæ™¯ä¸­çš„å‡½æ•°è°ƒç”¨å‡†ç¡®æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼›åœ¨Ï„ - Benchå’ŒÏ„Â² - Benchä¸Šï¼Œåœ¨å·¥å…·é€‰æ‹©ã€æ‰§è¡Œä¿çœŸåº¦å’ŒåŠ¨æ€ç”¨æˆ·äº¤äº’ä¸‹çš„å¤šè½®æ¨ç†æ–¹é¢æœ‰æ˜¾è‘—æ”¹è¿›ï¼›åœ¨MCP - UniverseåŸºå‡†æµ‹è¯•ä¸­ï¼ŒTOUCANå¾®è°ƒçš„æ¨¡å‹åœ¨å…¶å‚æ•°ç±»åˆ«ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå§‹ç»ˆä¼˜äºå¯æ¯”è§„æ¨¡çš„é¢†å…ˆæ¨¡å‹ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **æ•°æ®é›†æ„å»ºæ€è·¯**ï¼šåˆ©ç”¨çœŸå®ç¯å¢ƒç”Ÿæˆæ•°æ®ï¼Œä¸ºæ„å»ºé«˜è´¨é‡ã€å¤§è§„æ¨¡ä¸”å…·æœ‰å¤šæ ·æ€§çš„æ•°æ®é›†æä¾›äº†æ–°çš„æ€è·¯ï¼Œæœ‰åŠ©äºè§£å†³è®­ç»ƒæ•°æ®ç¼ºä¹çœŸå®æ€§å’Œå¤šæ ·æ€§çš„é—®é¢˜ã€‚
2. **æ•°æ®ç”Ÿæˆä¸ç­›é€‰æµç¨‹**ï¼šå¤šé˜¶æ®µçš„æ•°æ®ç”Ÿæˆå’Œä¸¥æ ¼çš„éªŒè¯æµç¨‹ï¼Œä¿è¯äº†æ•°æ®çš„è´¨é‡å’Œç›¸å…³æ€§ï¼Œè¿™ç§æµç¨‹è®¾è®¡å¯åº”ç”¨äºå…¶ä»–ç±»ä¼¼çš„æ•°æ®ç”Ÿæˆä»»åŠ¡ä¸­ã€‚
3. **æ¨¡å‹å¾®è°ƒæ•ˆæœ**ï¼šåœ¨TOUCANä¸Šå¾®è°ƒæ¨¡å‹çš„è‰¯å¥½è¡¨ç°ï¼Œè¯æ˜äº†è¯¥æ•°æ®é›†å¯¹æå‡æ¨¡å‹åœ¨å·¥å…· - ä»£ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½å…·æœ‰æ˜¾è‘—ä½œç”¨ï¼Œä¸ºæ¨¡å‹è®­ç»ƒæä¾›äº†ä¼˜è´¨çš„æ•°æ®èµ„æºå‚è€ƒã€‚
``` 

## autodata--a-multi-agent-system-for-open-web-data-collection
### Abstract
The exponential growth of data-driven systems and AI technologies has
intensified the demand for high-quality web-sourced datasets. While existing
datasets have proven valuable, conventional web data collection approaches face
significant limitations in terms of human effort and scalability. Current
data-collecting solutions fall into two categories: wrapper-based methods that
struggle with adaptability and reproducibility, and large language model
(LLM)-based approaches that incur substantial computational and financial
costs. To address these challenges, we propose AutoData, a novel multi-agent
system for Automated web Data collection, that requires minimal human
intervention, i.e., only necessitating a natural language instruction
specifying the desired dataset. In addition, AutoData is designed with a robust
multi-agent architecture, featuring a novel oriented message hypergraph
coordinated by a central task manager, to efficiently organize agents across
research and development squads. Besides, we introduce a novel hypergraph cache
system to advance the multi-agent collaboration process that enables efficient
automated data collection and mitigates the token cost issues prevalent in
existing LLM-based systems. Moreover, we introduce Instruct2DS, a new benchmark
dataset supporting live data collection from web sources across three domains:
academic, finance, and sports. Comprehensive evaluations over Instruct2DS and
three existing benchmark datasets demonstrate AutoData's superior performance
compared to baseline methods. Case studies on challenging tasks such as picture
book collection and paper extraction from surveys further validate its
applicability. Our source code and dataset are available at
https://github.com/GraphResearcher/AutoData.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | AutoDataï¼šå¼€å¯è‡ªåŠ¨ç½‘ç»œæ•°æ®æ”¶é›†æ–°æ—¶ä»£

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
æ•°æ®æ˜¯ç°ä»£ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ™ºèƒ½ç³»ç»Ÿçš„é©±åŠ¨åŠ›ï¼Œé«˜è´¨é‡çš„ç½‘ç»œæºæ•°æ®é›†éœ€æ±‚æ—¥ç›Šå¢é•¿ã€‚ä¸‡ç»´ç½‘æˆä¸ºå¤§è§„æ¨¡æ•°æ®è·å–çš„é»˜è®¤æ¥æºï¼Œå·²æœ‰ç½‘ç»œæºæ•°æ®æ¨åŠ¨äº†å¤šé¢†åŸŸç ”ç©¶ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿç½‘ç»œæ•°æ®æ”¶é›†æ–¹æ³•å­˜åœ¨æ˜¾è‘—å±€é™ï¼šåŸºäºåŒ…è£…å™¨çš„æ–¹æ³•é€‚åº”æ€§å’Œå¯é‡å¤æ€§å·®ï¼›åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–¹æ³•è®¡ç®—å’Œè´¢åŠ¡æˆæœ¬é«˜ã€‚æ­¤å¤–ï¼Œç¼ºä¹ç”¨äºè¯„ä¼°å¼€æ”¾ç½‘ç»œæ•°æ®æ”¶é›†ä»»åŠ¡æ¨¡å‹æ€§èƒ½çš„åŸºå‡†æ•°æ®é›†ï¼Œç°æœ‰ç›¸å…³åŸºå‡†æ•°æ®é›†å¤šåŸºäºé™æ€å’Œå­˜æ¡£ç½‘é¡µï¼Œæ— æ³•æµ‹è¯•å¼€æ”¾ç½‘ç»œæ•°æ®æ”¶é›†ã€‚å› æ­¤ï¼Œéœ€è¦æ„å»ºä¸€ä¸ªç«¯åˆ°ç«¯çš„å…¨è‡ªåŠ¨å¼€æ”¾ç½‘ç»œæ•°æ®æ”¶é›†ç³»ç»Ÿï¼Œä»¥å…¼é¡¾è¦†ç›–èŒƒå›´ã€å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ–°é¢–çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
å¼€å‘äº†å…¨è‡ªåŠ¨å¤šæ™ºèƒ½ä½“ç³»ç»ŸAutoDataï¼Œç”±å…«ä¸ªä¸“ä¸šæ™ºèƒ½ä½“å’Œæ–°é¢–çš„æœ‰å‘è¶…å›¾ç¼“å­˜ç³»ç»Ÿï¼ˆOHCacheï¼‰ç»„æˆã€‚AutoDataåœ¨ä¸­å¤®ä»»åŠ¡ç®¡ç†å™¨ï¼ˆMGRï¼‰ä¸‹åè°ƒç ”ç©¶å’Œå¼€å‘ä¸¤ä¸ªä¸“ä¸šæ™ºèƒ½ä½“å°ç»„ã€‚ç ”ç©¶å°ç»„çš„æ™ºèƒ½ä½“æ ¹æ®è¾“å…¥æŒ‡ä»¤æµè§ˆç½‘é¡µç”Ÿæˆå¼€å‘è“å›¾ï¼Œå¼€å‘å°ç»„åˆ™å°†è“å›¾è½¬åŒ–ä¸ºå¯æ‰§è¡Œä»£ç å¹¶è¿è¡Œè·å–æ‰€éœ€æ•°æ®é›†ã€‚OHCacheåŒ…æ‹¬æœ‰å‘æ¶ˆæ¯è¶…å›¾ï¼ˆå°†æ™ºèƒ½ä½“é—´æ¶ˆæ¯æµå»ºæ¨¡ä¸ºæœ‰å‘è¶…è¾¹ï¼‰ã€æœ‰å‘è¶…è¾¹æ ¼å¼åŒ–å™¨ï¼ˆå¼ºåˆ¶ç»“æ„åŒ–é€šä¿¡æ¨¡å¼å’Œè¶…è¾¹æ¶ˆæ¯ç§¯ç´¯ï¼‰å’Œæœ¬åœ°ç¼“å­˜ç³»ç»Ÿï¼ˆå­˜å‚¨å¯é‡ç”¨å·¥ä»¶ä¾›æ™ºèƒ½ä½“æŒ‰éœ€æ£€ç´¢ï¼‰ï¼Œä»¥å®ç°é«˜æ•ˆçš„å¤šæ™ºèƒ½ä½“åä½œã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæ–°çš„åŸºå‡†æ•°æ®é›†
å¼•å…¥æ–°æ”¶é›†çš„åŸºå‡†æ•°æ®é›†Instruct2DSï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºè¯„ä¼°å¼€æ”¾ç½‘ç»œæ•°æ®æ”¶é›†ä»»åŠ¡æ¨¡å‹æ€§èƒ½çš„åŸºå‡†æ•°æ®é›†ï¼Œæ¶µç›–å­¦æœ¯ã€é‡‘èå’Œä½“è‚²ä¸‰ä¸ªé¢†åŸŸï¼Œæ”¯æŒä»ç½‘ç»œæºè¿›è¡Œå®æ—¶æ•°æ®æ”¶é›†ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨Instruct2DSå’Œä¸‰ä¸ªç°æœ‰åŸºå‡†æ•°æ®é›†ï¼ˆSWDEã€EXTENDED WSDEå’ŒHUMANEVALï¼‰ä¸Šå¯¹AutoDataå’ŒåŸºçº¿æ–¹æ³•è¿›è¡Œäº†å…¨é¢å®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒAutoDataåœ¨å¼€æ”¾ç½‘ç»œæ•°æ®æ”¶é›†ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜äºåŸºçº¿æ–¹æ³•çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€æ•ˆç‡å’Œé€‚ç”¨æ€§ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹å¦‚ç»˜æœ¬æ”¶é›†å’Œè°ƒæŸ¥è®ºæ–‡æå–ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡è¿›è¡Œçš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶é€‚ç”¨æ€§å’Œå³æ’å³ç”¨çš„é€‚åº”æ€§ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **å¤šæ™ºèƒ½ä½“åä½œæ¨¡å¼**ï¼šAutoDataçš„å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ä¸ºè§£å†³å¤æ‚çš„æ•°æ®æ”¶é›†ä»»åŠ¡æä¾›äº†æ–°çš„æ€è·¯ï¼Œå¯åº”ç”¨äºå…¶ä»–éœ€è¦å¤šæ™ºèƒ½ä½“ååŒçš„åœºæ™¯ï¼Œå¦‚å¤æ‚çš„ä¿¡æ¯æ£€ç´¢ã€è‡ªåŠ¨åŒ–è½¯ä»¶å¼€å‘ç­‰ã€‚
2. **ç¼“å­˜ç³»ç»Ÿè®¾è®¡**ï¼šOHCacheçš„è®¾è®¡æœ‰æ•ˆé™ä½äº†åŸºäºLLMæ–¹æ³•çš„ä»¤ç‰Œæˆæœ¬é—®é¢˜ï¼Œå¯¹äºåœ¨èµ„æºå—é™æƒ…å†µä¸‹æé«˜ç³»ç»Ÿæ•ˆç‡å…·æœ‰å€Ÿé‰´æ„ä¹‰ï¼Œå¯åº”ç”¨äºå…¶ä»–ä¾èµ–å¤§è¯­è¨€æ¨¡å‹ä¸”å¯¹æˆæœ¬æ•æ„Ÿçš„åº”ç”¨ä¸­ã€‚
3. **åŸºå‡†æ•°æ®é›†æ„å»º**ï¼šInstruct2DSçš„æ„å»ºä¸ºè¯„ä¼°å¼€æ”¾ç½‘ç»œæ•°æ®æ”¶é›†ä»»åŠ¡æ¨¡å‹æä¾›äº†æ ‡å‡†ï¼Œå¯¹äºå…¶ä»–æ–°å…´ç ”ç©¶é¢†åŸŸï¼Œæ„å»ºé’ˆå¯¹æ€§çš„åŸºå‡†æ•°æ®é›†æœ‰åŠ©äºæ¨åŠ¨è¯¥é¢†åŸŸçš„ç ”ç©¶è¿›å±•å’Œæ¨¡å‹æ€§èƒ½è¯„ä¼°ã€‚
``` 

## agent-data-protocol--unifying-datasets-for-diverse--effective-fine-tuning-of-llm-agents
### Abstract
Public research results on large-scale supervised finetuning of AI agents
remain relatively rare, since the collection of agent training data presents
unique challenges. In this work, we argue that the bottleneck is not a lack of
underlying data sources, but that a large variety of data is fragmented across
heterogeneous formats, tools, and interfaces. To this end, we introduce the
agent data protocol (ADP), a light-weight representation language that serves
as an "interlingua" between agent datasets in diverse formats and unified agent
training pipelines downstream. The design of ADP is expressive enough to
capture a large variety of tasks, including API/tool use, browsing, coding,
software engineering, and general agentic workflows, while remaining simple to
parse and train on without engineering at a per-dataset level. In experiments,
we unified a broad collection of 13 existing agent training datasets into ADP
format, and converted the standardized ADP data into training-ready formats for
multiple agent frameworks. We performed SFT on these data, and demonstrated an
average performance gain of ~20% over corresponding base models, and delivers
state-of-the-art or near-SOTA performance on standard coding, browsing, tool
use, and research benchmarks, without domain-specific tuning. All code and data
are released publicly, in the hope that ADP could help lower the barrier to
standardized, scalable, and reproducible agent training.
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | ADPï¼šå¼€å¯å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è®­ç»ƒæ ‡å‡†åŒ–æ–°æ—¶ä»£

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é¢„è®­ç»ƒå¾—ç›Šäºä¸°å¯Œçš„äº’è”ç½‘è§„æ¨¡æ•°æ®ï¼Œä½†åè®­ç»ƒé˜¶æ®µè·å–é«˜è´¨é‡ç‰¹å®šä»»åŠ¡æ•°æ®é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æ™ºèƒ½ä½“åº”ç”¨åœºæ™¯ä¸­ã€‚æ™ºèƒ½ä½“éœ€é‡‡å–é¡ºåºè¡ŒåŠ¨å¹¶ä¸ä¸–ç•Œè¿­ä»£äº¤äº’ï¼Œæ„å»ºæ­¤ç±»åœºæ™¯çš„æ•°æ®é›†éœ€è®°å½•å’Œæ„å»ºæ™ºèƒ½ä½“è¡Œä¸ºè½¨è¿¹ï¼Œæ¯”æ”¶é›†é™æ€è¾“å…¥ - è¾“å‡ºå¯¹å›°éš¾å¾—å¤šã€‚å°½ç®¡å·²æœ‰å¤šç§åˆ›å»ºæ™ºèƒ½ä½“æ•°æ®é›†çš„æ–¹æ³•ä¸”æ•°æ®é›†æ¶µç›–å¹¿æ³›ä»»åŠ¡ï¼Œä½†å¤§è§„æ¨¡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åœ¨å­¦æœ¯ç ”ç©¶ä¸­ä»è¾ƒä¸ºç½•è§ã€‚åŸå› å¹¶éç¼ºä¹æ•°æ®ï¼Œè€Œæ˜¯ç°æœ‰æ•°æ®é›†æ ¼å¼å’Œè¡¨ç¤ºä¸ä¸€è‡´ï¼Œç¢ç‰‡åŒ–ä¸¥é‡ï¼Œéš¾ä»¥æœ‰æ•ˆç»„åˆã€å…±äº«å’Œåˆ©ç”¨ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºæ™ºèƒ½ä½“æ•°æ®åè®®ï¼ˆADPï¼‰
ADPæ˜¯ä¸€ç§è½»é‡çº§è¡¨ç¤ºè¯­è¨€ï¼Œä½œä¸ºä¸åŒæ ¼å¼çš„æ™ºèƒ½ä½“æ•°æ®é›†ä¸ç»Ÿä¸€çš„ä¸‹æ¸¸æ™ºèƒ½ä½“è®­ç»ƒç®¡é“ä¹‹é—´çš„â€œä¸­é—´è¯­è¨€â€ã€‚å®ƒä»¥Pydanticæ¨¡å¼å®ç°ï¼Œè¡¨è¾¾å¯¹åº”å¸¸è§æ™ºèƒ½ä½“ç”¨ä¾‹ï¼ˆå¦‚é€šä¿¡ã€æµè§ˆã€ç¼–ç å’Œå„ç§å·¥å…·è°ƒç”¨ï¼‰çš„è¡ŒåŠ¨å’Œè§‚å¯Ÿï¼Œå¹¶é€šè¿‡ä¸¥æ ¼çš„è‡ªåŠ¨éªŒè¯ç»´æŒé«˜æ•°æ®è´¨é‡ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå®ç°æ•°æ®é›†è½¬æ¢ä¸æ„å»º
å®ç°äº†å°†13ä¸ªç°æœ‰æ•°æ®é›†è½¬æ¢ä¸ºADPæ ¼å¼çš„è½¬æ¢å™¨ï¼Œä»¥åŠä»ADPåˆ°3ç§ä¸åŒæ™ºèƒ½ä½“æ¶æ„çš„è½¬æ¢å™¨ï¼Œå±•ç¤ºäº†å…¶é€šç”¨æ€§ã€‚åŸºäºæ­¤åˆ›å»ºå¹¶å‘å¸ƒäº†æœ€å¤§çš„å…¬å¼€å¯ç”¨æ™ºèƒ½ä½“è®­ç»ƒæ•°æ®é›†ADP Dataset V1ï¼ŒåŒ…å«130ä¸‡ä¸ªè®­ç»ƒè½¨è¿¹ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
ä½¿ç”¨ADPè®­ç»ƒæ™ºèƒ½ä½“åœ¨å¤šä¸ªé¢†åŸŸå¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡ï¼ŒåŒ…æ‹¬ç¼–ç ï¼ˆSWE - Bench Verifiedï¼‰ã€ç½‘é¡µæµè§ˆï¼ˆWebArenaï¼‰ã€ç ”ç©¶ï¼ˆGAIAï¼‰å’Œæ™ºèƒ½ä½“å·¥å…·ä½¿ç”¨ï¼ˆAgentBenchï¼‰ç­‰ï¼Œå¹³å‡æ€§èƒ½æ¯”ç›¸åº”åŸºç¡€æ¨¡å‹æé«˜çº¦20%ï¼Œåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æˆ–æ¥è¿‘å½“å‰æœ€ä¼˜æ°´å¹³ã€‚åŒæ—¶ï¼Œè·¨ä»»åŠ¡è¿ç§»ä¹Ÿæœ‰æ˜¾è‘—æ”¶ç›Šï¼Œåœ¨ADPæ•°æ®ä¸Šè®­ç»ƒæ¯”åœ¨å•ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒæœ‰æ˜æ˜¾æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒADPè¿˜æ”¯æŒç³»ç»Ÿçš„è·¨æ•°æ®é›†åˆ†æï¼Œæ­ç¤ºå…¬å¼€å¯ç”¨æ•°æ®çš„è¶‹åŠ¿å’Œæ”¹è¿›æ–¹å‘ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ADPä¸ºæ™ºèƒ½ä½“è®­ç»ƒæ•°æ®çš„æ ‡å‡†åŒ–æä¾›äº†æœ‰æ•ˆè§£å†³æ–¹æ¡ˆï¼Œé™ä½äº†å¤§è§„æ¨¡ç›‘ç£æ™ºèƒ½ä½“è®­ç»ƒçš„é—¨æ§›ï¼Œä½¿å…¶æ›´å…·å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚å…¶é€šç”¨çš„è½¬æ¢æœºåˆ¶å’Œé«˜è´¨é‡çš„æ•°æ®è¡¨ç¤ºæ–¹å¼ï¼Œå¯¹äºæ•´åˆå’Œåˆ©ç”¨å¤šæ ·åŒ–çš„æ™ºèƒ½ä½“æ•°æ®é›†å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚æ­¤å¤–ï¼Œå…¬å¼€ä»£ç å’Œæ•°æ®é›†çš„åšæ³•æœ‰åŠ©äºç¤¾åŒºçš„é‡‡ç”¨å’Œæ–°æ•°æ®é›†çš„è´¡çŒ®ï¼Œæ¨åŠ¨æ™ºèƒ½ä½“æ¨¡å‹å¾®è°ƒçš„è¿›ä¸€æ­¥å‘å±•ã€‚
``` 

## cognitive-kernel-pro--a-framework-for-deep-research-agents-and-agent-foundation-models-training
### Abstract
General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro
```
### ğŸŒŸ è®ºæ–‡è§£è¯» | Cognitive Kernel - Proï¼šå¼€å¯å¼€æºæ™ºèƒ½ä½“ç ”ç©¶æ–°å¾ç¨‹

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
é€šç”¨äººå·¥æ™ºèƒ½ä½“æ­£é€æ¸æˆä¸ºä¸‹ä¸€ä»£äººå·¥æ™ºèƒ½çš„åŸºç¡€æ¡†æ¶ï¼Œå…·å¤‡å¤æ‚æ¨ç†ã€ç½‘é¡µäº¤äº’ã€ç¼–ç å’Œè‡ªä¸»ç ”ç©¶ç­‰èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ™ºèƒ½ä½“ç³»ç»Ÿè¦ä¹ˆæ˜¯é—­æºçš„ï¼Œè¦ä¹ˆä¸¥é‡ä¾èµ–å„ç§ä»˜è´¹APIå’Œä¸“æœ‰å·¥å…·ï¼Œè¿™é™åˆ¶äº†ç ”ç©¶ç¤¾åŒºçš„å¯è®¿é—®æ€§å’Œå¯é‡å¤æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†Cognitive Kernel - Proï¼Œä¸€ä¸ªå®Œå…¨å¼€æºä¸”ï¼ˆå°½å¯èƒ½ï¼‰å…è´¹çš„å¤šæ¨¡å—æ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨æ¨åŠ¨å…ˆè¿›äººå·¥æ™ºèƒ½ä½“çš„å¼€å‘å’Œè¯„ä¼°çš„æ°‘ä¸»åŒ–ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå¼€æºå¤šæ¨¡å—æ™ºèƒ½ä½“æ¡†æ¶
æå‡ºCognitive Kernel - Proæ¡†æ¶ï¼Œé‡‡ç”¨ä¸¤å±‚å¤šæ¨¡å—æ¶æ„ï¼Œç”±è´Ÿè´£ä»»åŠ¡åˆ†è§£ã€å­ä»»åŠ¡å§”æ´¾å’Œä¿¡æ¯èšåˆç­‰çš„ä¸»æ™ºèƒ½ä½“ï¼Œä»¥åŠè§£å†³ä¸»æ™ºèƒ½ä½“åˆ†é…çš„å­ä»»åŠ¡çš„å¤šä¸ªå­æ™ºèƒ½ä½“ç»„æˆã€‚ä¸»æ™ºèƒ½ä½“å’Œå­æ™ºèƒ½ä½“éƒ½ç»§æ‰¿è‡ªåŒä¸€åŸºç±»ï¼Œè¾“å…¥ä¸ºä»»åŠ¡å­—ç¬¦ä¸²ï¼Œè¾“å‡ºä¸ºå“åº”å­—ç¬¦ä¸²ï¼Œä¸­é—´åŠ¨ä½œä»¥Pythonä»£ç å½¢å¼æ‰§è¡Œã€‚è¯¥æ¡†æ¶ä»¥Pythonä»£ç ä½œä¸ºåŠ¨ä½œç©ºé—´ï¼Œå……åˆ†åˆ©ç”¨ç°ä»£å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†å’Œä»£ç ç”Ÿæˆæ½œåŠ›ï¼Œå¼ºè°ƒæ™ºèƒ½ä½“åŸºç¡€æ¨¡å‹çš„å†…åœ¨èƒ½åŠ›ï¼Œå‡å°‘å¯¹ä¸“æœ‰å·¥å…·çš„ä¾èµ–ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå…¨é¢çš„è®­ç»ƒæ–¹æ³•
å¼•å…¥é’ˆå¯¹Cognitive Kernel - Proçš„å…¨é¢è®­ç»ƒæ–¹æ³•ï¼Œæ¶µç›–ç½‘é¡µå¯¼èˆªã€æ–‡ä»¶å¤„ç†ã€ä»£ç ç”Ÿæˆå’Œæ¨ç†ç­‰å¤šä¸ªé¢†åŸŸã€‚æ„å»ºå¯éªŒè¯çš„æ™ºèƒ½ä½“æŸ¥è¯¢ - ç­”æ¡ˆå¯¹ï¼Œç¡®ä¿é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚é€šè¿‡çº³å…¥ä¸­é—´è¿‡ç¨‹æç¤ºå’ŒåŸºäºæç¤ºçš„æ‹’ç»é‡‡æ ·æ¥å¢å¼ºæ•°æ®æ”¶é›†ï¼Œæ˜¾è‘—æé«˜æ”¶é›†æ•°æ®çš„è´¨é‡å’Œç›¸å…³æ€§ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šæ¨ç†æ—¶é—´ä¼˜åŒ–æŠ€æœ¯
æ¢ç´¢æ¨ç†æ—¶é—´ä¼˜åŒ–æŠ€æœ¯ï¼Œä»¥åº”å¯¹ç½‘é¡µæµè§ˆç­‰ä»»åŠ¡ä¸­å›ºæœ‰çš„éšæœºæ€§ã€‚æå‡ºé›†æˆé‡è¯•æœºåˆ¶å’ŒåŸºäºé›†æˆçš„å¤šæ¬¡è¿è¡Œç­–ç•¥çš„ç®¡é“ï¼Œæé«˜Cognitive Kernel - Proæ€§èƒ½çš„å¯é æ€§å’Œä¸€è‡´æ€§ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨GAIAä¸Šå¯¹Cognitive Kernel - Proè¿›è¡Œè¯„ä¼°ï¼Œåœ¨å¼€æºå’Œå…è´¹æ™ºèƒ½ä½“ä¸­å–å¾—äº†é¢†å…ˆçš„ç»“æœã€‚å…¶8Bå‚æ•°çš„å¼€æºæ¨¡å‹è¶…è¶Šäº†ä¹‹å‰çš„é¢†å…ˆç³»ç»Ÿï¼Œå¦‚WebDancerå’ŒWebSailorï¼Œä¸ºå¯è®¿é—®çš„ã€é«˜èƒ½åŠ›çš„äººå·¥æ™ºèƒ½ä½“å»ºç«‹äº†æ–°çš„æ€§èƒ½æ ‡å‡†ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **å¼€æºç†å¿µ**ï¼šCognitive Kernel - Proçš„å®Œå…¨å¼€æºç‰¹æ€§ä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä¸€ä¸ªå¯è®¿é—®å’Œå¯å¤ç”¨çš„æ™ºèƒ½ä½“å¼€å‘å¹³å°ï¼Œé™ä½äº†ç ”ç©¶é—¨æ§›ï¼Œä¿ƒè¿›äº†ç¤¾åŒºå†…çš„åˆä½œä¸åˆ›æ–°ã€‚
2. **è®­ç»ƒæ–¹æ³•**ï¼šç³»ç»Ÿåœ°æ„å»ºå’Œä¼˜åŒ–è®­ç»ƒæ•°æ®çš„æ–¹æ³•ï¼Œå¦‚æ„å»ºå¯éªŒè¯çš„æŸ¥è¯¢ - ç­”æ¡ˆå¯¹ã€åˆ©ç”¨ä¸­é—´è¿‡ç¨‹æç¤ºç­‰ï¼Œå¯¹äºæé«˜æ™ºèƒ½ä½“çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›å…·æœ‰é‡è¦çš„å€Ÿé‰´æ„ä¹‰ã€‚
3. **æ¶æ„è®¾è®¡**ï¼šåˆ†å±‚å¤šæ¨¡å—çš„æ™ºèƒ½ä½“æ¶æ„è®¾è®¡ï¼Œæ—¢ä¿è¯äº†æ™ºèƒ½ä½“åŠŸèƒ½çš„æ¨¡å—åŒ–å’Œå¯æ‰©å±•æ€§ï¼Œåˆç®€åŒ–äº†ç‰¹å®šä»»åŠ¡è®­ç»ƒæ•°æ®çš„æ”¶é›†ï¼Œä¸ºæ™ºèƒ½ä½“çš„è®¾è®¡å’Œå¼€å‘æä¾›äº†æ–°çš„æ€è·¯ã€‚
``` 

