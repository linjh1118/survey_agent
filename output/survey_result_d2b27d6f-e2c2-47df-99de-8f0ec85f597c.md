# Paper List of Terms(entropy+LLM)
- [25/09] **Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning**  
[[Paper](http://arxiv.org/pdf/2509.03646v1)] [[Code/Page]()] [[TLDR/Notes](#emergent-hierarchical-reasoning-in-llms-through-reinforcement-learning)]

- [25/09] **On Entropy Control in LLM-RL Algorithms**  
[[Paper](http://arxiv.org/pdf/2509.03493v1)] [[Code/Page]()] [[TLDR/Notes](#on-entropy-control-in-llm-rl-algorithms)]

- [25/09] **Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR**  
[[Paper](http://arxiv.org/pdf/2509.02522v1)] [[Code/Page](https://github.com/ritzz-ai/PACS.)] [[TLDR/Notes](#implicit-actor-critic-coupling-via-a-supervised-learning-framework-for-rlvr)]

- [25/09] **Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation**  
[[Paper](http://arxiv.org/pdf/2509.02510v1)] [[Code/Page](https://github.com/ErfanBaghaei/Top-H-Decoding.)] [[TLDR/Notes](#top-h-decoding--adapting-the-creativity-and-coherence-with-bounded-entropy-in-text-generation)]

- [25/09] **Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning**  
[[Paper](http://arxiv.org/pdf/2509.02401v1)] [[Code/Page]()] [[TLDR/Notes](#towards-agents-that-know-when-they-don-t-know--uncertainty-as-a-control-signal-for-structured-reasoning)]

- [25/09] **Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate**  
[[Paper](http://arxiv.org/pdf/2509.04492v1)] [[Code/Page]()] [[TLDR/Notes](#learned-hallucination-detection-in-black-box-llms-using-token-level-entropy-production-rate)]

- [25/09] **TECP: Token-Entropy Conformal Prediction for LLMs**  
[[Paper](http://arxiv.org/pdf/2509.00461v2)] [[Code/Page]()] [[TLDR/Notes](#tecp--token-entropy-conformal-prediction-for-llms)]

- [25/08] **From Canonical to Complex: Benchmarking LLM Capabilities in Undergraduate Thermodynamics**  
[[Paper](http://arxiv.org/pdf/2508.21452v1)] [[Code/Page]()] [[TLDR/Notes](#from-canonical-to-complex--benchmarking-llm-capabilities-in-undergraduate-thermodynamics)]

- [25/08] **GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation**  
[[Paper](http://arxiv.org/pdf/2508.20757v2)] [[Code/Page](https://github.com/YecanLee/GUARD.)] [[TLDR/Notes](#guard--glocal-uncertainty-aware-robust-decoding-for-effective-and-efficient-open-ended-text-generation)]

- [25/08] **Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning**  
[[Paper](http://arxiv.org/pdf/2508.20697v1)] [[Code/Page]()] [[TLDR/Notes](#token-buncher--shielding-llms-from-harmful-reinforcement-learning-fine-tuning)]

- [25/08] **SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM**  
[[Paper](http://arxiv.org/pdf/2508.20514v1)] [[Code/Page]()] [[TLDR/Notes](#scitopic--enhancing-topic-discovery-in-scientific-literature-through-advanced-llm)]

- [25/08] **Automated Quality Assessment for LLM-Based Complex Qualitative Coding: A Confidence-Diversity Framework**  
[[Paper](http://arxiv.org/pdf/2508.20462v1)] [[Code/Page]()] [[TLDR/Notes](#automated-quality-assessment-for-llm-based-complex-qualitative-coding--a-confidence-diversity-framework)]

- [25/08] **Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction**  
[[Paper](http://arxiv.org/pdf/2508.20395v1)] [[Code/Page]()] [[TLDR/Notes](#measuring-reasoning-utility-in-llms-via-conditional-entropy-reduction)]

- [25/08] **Uncertainty Under the Curve: A Sequence-Level Entropy Area Metric for Reasoning LLM**  
[[Paper](http://arxiv.org/pdf/2508.20384v1)] [[Code/Page]()] [[TLDR/Notes](#uncertainty-under-the-curve--a-sequence-level-entropy-area-metric-for-reasoning-llm)]

- [25/09] **Pre-trained knowledge elevates large language models beyond traditional chemical reaction optimizers**  
[[Paper](http://arxiv.org/pdf/2509.00103v1)] [[Code/Page](https://gomes.andrew.cmu.edu/iron-mind),)] [[TLDR/Notes](#pre-trained-knowledge-elevates-large-language-models-beyond-traditional-chemical-reaction-optimizers)]

- [25/08] **NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks**  
[[Paper](http://arxiv.org/pdf/2508.19724v2)] [[Code/Page]()] [[TLDR/Notes](#nlki--a-lightweight-natural-language-knowledge-integration-framework-for-improving-small-vlms-in-commonsense-vqa-tasks)]

- [25/09] **Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck**  
[[Paper](http://arxiv.org/pdf/2509.03533v1)] [[Code/Page]()] [[TLDR/Notes](#topic-identification-in-llm-input-output-pairs-through-the-lens-of-information-bottleneck)]

- [25/08] **HAEPO: History-Aggregated Exploratory Policy Optimization**  
[[Paper](http://arxiv.org/pdf/2508.18884v1)] [[Code/Page]()] [[TLDR/Notes](#haepo--history-aggregated-exploratory-policy-optimization)]

- [25/08] **CoCoA: Confidence and Context-Aware Adaptive Decoding for Resolving Knowledge Conflicts in Large Language Models**  
[[Paper](http://arxiv.org/pdf/2508.17670v2)] [[Code/Page]()] [[TLDR/Notes](#cocoa--confidence-and-context-aware-adaptive-decoding-for-resolving-knowledge-conflicts-in-large-language-models)]

- [25/08] **Risk Assessment and Security Analysis of Large Language Models**  
[[Paper](http://arxiv.org/pdf/2508.17329v1)] [[Code/Page]()] [[TLDR/Notes](#risk-assessment-and-security-analysis-of-large-language-models)]

- [25/08] **DeAR: Dual-Stage Document Reranking with Reasoning Agents via LLM Distillation**  
[[Paper](http://arxiv.org/pdf/2508.16998v1)] [[Code/Page](https://github.com/DataScienceUIBK/DeAR-Reranking.}.)] [[TLDR/Notes](#dear--dual-stage-document-reranking-with-reasoning-agents-via-llm-distillation)]

- [25/08] **From Confidence to Collapse in LLM Factual Robustness**  
[[Paper](http://arxiv.org/pdf/2508.16267v2)] [[Code/Page]()] [[TLDR/Notes](#from-confidence-to-collapse-in-llm-factual-robustness)]

- [25/08] **The Fools are Certain; the Wise are Doubtful: Exploring LLM Confidence in Code Completion**  
[[Paper](http://arxiv.org/pdf/2508.16131v1)] [[Code/Page]()] [[TLDR/Notes](#the-fools-are-certain;-the-wise-are-doubtful--exploring-llm-confidence-in-code-completion)]

- [25/08] **From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence**  
[[Paper](http://arxiv.org/pdf/2508.15447v1)] [[Code/Page]()] [[TLDR/Notes](#from-bits-to-boardrooms--a-cutting-edge-multi-agent-llm-framework-for-business-excellence)]

- [25/08] **Recall-Extend Dynamics: Enhancing Small Language Models through Controlled Exploration and Refined Offline Integration**  
[[Paper](http://arxiv.org/pdf/2508.16677v1)] [[Code/Page]()] [[TLDR/Notes](#recall-extend-dynamics--enhancing-small-language-models-through-controlled-exploration-and-refined-offline-integration)]

- [25/08] **Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats**  
[[Paper](http://arxiv.org/pdf/2508.19263v1)] [[Code/Page]()] [[TLDR/Notes](#lossless-compression-of-neural-network-components--weights--checkpoints--and-k/v-caches-in-low-precision-formats)]

- [25/08] **Entropy-Constrained Strategy Optimization in Urban Floods: A Multi-Agent Framework with LLM and Knowledge Graph Integration**  
[[Paper](http://arxiv.org/pdf/2508.14654v1)] [[Code/Page]()] [[TLDR/Notes](#entropy-constrained-strategy-optimization-in-urban-floods--a-multi-agent-framework-with-llm-and-knowledge-graph-integration)]

- [25/08] **Semantic Energy: Detecting LLM Hallucination Beyond Entropy**  
[[Paper](http://arxiv.org/pdf/2508.14496v2)] [[Code/Page]()] [[TLDR/Notes](#semantic-energy--detecting-llm-hallucination-beyond-entropy)]

- [25/08] **Measuring LLM Code Generation Stability via Structural Entropy**  
[[Paper](http://arxiv.org/pdf/2508.14288v1)] [[Code/Page]()] [[TLDR/Notes](#measuring-llm-code-generation-stability-via-structural-entropy)]

- [25/08] **Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR**  
[[Paper](http://arxiv.org/pdf/2508.14029v2)] [[Code/Page]()] [[TLDR/Notes](#beyond-pass@1--self-play-with-variational-problem-synthesis-sustains-rlvr)]

- [25/08] **AdapSNE: Adaptive Fireworks-Optimized and Entropy-Guided Dataset Sampling for Edge DNN Training**  
[[Paper](http://arxiv.org/pdf/2508.16647v1)] [[Code/Page]()] [[TLDR/Notes](#adapsne--adaptive-fireworks-optimized-and-entropy-guided-dataset-sampling-for-edge-dnn-training)]

- [25/08] **Improving Detection of Watermarked Language Models**  
[[Paper](http://arxiv.org/pdf/2508.13131v1)] [[Code/Page]()] [[TLDR/Notes](#improving-detection-of-watermarked-language-models)]

- [25/08] **J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs**  
[[Paper](http://arxiv.org/pdf/2508.12086v1)] [[Code/Page]()] [[TLDR/Notes](#j6--jacobian-driven-role-attribution-for-multi-objective-prompt-optimization-in-llms)]

- [25/08] **CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures**  
[[Paper](http://arxiv.org/pdf/2508.11915v1)] [[Code/Page](https://github.com/psyonp/core.)] [[TLDR/Notes](#core--measuring-multi-agent-llm-interaction-quality-under-game-theoretic-pressures)]

- [25/08] **Can We Tell if ChatGPT is a Parasite? Studying Human-AI Symbiosis with Game Theory**  
[[Paper](http://arxiv.org/pdf/2508.11359v1)] [[Code/Page]()] [[TLDR/Notes](#can-we-tell-if-chatgpt-is-a-parasite--studying-human-ai-symbiosis-with-game-theory)]

- [25/08] **ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism**  
[[Paper](http://arxiv.org/pdf/2508.11356v2)] [[Code/Page]()] [[TLDR/Notes](#ettrl--balancing-exploration-and-exploitation-in-llm-test-time-reinforcement-learning-via-entropy-mechanism)]

- [25/08] **CURE: Critical-Token-Guided Re-Concatenation for Entropy-Collapse Prevention**  
[[Paper](http://arxiv.org/pdf/2508.11016v2)] [[Code/Page](https://github.com/bytedance/CURE.)] [[TLDR/Notes](#cure--critical-token-guided-re-concatenation-for-entropy-collapse-prevention)]

- [25/08] **KL-based self-distillation for large language models**  
[[Paper](http://arxiv.org/pdf/2508.15807v1)] [[Code/Page]()] [[TLDR/Notes](#kl-based-self-distillation-for-large-language-models)]

- [25/08] **Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models**  
[[Paper](http://arxiv.org/pdf/2508.10192v1)] [[Code/Page]()] [[TLDR/Notes](#prompt-response-semantic-divergence-metrics-for-faithfulness-hallucination-and-misalignment-detection-in-large-language-models)]

- [25/08] **Provable In-Context Vector Arithmetic via Retrieving Task Concepts**  
[[Paper](http://arxiv.org/pdf/2508.09820v1)] [[Code/Page]()] [[TLDR/Notes](#provable-in-context-vector-arithmetic-via-retrieving-task-concepts)]

- [25/08] **Trapping, chaos and averaging in bubbling AdS spaces**  
[[Paper](http://arxiv.org/pdf/2508.09669v1)] [[Code/Page]()] [[TLDR/Notes](#trapping--chaos-and-averaging-in-bubbling-ads-spaces)]

- [25/08] **Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation**  
[[Paper](http://arxiv.org/pdf/2508.09666v2)] [[Code/Page]()] [[TLDR/Notes](#slow-tuning-and-low-entropy-masking-for-safe-chain-of-thought-distillation)]

- [25/08] **Selective KV-Cache Sharing to Mitigate Timing Side-Channels in LLM Inference**  
[[Paper](http://arxiv.org/pdf/2508.08438v1)] [[Code/Page]()] [[TLDR/Notes](#selective-kv-cache-sharing-to-mitigate-timing-side-channels-in-llm-inference)]

- [25/08] **From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR**  
[[Paper](http://arxiv.org/pdf/2508.07534v2)] [[Code/Page]()] [[TLDR/Notes](#from-trial-and-error-to-improvement--a-systematic-analysis-of-llm-exploration-mechanisms-in-rlvr)]

- [25/08] **Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models**  
[[Paper](http://arxiv.org/pdf/2508.14062v1)] [[Code/Page]()] [[TLDR/Notes](#assessing-and-mitigating-data-memorization-risks-in-fine-tuned-large-language-models)]

- [25/08] **Bridging Classical and Quantum Computing for Next-Generation Language Models**  
[[Paper](http://arxiv.org/pdf/2508.07026v1)] [[Code/Page]()] [[TLDR/Notes](#bridging-classical-and-quantum-computing-for-next-generation-language-models)]

- [25/08] **AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance**  
[[Paper](http://arxiv.org/pdf/2508.06944v2)] [[Code/Page](https://github.com/hlxtsyj/AMFT.)] [[TLDR/Notes](#amft--aligning-llm-reasoners-by-meta-learning-the-optimal-imitation-exploration-balance)]

- [25/08] **BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation**  
[[Paper](http://arxiv.org/pdf/2508.06781v1)] [[Code/Page]()] [[TLDR/Notes](#bixse--improving-dense-retrieval-via-probabilistic-graded-relevance-distillation)]

- [25/08] **Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees**  
[[Paper](http://arxiv.org/pdf/2508.05544v1)] [[Code/Page]()] [[TLDR/Notes](#conformal-sets-in-multiple-choice-question-answering-under-black-box-settings-with-provable-coverage-guarantees)]

- [25/08] **SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens**  
[[Paper](http://arxiv.org/pdf/2508.05305v1)] [[Code/Page]()] [[TLDR/Notes](#sonar-llm--autoregressive-transformer-that-thinks-in-sentence-embeddings-and-speaks-in-tokens)]



# TLDR/Notes
## emergent-hierarchical-reasoning-in-llms-through-reinforcement-learning
### Abstract
Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.
### ğŸŒŸ è®ºæ–‡è§£è¯» | å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ ä¸­æ¶Œç°çš„åˆ†å±‚æ¨ç†ï¼šä»æœºåˆ¶åˆ°é«˜æ•ˆç®—æ³•

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¤æ‚æ¨ç†èƒ½åŠ›ä¸Šå·²è¢«è¯æ˜ååˆ†æœ‰æ•ˆï¼Œä½†èƒŒåé©±åŠ¨æˆåŠŸçš„æœºåˆ¶å´ä»ä¸æ˜æ™°ã€‚è®­ç»ƒä¸­å‡ºç°çš„ â€œé¡¿æ‚Ÿæ—¶åˆ»ï¼ˆaha momentsï¼‰â€â€œé•¿åº¦ç¼©æ”¾ï¼ˆlength - scalingï¼‰â€ ä»¥åŠç†µåŠ¨æ€ç­‰ç°è±¡ï¼Œæ­¤å‰ç¼ºä¹ç»Ÿä¸€ç†è§£ã€‚åŒæ—¶ï¼Œç°æœ‰ä¸»æµ RL ç®—æ³•ï¼ˆå¦‚ GRPOï¼‰å­˜åœ¨æ ¸å¿ƒä½æ•ˆé—®é¢˜ï¼šæ— å·®åˆ«æ–½åŠ ä¼˜åŒ–å‹åŠ›ï¼Œç¨€é‡Šäº†å¯¹å…³é”® token çš„å­¦ä¹ ä¿¡å·ã€‚æœ¬æ–‡æ—¨åœ¨æ­ç¤º RL æå‡ LLM æ¨ç†èƒ½åŠ›çš„å†…åœ¨æœºåˆ¶ï¼Œå¹¶è®¾è®¡æ›´é«˜æ•ˆçš„ RL ç®—æ³•ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ­ç¤ºæ¶Œç°çš„æ¨ç†åˆ†å±‚æœºåˆ¶  
ç ”ç©¶å‘ç°ï¼ŒRL è¿‡ç¨‹ä¸­ LLM æ¨ç†èƒ½åŠ›æå‡å¹¶éå•ä¸€è¿‡ç¨‹ï¼Œè€Œæ˜¯æ¶Œç°å‡ºç±»ä¼¼äººç±»è®¤çŸ¥ä¸­ â€œé«˜å±‚æˆ˜ç•¥è§„åˆ’ + ä½å±‚æµç¨‹æ‰§è¡Œâ€ åˆ†ç¦»çš„æ¨ç†åˆ†å±‚ç»“æ„ï¼Œä¸”å­¦ä¹ å­˜åœ¨ä¸¤é˜¶æ®µåŠ¨æ€ï¼šåˆå§‹é˜¶æ®µå—é™äºæµç¨‹æ­£ç¡®æ€§ï¼Œéœ€æå‡ä½å±‚æ‰§è¡ŒæŠ€èƒ½ï¼›ä¹‹åå­¦ä¹ ç“¶é¢ˆè½¬ç§»ï¼Œé«˜å±‚æˆ˜ç•¥è§„åˆ’çš„æ¢ç´¢ä¸æŒæ¡æˆä¸ºæ€§èƒ½æå‡å…³é”®ã€‚è¿™ä¸€æœºåˆ¶ç»Ÿä¸€è§£é‡Šäº† â€œé¡¿æ‚Ÿæ—¶åˆ»â€ï¼ˆå¯¹åº”é«˜å±‚æˆ˜ç•¥æ¨ç†ç­–ç•¥çš„å‘ç°ä¸å†…åŒ–ï¼‰ã€â€œé•¿åº¦ç¼©æ”¾â€ï¼ˆæ›´å¤æ‚æˆ˜ç•¥å¸¦æ¥æ›´ç»“æ„åŒ–ã€æ›´é•¿çš„æ¨ç†è½¨è¿¹ï¼‰ç­‰æ­¤å‰è´¹è§£çš„ç°è±¡ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæå‡ºåˆ†å±‚æ„ŸçŸ¥ä¿¡ç”¨åˆ†é…ç®—æ³• HICRA  
é‰´äºç°æœ‰ç®—æ³•ï¼ˆå¦‚ GRPOï¼‰æ— å·®åˆ«ä¼˜åŒ–å¯¼è‡´ä½æ•ˆï¼Œæå‡º HIerarchy - Aware Credit Assignmentï¼ˆHICRAï¼‰ã€‚è¯¥ç®—æ³•å°†ä¼˜åŒ–åŠªåŠ›é›†ä¸­äºé«˜å½±å“åŠ›çš„ â€œè§„åˆ’ tokenâ€ï¼ˆå³é©±åŠ¨é«˜å±‚æˆ˜ç•¥æ¨ç†çš„ tokenï¼‰ï¼Œé’ˆå¯¹æ€§å¼ºåŒ–é«˜å±‚æˆ˜ç•¥æ¨ç†èƒ½åŠ›çš„æ¢ç´¢ä¸å·©å›ºï¼Œè§£å†³æˆ˜ç•¥ç“¶é¢ˆé—®é¢˜ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šéªŒè¯è¯­ä¹‰ç†µä½œä¸ºæ›´ä¼˜åº¦é‡æŒ‡æ ‡  
æŒ‡å‡ºä¼ ç»Ÿ token çº§ç†µç­‰æŒ‡æ ‡æ˜“è¯¯å¯¼ï¼ŒéªŒè¯äº†è¯­ä¹‰ç†µä½œä¸ºè¡¡é‡æˆ˜ç•¥æ¢ç´¢æ›´ä¼˜ â€œæŒ‡å—é’ˆâ€ çš„æœ‰æ•ˆæ€§ï¼Œä¸ºè¯„ä¼° LLM æˆ˜ç•¥æ¨ç†æ¢ç´¢æä¾›æ›´å¯é æ–¹å¼ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
æ–‡ä¸­é€šè¿‡å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHICRA åœ¨å¤šæ¨¡å‹ä¸å¤šåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶Šå¼ºåŸºçº¿æ–¹æ³•ï¼Œè¯æ˜èšç„¦æˆ˜ç•¥ç“¶é¢ˆå¯¹è§£é”é«˜çº§æ¨ç†èƒ½åŠ›çš„å…³é”®ä½œç”¨ï¼›åŒæ—¶éªŒè¯äº†è¯­ä¹‰ç†µç›¸æ¯” token çº§ç†µç­‰ä¼ ç»ŸæŒ‡æ ‡ï¼Œåœ¨è¡¡é‡æˆ˜ç•¥æ¢ç´¢æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. æœºåˆ¶ç†è§£å±‚é¢ï¼šè®¤è¯†åˆ° LLM æ¨ç†èƒ½åŠ›æå‡çš„ä¸¤é˜¶æ®µåˆ†å±‚åŠ¨æ€ï¼Œä¸ºç†è§£æ¨¡å‹è®­ç»ƒä¸­å„ç±»ç°è±¡ï¼ˆå¦‚é¡¿æ‚Ÿã€é•¿åº¦ç¼©æ”¾ï¼‰æä¾›ç»Ÿä¸€æ¡†æ¶ï¼Œåç»­ç ”ç©¶å¯åŸºäºæ­¤æ›´æ·±å…¥å‰–ææ¨¡å‹å­¦ä¹ è¿‡ç¨‹ã€‚  
2. ç®—æ³•è®¾è®¡å±‚é¢ï¼šHICRA èšç„¦å…³é”®åˆ†å±‚ç»„ä»¶ï¼ˆè§„åˆ’ tokenï¼‰ä¼˜åŒ–çš„æ€è·¯ï¼Œä¸ºè®¾è®¡æ›´é«˜æ•ˆ RL ç®—æ³•æä¾›èŒƒå¼ï¼Œå¯å¯å‘é’ˆå¯¹ä¸åŒä»»åŠ¡ã€ä¸åŒæ¨¡å‹ç»“æ„çš„å®šåˆ¶åŒ–ä¿¡ç”¨åˆ†é…ç­–ç•¥ã€‚  
3. åº¦é‡æŒ‡æ ‡å±‚é¢ï¼šè¯­ä¹‰ç†µçš„æœ‰æ•ˆæ€§éªŒè¯ï¼Œæç¤ºåœ¨è¯„ä¼°æ¨¡å‹æˆ˜ç•¥æ¨ç†ã€æ¢ç´¢ç­‰èƒ½åŠ›æ—¶ï¼Œéœ€å…³æ³¨æ›´è´´åˆè¯­ä¹‰ä¸é«˜å±‚è¡Œä¸ºçš„æŒ‡æ ‡ï¼Œé¿å…ä¼ ç»Ÿç»†ç²’åº¦ä½†æ˜“è¯¯å¯¼çš„æŒ‡æ ‡å±€é™ã€‚

## on-entropy-control-in-llm-rl-algorithms
### Abstract
For RL algorithms, appropriate entropy control is crucial to their
effectiveness. To control the policy entropy, a commonly used method is entropy
regularization, which is adopted in various popular RL algorithms including
PPO, SAC and A3C. Although entropy regularization proves effective in robotic
and games RL conventionally, studies found that it gives weak to no gains in
LLM-RL training. In this work, we study the issues of entropy bonus in LLM-RL
setting. Specifically, we first argue that the conventional entropy
regularization suffers from the LLM's extremely large response space and the
sparsity of the optimal outputs. As a remedy, we propose AEnt, an entropy
control method that utilizes a new clamped entropy bonus with an automatically
adjusted coefficient. The clamped entropy is evaluated with the re-normalized
policy defined on certain smaller token space, which encourages exploration
within a more compact response set. In addition, the algorithm automatically
adjusts entropy coefficient according to the clamped entropy value, effectively
controlling the entropy-induced bias while leveraging the entropy's benefits.
AEnt is tested in math-reasoning tasks under different base models and
datasets, and it is observed that AEnt outperforms the baselines consistently
across multiple benchmarks.
### ğŸŒŸ è®ºæ–‡è§£è¯» | LLMå¼ºåŒ–å­¦ä¹ ä¸­ç†µæ§åˆ¶çš„æ–°çªç ´ï¼šAEntæ–¹æ³•

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç®—æ³•é‡Œï¼Œåˆé€‚çš„ç†µæ§åˆ¶å¯¹ç®—æ³•æœ‰æ•ˆæ€§è‡³å…³é‡è¦ï¼Œç†µæ­£åˆ™åŒ–æ˜¯å¸¸ç”¨æ§åˆ¶ç­–ç•¥ç†µçš„æ–¹æ³•ï¼Œåœ¨PPOã€SACã€A3Cç­‰ç»å…¸RLç®—æ³•ä¸­å¹¿æ³›åº”ç”¨ä¸”æ•ˆæœæ˜¾è‘—ï¼Œèƒ½åœ¨æœºå™¨äººã€æ¸¸æˆç­‰RLåœºæ™¯é‡ŒåŠ©åŠ›ç­–ç•¥æ¢ç´¢é¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚ä½†åœ¨å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ ï¼ˆLLM - RLï¼‰è®­ç»ƒä¸­ï¼Œä¼ ç»Ÿç†µæ­£åˆ™åŒ–å´æ”¶æ•ˆç”šå¾®ç”šè‡³æ²¡å¢ç›Šã€‚åŸå› åœ¨äºLLMå­˜åœ¨æå¤§çš„å“åº”ç©ºé—´ä»¥åŠæœ€ä¼˜è¾“å‡ºç¨€ç–æ€§ï¼Œä¼ ç»Ÿç†µæ­£åˆ™åŒ–éš¾ä»¥åº”å¯¹ã€‚æ‰€ä»¥ï¼Œæ·±å…¥ç ”ç©¶LLM - RLåœºæ™¯ä¸‹ç†µå¥–åŠ±é—®é¢˜å¹¶æå‡ºæ”¹è¿›æ–¹æ³•å¾ˆæœ‰å¿…è¦ï¼Œè¿™å°±æ˜¯æœ¬æ–‡çš„åŠ¨æœºã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šLLM - RLä¸­ç†µæ•ˆåº”çš„ç†è®ºåˆ†æ
ä»ç†è®ºå±‚é¢å‰–æLLM - RLè®­ç»ƒä¸­ç†µçš„ä½œç”¨åŠé—®é¢˜ã€‚æ— ç†µå¥–åŠ±æ—¶ï¼Œè¯æ˜ç†µåå¡Œæ„å‘³ç€å­¦ä¹ åœæ»å¹¶ç»™å‡ºæ€§èƒ½è¾¹ç•Œï¼›è¿˜è¡¨æ˜å› LLMä»»åŠ¡ä¸­æœ€ä¼˜å“åº”ç¨€ç–æ€§å¸¦æ¥è‡ªè¯±å¯¼åå·®ï¼Œä¼ ç»Ÿç†µæ­£åˆ™åŒ–éš¾ä»¥æ”¹å–„å­¦ä¹ ç»“æœï¼Œè§£é‡Šäº†ä¼ ç»Ÿç†µæ­£åˆ™åŒ–åœ¨LLM - RLé‡Œæ•ˆæœä¸ä½³çš„ç¼˜ç”±ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæå‡ºAEntç†µæ§åˆ¶æ–¹æ³•
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæå‡ºAEntæ–¹æ³•ã€‚å…¶ä¸€ï¼Œé‡‡ç”¨åŸºäºç¼©å°åçš„tokenç©ºé—´ä¸Šé‡æ–°å½’ä¸€åŒ–ç­–ç•¥æ¥å®šä¹‰çš„â€œclamped entropyï¼ˆå—é™ç†µï¼‰â€ï¼Œè¯¥å—é™ç†µä»…åœ¨åˆç†å“åº”é›†åˆä¸Šå¯¹ç­–ç•¥è¿›è¡Œå¹³æ»‘ï¼Œç›¸æ¯”åŸå§‹ç†µåå·®æ›´å°ï¼Œèƒ½é¼“åŠ±åœ¨æ›´ç´§å‡‘å“åº”é›†åˆå†…æ¢ç´¢ï¼›å…¶äºŒï¼ŒAEntä¾æ®å—é™ç†µå€¼è‡ªåŠ¨è°ƒæ•´ç†µç³»æ•°ï¼Œåœ¨åˆ©ç”¨ç†µçš„ç›Šå¤„åŒæ—¶æœ‰æ•ˆæ§åˆ¶ç†µè¯±å¯¼çš„åå·®ï¼Œè®©ç†µæ­£åˆ™åŒ–åœ¨LLM - RLä¸­çœŸæ­£å‘æŒ¥ä½œç”¨ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨ä¸åŒåŸºç¡€æ¨¡å‹å’Œæ•°æ®é›†ä¸‹çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­æµ‹è¯•AEntã€‚ç»“æœæ˜¾ç¤ºï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­AEntæŒç»­è¶…è¶ŠåŸºçº¿æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨LLM - RLä»»åŠ¡ä¸­ç†µæ§åˆ¶çš„æœ‰æ•ˆæ€§ä»¥åŠå¯¹ä»»åŠ¡æ€§èƒ½æå‡çš„ä½œç”¨ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. ç†è®ºåˆ†æè§’åº¦ï¼šæœ¬æ–‡ä»ç†è®ºå±‚é¢æ·±å…¥åˆ†æLLM - RLä¸­ç†µçš„ä½œç”¨æœºåˆ¶ä¸ä¼ ç»Ÿæ–¹æ³•å¤±æ•ˆåŸå› ï¼Œä¸ºåç»­ç ”ç©¶LLMä¸RLç»“åˆæ—¶çš„å„ç±»æœºåˆ¶æä¾›äº†ç†è®ºåˆ†æçš„æ€è·¯èŒƒå¼ï¼Œå¯å‘ç ”ç©¶è€…å…³æ³¨åœºæ™¯ç‰¹æ€§ï¼ˆå¦‚LLMå¤§å“åº”ç©ºé—´ã€ç¨€ç–æœ€ä¼˜è¾“å‡ºï¼‰å¯¹ç»å…¸RLæŠ€æœ¯çš„å½±å“ã€‚
2. æ–¹æ³•åˆ›æ–°è§’åº¦ï¼šAEntä¸­é’ˆå¯¹å¤§ç©ºé—´å’Œç¨€ç–æ€§è®¾è®¡å—é™ç†µä»¥åŠè‡ªåŠ¨è°ƒæ•´ç³»æ•°çš„æ€è·¯ï¼Œå¯å€Ÿé‰´åˆ°å…¶ä»–éœ€å¤„ç†â€œå¤§åŠ¨ä½œç©ºé—´ + ç¨€ç–ä¼˜è´¨è§£â€åœºæ™¯çš„RLä»»åŠ¡ä¸­ï¼Œæ¯”å¦‚ä¸€äº›å¤æ‚å¤šæ¨¡æ€ç”Ÿæˆã€é•¿æ–‡æœ¬ç”Ÿæˆç±»ç»“åˆRLä¼˜åŒ–çš„ä»»åŠ¡ï¼Œä¸ºåº”å¯¹ç±»ä¼¼åœºæ™¯ä¸‹çš„ç†µæ§åˆ¶ç”šè‡³æ˜¯ç­–ç•¥æ­£åˆ™åŒ–æä¾›äº†æ–°æ–¹æ³•æ–¹å‘ã€‚
3. å®éªŒéªŒè¯è§’åº¦ï¼šåœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ï¼ˆæ•°å­¦æ¨ç†ï¼‰ç»“åˆå¤šæ¨¡å‹å¤šæ•°æ®é›†éªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ï¼Œè¿™ç§èšç„¦ç‰¹å®šæœ‰æŒ‘æˆ˜åœºæ™¯éªŒè¯çš„æ–¹å¼ï¼Œä¹Ÿä¸ºç®—æ³•ç±»ç ”ç©¶éªŒè¯æä¾›äº†å‚è€ƒï¼Œå³é€‰æ‹©èƒ½å‡¸æ˜¾æ–¹æ³•ä¼˜åŠ¿å’Œåœºæ™¯ç—›ç‚¹çš„ä»»åŠ¡æ¥å……åˆ†æ£€éªŒåˆ›æ–°ç‚¹ã€‚

## implicit-actor-critic-coupling-via-a-supervised-learning-framework-for-rlvr
### Abstract
Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have
empowered large language models (LLMs) to tackle challenging reasoning tasks
such as mathematics and programming. RLVR leverages verifiable outcome rewards
to guide policy optimization, enabling LLMs to progressively improve output
quality in a grounded and reliable manner. Despite its promise, the RLVR
paradigm poses significant challenges, as existing methods often suffer from
sparse reward signals and unstable policy gradient updates, particularly in
RL-based approaches. To address the challenges, we propose $\textbf{PACS}$, a
novel RLVR framework that achieves im$\textbf{P}$licit $\textbf{A}$ctor
$\textbf{C}$ritic coupling via a $\textbf{S}$upervised learning framework. By
treating the outcome reward as a predictable label, we reformulate the RLVR
problem into a supervised learning task over a score function parameterized by
the policy model and optimized using cross-entropy loss. A detailed gradient
analysis shows that this supervised formulation inherently recovers the
classical policy gradient update while implicitly coupling actor and critic
roles, yielding more stable and efficient training. Benchmarking on challenging
mathematical reasoning tasks, PACS outperforms strong RLVR baselines, such as
PPO and GRPO, achieving superior reasoning performance. For instance, PACS
achieves 59.78\% at pass@256 on AIME 2025, representing improvements of 13.32
and 14.36 points over PPO and GRPO. This simple yet powerful framework offers a
promising avenue for LLMs post-training with verifiable rewards. Our code and
data are available as open source at https://github.com/ritzz-ai/PACS.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ç”¨ç›‘ç£å­¦ä¹ é‡æ„RLVRï¼šPACSæ¡†æ¶å®ç°éšå¼Actor - Criticè€¦åˆ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨å¼ºåŒ–å­¦ä¹ ç»“åˆå¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰çš„é¢†åŸŸï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½èƒ½å€ŸåŠ©å¯éªŒè¯ç»“æœå¥–åŠ±ä¼˜åŒ–ç­–ç•¥ï¼Œåœ¨æ•°å­¦ã€ç¼–ç¨‹ç­‰æ¨ç†ä»»åŠ¡ä¸­å–å¾—è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•å­˜åœ¨æ˜æ˜¾ç¼ºé™·ã€‚åŸºäºRLçš„RLVRæ–¹æ³•å¸¸å—ç¨€ç–å¥–åŠ±ä¿¡å·å›°æ‰°ï¼Œå¯¼è‡´ä¿¡ç”¨åˆ†é…å’Œæ¢¯åº¦ä¼ æ’­å›°éš¾ï¼›åŸºäºä»·å€¼æ¨¡å‹çš„æ–¹æ³•ï¼ˆå¦‚PPOï¼‰è™½ç”¨ä»·å€¼æ¨¡å‹ä¼°è®¡ä¼˜åŠ¿ï¼Œä½†å¢åŠ äº†æ¨¡å‹å¤æ‚åº¦ä¸è®¡ç®—å¼€é”€ï¼›æ— ä»·å€¼æ¨¡å‹çš„æ–¹æ³•ï¼ˆå¦‚GRPOï¼‰ä¾èµ–è’™ç‰¹å¡æ´›ä¼°è®¡ç›¸å¯¹å¥–åŠ±ï¼Œæ–¹å·®é«˜ï¼Œæ˜“å‡ºç°ä¼˜åŠ¿å´©æºƒã€è®­ç»ƒä¸ç¨³å®šå’Œæ€§èƒ½ä¸‹é™ç­‰é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºPACSæ¡†æ¶ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå°†RLVRé‡æ„ä¸ºç›‘ç£å­¦ä¹ ä»»åŠ¡  
PACSæŠŠRLVRé—®é¢˜é‡æ–°å®šä¹‰ä¸ºç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼Œä¸å†ä¾èµ–ç¨€ç–çš„ç»“æœå¥–åŠ±é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ç­–ç•¥ï¼Œè€Œæ˜¯å°†ç»“æœå¥–åŠ±è§†ä¸ºç›‘ç£ä¿¡å·ï¼Œè®­ç»ƒç”±ç­–ç•¥æ¨¡å‹å‚æ•°åŒ–çš„åˆ†æ•°å‡½æ•°ï¼Œé€šè¿‡äº¤å‰ç†µæŸå¤±æ¥é¢„æµ‹è¯¥å¥–åŠ±ã€‚è¿™æ ·å°±æŠŠåŸæœ¬RLèŒƒå¼ä¸‹çš„æŒ‘æˆ˜è½¬åŒ–ä¸ºæ›´æ˜“å¤„ç†çš„ç›‘ç£å­¦ä¹ åœºæ™¯ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šéšå¼è€¦åˆActor - Criticå¹¶æ¢å¤ç­–ç•¥æ¢¯åº¦æ›´æ–°  
é€šè¿‡æ¢¯åº¦åˆ†æè¡¨æ˜ï¼Œè¯¥ç›‘ç£å­¦ä¹ å½¢å¼ä¸ä»…èƒ½æ¢å¤ç»å…¸çš„ç­–ç•¥æ¢¯åº¦æ›´æ–°ï¼Œè¿˜èƒ½åœ¨å•æ¬¡æ›´æ–°ä¸­éšå¼åœ°è€¦åˆActorï¼ˆç­–ç•¥æ”¹è¿›ï¼‰å’ŒCriticï¼ˆå¥–åŠ±ä¼°è®¡ï¼‰è§’è‰²ã€‚ä¸ä¼ ç»ŸActor - Criticæ–¹æ³•ç»´æŠ¤å•ç‹¬ä»·å€¼å‡½æ•°ä¼°è®¡å™¨ä¸åŒï¼ŒPACSé‡‡ç”¨å…±äº«å‚æ•°åŒ–ï¼Œè®©ä¸¤ä¸ªè§’è‰²é€šè¿‡ç»Ÿä¸€å­¦ä¹ ä¿¡å·è”åˆæ›´æ–°ï¼Œæ¶ˆé™¤äº†å¥–åŠ±ä¼°è®¡å’Œç­–ç•¥æ›´æ–°ä¹‹é—´çš„æ—¶é—´ä¸åŒ¹é…é—®é¢˜ï¼Œæå‡è®­ç»ƒæ•ˆç‡ï¼›åŒæ—¶ç›¸æ¯”æ— ä»·å€¼æ¨¡å‹æ–¹æ³•ä¾èµ–é«˜æ–¹å·®è’™ç‰¹å¡æ´›ä¼°è®¡ï¼ŒPACSåˆ©ç”¨åŸºäºé¢„æµ‹è¯¯å·®çš„å­¦ä¹ ä¿¡å·ï¼Œä¸ºä¼˜åŒ–æä¾›æ›´ç¨³å®šå¯é çš„æŒ‡å¯¼ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦æ¨ç†ä»»åŠ¡åŸºå‡†æµ‹è¯•ä¸­ï¼ŒPACSè¡¨ç°ä¼˜äºå¼ºRLVRåŸºçº¿ï¼ˆå¦‚PPOå’ŒGRPOï¼‰ã€‚ä¾‹å¦‚åœ¨AIME 2025ä»»åŠ¡ä¸­ï¼ŒPACSåœ¨pass@256æŒ‡æ ‡ä¸Šè¾¾åˆ°59.78%ï¼Œç›¸æ¯”PPOå’ŒGRPOåˆ†åˆ«æå‡13.32å’Œ14.36ä¸ªç™¾åˆ†ç‚¹ã€‚æ¶ˆèå®éªŒè¯å®äº†åŠ æƒæœºåˆ¶çš„å…³é”®é‡è¦æ€§ï¼Œè®­ç»ƒåŠ¨æ€åˆ†ææ˜¾ç¤ºPACSåœ¨æ¢ç´¢ - åˆ©ç”¨å¹³è¡¡æ–¹é¢è¡¨ç°æ›´ä¼˜ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
PACSä¸ºå¤§è¯­è¨€æ¨¡å‹åœ¨å¯éªŒè¯å¥–åŠ±ä¸‹çš„è®­ç»ƒæä¾›äº†ç®€æ´ä¸”å¼ºå¤§çš„æ¡†æ¶æ€è·¯ï¼Œè¯æ˜äº†å°†RLé—®é¢˜é‡æ„ä¸ºç›‘ç£å­¦ä¹ ä»»åŠ¡åœ¨å¤„ç†ç¨€ç–å¥–åŠ±ç­‰RLVRç—›ç‚¹æ—¶çš„æœ‰æ•ˆæ€§ï¼›å…¶å…±äº«å‚æ•°åŒ–éšå¼è€¦åˆActor - Criticçš„è®¾è®¡ï¼Œä¸ºåç»­ä¼˜åŒ–ç­–ç•¥å­¦ä¹ ä¸å¥–åŠ±ä¼°è®¡çš„èåˆæ–¹å¼æä¾›äº†å‚è€ƒï¼Œåœ¨è¿½æ±‚è®­ç»ƒç¨³å®šæ€§ä¸æ•ˆç‡çš„LLMsè®­ç»ƒæ–¹å‘ä¸Šå…·æœ‰å€Ÿé‰´æ„ä¹‰ï¼ŒåŒæ—¶å¼€æºä»£ç ä¹Ÿä¸ºç›¸å…³ç ”ç©¶è€…å¤ç°å’Œæ‹“å±•å·¥ä½œæä¾›äº†ä¾¿åˆ©ã€‚

## top-h-decoding--adapting-the-creativity-and-coherence-with-bounded-entropy-in-text-generation
### Abstract
Large language models (LLMs), despite their impressive performance across a
wide range of tasks, often struggle to balance two competing objectives in
open-ended text generation: fostering diversity and creativity while preserving
logical coherence. Existing truncated sampling techniques, including
temperature scaling, top-\$p\$ (nucleus) sampling, and min-\$p\$ sampling, aim
to manage this trade-off. However, they exhibit limitations, particularly in
the effective incorporation of the confidence of the model into the
corresponding sampling strategy. For example, min-\$p\$ sampling relies on a
single top token as a heuristic for confidence, eventually underutilizing the
information of the probability distribution. Toward effective incorporation of
the confidence of the model, in this paper, we present **top-H** decoding. We
first establish the theoretical foundation of the interplay between creativity
and coherence in truncated sampling by formulating an **entropy-constrained
minimum divergence** problem. We then prove this minimization problem to be
equivalent to an **entropy-constrained mass maximization** (ECMM) problem,
which is NP-hard. Finally, we present top-H decoding, a computationally
efficient greedy algorithm to solve the ECMM problem. Extensive empirical
evaluations demonstrate that top-H outperforms the state-of-the-art (SoTA)
alternative of min-\$p\$ sampling by up to **25.63%** on creative writing
benchmarks, while maintaining robustness on question-answering datasets such as
GPQA, GSM8K, and MT-Bench. Additionally, an *LLM-as-judge* evaluation confirms
that top-H indeed produces coherent outputs even at higher temperatures, where
creativity is especially critical. In summary, top-H advances SoTA in
open-ended text generation and can be *easily integrated* into creative writing
applications. The code is available at
https://github.com/ErfanBaghaei/Top-H-Decoding.
### ğŸŒŸ è®ºæ–‡è§£è¯» | Top-H Decodingï¼šç”¨æœ‰ç•Œç†µå¹³è¡¡æ–‡æœ¬ç”Ÿæˆä¸­çš„åˆ›é€ åŠ›ä¸è¿è´¯æ€§

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼€æ”¾å¼æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå¾ˆéš¾å¹³è¡¡**åˆ›é€ åŠ›ï¼ˆå¤šæ ·æ€§ï¼‰**ä¸**è¿è´¯æ€§**è¿™ä¸¤ä¸ªç›®æ ‡ã€‚ç°æœ‰æˆªæ–­é‡‡æ ·æŠ€æœ¯ï¼ˆå¦‚æ¸©åº¦ç¼©æ”¾ã€top - pã€min - pé‡‡æ ·ç­‰ï¼‰è™½è¯•å›¾å¤„ç†è¯¥æƒè¡¡ï¼Œä½†å­˜åœ¨å±€é™ï¼šä»¥min - pä¸ºä¾‹ï¼Œå®ƒä»…ä¾èµ–å•ä¸ªæœ€é«˜æ¦‚ç‡tokenæ¥è¡¡é‡æ¨¡å‹ç½®ä¿¡åº¦ï¼Œæœªå……åˆ†åˆ©ç”¨æ¦‚ç‡åˆ†å¸ƒçš„æ•´ä½“ä¿¡æ¯ï¼Œåœ¨ç¨€ç–æˆ–å¯†é›†åˆ†å¸ƒä¸‹æ˜“å‡ºç°è¿‡æˆªæ–­æˆ–æ¬ æˆªæ–­é—®é¢˜ã€‚åŒæ—¶ï¼Œç¼ºä¹åŸºäºç†è®ºçš„æ¡†æ¶åˆ†æç”Ÿæˆä¸­åˆ›é€ åŠ›ä¸è¿è´¯æ€§çš„ç›¸äº’ä½œç”¨ï¼Œä¹Ÿä¿ƒä½¿éœ€è¦æ›´ç³»ç»Ÿçš„ç½®ä¿¡æ„ŸçŸ¥é‡‡æ ·æ–¹æ³•ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºç†µçº¦æŸä¸‹çš„ç†è®ºæ¡†æ¶  
ä¸ºäº†ç»™é‡‡æ ·æ–¹æ³•å»ºç«‹ç†è®ºåŸºç¡€ï¼Œè®ºæ–‡å…ˆæ„å»ºäº†**ç†µçº¦æŸæœ€å° divergenceï¼ˆECMDï¼‰**é—®é¢˜ï¼Œä»¥æ­¤åˆ»ç”»è¯­è¨€ç”Ÿæˆä¸­åˆ›é€ åŠ›ä¸è¿è´¯æ€§çš„æƒè¡¡ã€‚å¹¶è¯æ˜è¯¥ECMDç­‰ä»·äº**ç†µçº¦æŸè´¨é‡æœ€å¤§åŒ–ï¼ˆECMMï¼‰**é—®é¢˜ï¼Œä¸”ECMMæ˜¯NPéš¾çš„ã€‚è¿™ä¸€æ­¥ä»ç†è®ºå±‚é¢æ˜ç¡®äº†åœ¨è€ƒè™‘ç†µï¼ˆå¯¹åº”åˆ›é€ åŠ›ç›¸å…³çš„ä¸ç¡®å®šæ€§ï¼‰çº¦æŸä¸‹ï¼Œå¦‚ä½•é€‰æ‹©tokenå­é›†æ¥å¹³è¡¡ä¸åŸåˆ†å¸ƒçš„å·®å¼‚ï¼ˆå¯¹åº”è¿è´¯æ€§ï¼‰ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šè®¾è®¡Top - Hè§£ç ç®—æ³•  
ç”±äºECMMæ˜¯NPéš¾é—®é¢˜ï¼Œè®ºæ–‡æå‡ºTop - Hè§£ç è¿™ä¸€è®¡ç®—é«˜æ•ˆçš„è´ªå¿ƒç®—æ³•æ¥è¿‘ä¼¼æ±‚è§£ã€‚Top - HåŠ¨æ€é€‰æ‹©tokenå­é›†ï¼Œä½¿é€‰ä¸­å­é›†çš„æˆªæ–­åˆ†å¸ƒæ»¡è¶³ç†µä¸Šç•Œçº¦æŸï¼ŒåŒæ—¶ä¸æ¨¡å‹é¢„æµ‹çš„åŸå§‹åˆ†å¸ƒå·®å¼‚æœ€å°ã€‚åœ¨è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼ŒTop - Hè¿˜èƒ½æ ¹æ®tokenåˆ†å¸ƒçš„ç†µåŠ¨æ€è°ƒæ•´ç†µé˜ˆå€¼ï¼Œé€‚é…æ¨¡å‹éšæ—¶é—´å˜åŒ–çš„ç½®ä¿¡åº¦ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å¤šç±»ä»»åŠ¡çš„å¤§é‡å®éªŒéªŒè¯äº†Top - Hçš„æœ‰æ•ˆæ€§ï¼š  
- åˆ›æ„å†™ä½œåŸºå‡†ï¼ˆå¦‚Alpaca - Evalã€MT - Benchï¼‰ä¸Šï¼Œç›¸æ¯”å½“å‰æœ€ä¼˜çš„min - pé‡‡æ ·ï¼ŒTop - Håœ¨å‡†ç¡®ç‡ä¸Šæœ€å¤šæå‡25.63%ï¼›  
- åœ¨é—®ç­”ç±»æ•°æ®é›†ï¼ˆGPQAã€GSM8Kã€MT - Benchç­‰ï¼‰ä¸Šä¿æŒäº†é²æ£’æ€§ï¼›  
- ä»¥LLMä½œä¸ºè¯„åˆ¤è€…çš„è¯„ä¼°æ˜¾ç¤ºï¼Œå³ä¾¿åœ¨é«˜æ¸©åº¦ï¼ˆåˆ›é€ åŠ›éœ€æ±‚é«˜åœºæ™¯ï¼‰ä¸‹ï¼ŒTop - Hç”Ÿæˆçš„è¾“å‡ºä¹Ÿèƒ½ä¿æŒè¿è´¯æ€§ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. ç†è®ºé©±åŠ¨è®¾è®¡ï¼šé€šè¿‡æ„å»ºç†µçº¦æŸä¸‹çš„ä¼˜åŒ–é—®é¢˜ï¼Œä¸ºæ–‡æœ¬ç”Ÿæˆä¸­åˆ›é€ åŠ›ä¸è¿è´¯æ€§çš„æƒè¡¡æä¾›äº†ç†è®ºåŸºç¡€ï¼Œè¿™ç§ä»ç†è®ºå±‚é¢å‰–æé‡‡æ ·ç­–ç•¥çš„æ€è·¯å€¼å¾—å€Ÿé‰´ï¼Œèƒ½å¸®åŠ©åç»­å·¥ä½œæ›´ç³»ç»Ÿåœ°æ€è€ƒé‡‡æ ·æ–¹æ³•è®¾è®¡ï¼›  
2. é«˜æ•ˆè´ªå¿ƒç®—æ³•ï¼šé¢å¯¹NPéš¾çš„ä¼˜åŒ–é—®é¢˜ï¼Œè®¾è®¡å‡ºè®¡ç®—é«˜æ•ˆä¸”å®ç”¨çš„è´ªå¿ƒç®—æ³•Top - Hæ¥è¿‘ä¼¼æ±‚è§£ï¼Œä¸ºå¤„ç†å¤æ‚çº¦æŸä¸‹çš„é‡‡æ ·é—®é¢˜æä¾›äº†ç®—æ³•è®¾è®¡å‚è€ƒï¼›  
3. å¤šä»»åŠ¡éªŒè¯ä¸æ˜“é›†æˆæ€§ï¼šåœ¨åˆ›æ„å†™ä½œã€æ¨ç†ç­‰å¤šç±»ä»»åŠ¡éªŒè¯æœ‰æ•ˆæ€§ï¼Œä¸”èƒ½è½»æ¾é›†æˆåˆ°åˆ›æ„å†™ä½œç±»åº”ç”¨ä¸­ï¼Œä½“ç°äº†æ–¹æ³•åœ¨å®é™…åœºæ™¯è½åœ°çš„æ½œåŠ›ï¼Œä¸ºæŠ€æœ¯è½¬åŒ–æä¾›äº†èŒƒä¾‹ã€‚

## towards-agents-that-know-when-they-don-t-know--uncertainty-as-a-control-signal-for-structured-reasoning
### Abstract
Large language model (LLM) agents are increasingly deployed in structured
biomedical data environments, yet they often produce fluent but overconfident
outputs when reasoning over complex multi-table data. We introduce an
uncertainty-aware agent for query-conditioned multi-table summarization that
leverages two complementary signals: (i) retrieval uncertainty--entropy over
multiple table-selection rollouts--and (ii) summary uncertainty--combining
self-consistency and perplexity. Summary uncertainty is incorporated into
reinforcement learning (RL) with Group Relative Policy Optimization (GRPO),
while both retrieval and summary uncertainty guide inference-time filtering and
support the construction of higher-quality synthetic datasets.
  On multi-omics benchmarks, our approach improves factuality and calibration,
nearly tripling correct and useful claims per summary (3.0\(\rightarrow\)8.4
internal; 3.6\(\rightarrow\)9.9 cancer multi-omics) and substantially improving
downstream survival prediction (C-index 0.32\(\rightarrow\)0.63). These results
demonstrate that uncertainty can serve as a control signal--enabling agents to
abstain, communicate confidence, and become more reliable tools for complex
structured-data environments.
### ğŸŒŸ è®ºæ–‡è§£è¯» | è®©æ™ºèƒ½ä½“â€œçŸ¥ä¹‹ä¸ºçŸ¥ä¹‹ï¼Œä¸çŸ¥ä¸ºä¸çŸ¥â€ï¼šç”¨ä¸ç¡®å®šæ€§èµ‹èƒ½ç»“æ„åŒ–æ¨ç†

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨ç”Ÿç‰©åŒ»å­¦ç­‰ç»“æ„åŒ–æ•°æ®ç¯å¢ƒä¸­ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“çš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ï¼Œä½†é¢å¯¹å¤æ‚å¤šè¡¨æ•°æ®æ¨ç†æ—¶ï¼Œå¸¸è¾“å‡ºæµç•…å´è¿‡åº¦è‡ªä¿¡ã€ä¸äº‹å®ä¸ç¬¦çš„å†…å®¹ã€‚æ¯”å¦‚ç”Ÿç‰©åŒ»å­¦ç ”ç©¶è€…æŸ¥è¯¢å¤šç»„å­¦æ•°æ®åº“æ‰¾ç”Ÿå­˜ç›¸å…³ç”Ÿç‰©æ ‡å¿—ç‰©æ—¶ï¼Œæ™®é€šLLMæ™ºèƒ½ä½“å¯èƒ½åœ¨è¯æ®ä¸è¶³æˆ–çŸ›ç›¾æ—¶ä»ç¬ƒå®šè¾“å‡ºç»“è®ºï¼Œè®©ç”¨æˆ·éš¾è¾¨çœŸå‡ã€‚åŒæ—¶ï¼Œç°ä»£ç§‘å­¦çŸ¥è¯†å¤šç¼–ç åœ¨é«˜ç»´è¡¨æ ¼ï¼ˆå¦‚åŸºå› ç»„åˆ†æã€ç”µå­å¥åº·è®°å½•ï¼‰é‡Œï¼Œéä¸“ä¸šäººå‘˜éš¾è·å–å…¶ä¸­ä»·å€¼ï¼Œè€ŒLLMè™½é€‚åˆå°†å¤æ‚æ•°æ®è½¬æˆè¿è´¯å™è¿°ï¼Œå´ç¼ºä¹å¯¹è‡ªèº«ä¸ç¡®å®šæ€§çš„æ„ŸçŸ¥ä¸åˆ©ç”¨ã€‚ç°æœ‰è¡¨æ ¼æ€»ç»“å’Œæ¨ç†æ–¹æ³•ä¹Ÿå¤šå¿½è§†ä¸ç¡®å®šæ€§è¿™ä¸€å…³é”®ç›²ç‚¹ï¼ŒLLMç”Ÿæˆä¸å¯ä¿¡è¾“å‡ºé—®é¢˜åœ¨é«˜ç»´æ•°æ®æ€»ç»“æ—¶æ›´ä¸¥é‡ï¼Œä¸”å¤šæ•°ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ä»…ä½œäº‹åè¯Šæ–­ï¼Œæœªèå…¥æ™ºèƒ½ä½“ä¸è¡¨æ ¼äº¤äº’çš„å†³ç­–è¿‡ç¨‹ï¼Œé™åˆ¶äº†åŠ¨æ€ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ã€‚å› æ­¤ï¼Œæ‰“é€ èƒ½æ„ŸçŸ¥ä¸ç¡®å®šæ€§ã€æ›´å¯é çš„æ™ºèƒ½ä½“æˆäº†å…³é”®éœ€æ±‚ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šä¸ç¡®å®šæ€§ä½œä¸ºæ§åˆ¶ä¿¡å·è´¯ç©¿è®­ç»ƒä¸æ¨ç†  
æå‡ºé¦–ä¸ªLLMæ™ºèƒ½ä½“æ¡†æ¶ï¼Œè®©ä¸ç¡®å®šæ€§ä¸åªæ˜¯è¢«ç›‘æµ‹ï¼Œæ›´æ˜¯åœ¨è®­ç»ƒæ—¶ç›´æ¥ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼ˆå€ŸåŠ©Group Relative Policy Optimizationå¼ºåŒ–å­¦ä¹ èå…¥æ‘˜è¦ä¸ç¡®å®šæ€§ï¼‰ï¼Œæ¨ç†æ—¶ä½œä¸ºâ€œå¼ƒæƒ/è¿‡æ»¤â€ä¿¡å·ã€‚ä¸å†å±€é™äºäº‹åè¯Šæ–­ï¼Œä»è®­ç»ƒåˆ°æ¨ç†å…¨æµç¨‹åˆ©ç”¨ä¸ç¡®å®šæ€§å¼•å¯¼æ™ºèƒ½ä½“è¡Œä¸ºï¼Œæ¯”å¦‚æ¨ç†æ—¶ä¾æ®æ£€ç´¢ä¸ç¡®å®šæ€§ï¼ˆå¤šè¡¨é€‰æ‹©æ¨æ¼”çš„ç†µï¼‰å’Œæ‘˜è¦ä¸ç¡®å®šæ€§ï¼ˆç»“åˆè‡ªä¸€è‡´æ€§ä¸å›°æƒ‘åº¦ï¼‰è¿‡æ»¤å€™é€‰æ‘˜è¦ï¼Œæå‡è¾“å‡ºå¯é æ€§ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šåŒä¸ç¡®å®šæ€§ä¿¡å·é©±åŠ¨  
åˆ©ç”¨ä¸¤ç±»äº’è¡¥ä¸ç¡®å®šæ€§ä¿¡å·ï¼šä¸€æ˜¯**æ£€ç´¢ä¸ç¡®å®šæ€§**ï¼Œé€šè¿‡å¤šè½®è¡¨é€‰æ‹©æ¨æ¼”çš„ç†µæ¥è¡¡é‡é€‰æ‹©è¡¨æ ¼ç¯èŠ‚çš„ä¸ç¡®å®šç¨‹åº¦ï¼›äºŒæ˜¯**æ‘˜è¦ä¸ç¡®å®šæ€§**ï¼Œç»“åˆè‡ªä¸€è‡´æ€§ï¼ˆçœ‹å¤šæ¬¡ç”Ÿæˆæ‘˜è¦çš„ä¸€è‡´ç¨‹åº¦ï¼‰å’Œå›°æƒ‘åº¦ï¼ˆæ¨¡å‹ç”Ÿæˆæ‘˜è¦æ—¶çš„ä¸ç¡®å®šåº¦é‡ï¼‰æ¥åˆ»ç”»æ‘˜è¦å±‚é¢çš„ä¸ç¡®å®šæ€§ã€‚è®­ç»ƒæ—¶æ‘˜è¦ä¸ç¡®å®šæ€§èå…¥å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ç­–ç•¥ï¼Œæ¨ç†æ—¶ä¸¤ç±»ä¸ç¡®å®šæ€§å…±åŒå¼•å¯¼è¿‡æ»¤ï¼Œè¿˜è¾…åŠ©æ„å»ºæ›´é«˜è´¨é‡çš„åˆæˆæ•°æ®é›†ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šé¢å‘ç»“æ„åŒ–ç¯å¢ƒçš„é²æ£’æ€§ä¸æ•°æ®è´¨é‡æå‡  
æ–¹æ³•é€‚ç”¨äºä»»æ„å¤šè¡¨åœºæ™¯ï¼Œåœ¨ç”Ÿç‰©åŒ»å­¦å¤šç»„å­¦ä»»åŠ¡ä¸­éªŒè¯ï¼Œè®©æ™ºèƒ½ä½“åœ¨äº‹å®æ€§ã€æ ¡å‡†åº¦ï¼ˆå¯¹è‡ªèº«ç½®ä¿¡åº¦çš„åˆç†è¯„ä¼°ï¼‰å’Œä¸‹æ¸¸æ•ˆç”¨ï¼ˆå¦‚ç”Ÿå­˜é¢„æµ‹ï¼‰ä¸Šè¡¨ç°æ›´ä¼˜ï¼›åŒæ—¶ï¼Œå°†é«˜ä¸ç¡®å®šæ€§æ ·æœ¬è¿‡æ»¤åèƒ½æå‡è¡¨æ ¼æ–‡æœ¬æ•°æ®é›†è´¨é‡ï¼Œä¸ºæ‰“é€ å¯é è¯­æ–™åº“æä¾›å®ç”¨å·¥å…·ï¼ŒæŠŠä¸ç¡®å®šæ€§å½“ä½œæ•°æ®è´¨é‡ä¿¡å·æ¥ç”¨ï¼Œä»æ•°æ®å±‚é¢åŠ©åŠ›ä¸‹æ¸¸æ›´ç¨³å¥å†³ç­–ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å¤šç»„å­¦åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ–¹æ³•æå‡äº†äº‹å®æ€§ä¸æ ¡å‡†åº¦ï¼šå†…éƒ¨å¤šç»„å­¦ä»»åŠ¡é‡Œï¼Œæ¯ä»½æ‘˜è¦çš„æ­£ç¡®æœ‰ç”¨è®ºæ–­æ•°ä»3.0æå‡åˆ°8.4ï¼›ç™Œç—‡å¤šç»„å­¦ä»»åŠ¡ä¸­ä»3.6æå‡åˆ°9.9ï¼Œè¿‘ä¹ä¸‰å€å¢é•¿ã€‚ä¸‹æ¸¸ç”Ÿå­˜é¢„æµ‹çš„CæŒ‡æ•°ä»0.32æå‡åˆ°0.63ï¼Œå¤§å¹…è¿›æ­¥ã€‚è¿™äº›ç»“æœè¯æ˜ä¸ç¡®å®šæ€§ä½œä¸ºæ§åˆ¶ä¿¡å·ï¼Œèƒ½è®©æ™ºèƒ½ä½“åœ¨å¤æ‚ç»“æ„åŒ–æ•°æ®ç¯å¢ƒä¸­â€œæ‡‚å¾—å¼ƒæƒã€ä¼ é€’ç½®ä¿¡åº¦ï¼Œæˆä¸ºæ›´å¯é å·¥å…·â€ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. ä¸ç¡®å®šæ€§åˆ©ç”¨èŒƒå¼ï¼šæ‰“ç ´â€œäº‹åè¯Šæ–­â€å±€é™ï¼ŒæŠŠä¸ç¡®å®šæ€§æ·±åº¦èå…¥æ™ºèƒ½ä½“è®­ç»ƒï¼ˆå½“å¥–åŠ±ï¼‰å’Œæ¨ç†ï¼ˆå½“è¿‡æ»¤/å¼ƒæƒä¾æ®ï¼‰æµç¨‹ï¼Œä¸ºæ‰“é€ æ›´å¯é AIç³»ç»Ÿæä¾›äº†â€œè®©æ¨¡å‹æ„ŸçŸ¥è‡ªèº«ä¸ç¡®å®šâ€çš„æ€è·¯ï¼Œå¯æ¨å¹¿åˆ°å…¶ä»–éœ€å¯é æ€§çš„LLMåº”ç”¨åœºæ™¯ï¼ˆå¦‚é‡‘èæŠ¥å‘Šç”Ÿæˆã€æ³•å¾‹æ–‡ä¹¦æ€»ç»“ç­‰ï¼‰ã€‚  
2. å¤šä¿¡å·èåˆæ€è·¯ï¼šç»“åˆæ£€ç´¢å’Œæ‘˜è¦ä¸¤ä¸ªç»´åº¦çš„ä¸ç¡®å®šæ€§ä¿¡å·ï¼Œä»â€œé€‰æ•°æ®ï¼ˆè¡¨é€‰æ‹©ï¼‰â€åˆ°â€œç”Ÿæˆå†…å®¹ï¼ˆæ‘˜è¦ï¼‰â€å…¨é“¾æ¡æŠŠæ§è´¨é‡ï¼Œè¿™ç§å¤šç¯èŠ‚å¤šä¿¡å·ååŒçš„æ–¹å¼ï¼Œä¸ºå¤„ç†å¤æ‚ä»»åŠ¡ï¼ˆæ¶‰åŠå¤šæ­¥éª¤ã€å¤šæ•°æ®æºï¼‰çš„æ™ºèƒ½ä½“è®¾è®¡æä¾›å‚è€ƒã€‚  
3. æ•°æ®è´¨é‡ä¸ä¸‹æ¸¸æ•ˆç”¨è”åŠ¨ï¼šå±•ç¤ºäº†ç”¨ä¸ç¡®å®šæ€§è¿‡æ»¤æ•°æ®æ¥æå‡æ•°æ®é›†è´¨é‡ï¼Œè¿›è€ŒåŠ©åŠ›ä¸‹æ¸¸ä»»åŠ¡çš„é—­ç¯é€»è¾‘ï¼Œåœ¨æ„å»ºé¢†åŸŸä¸“å±è¯­æ–™ã€ä¼˜åŒ–ä¸‹æ¸¸æ¨¡å‹è¡¨ç°ç­‰æ–¹é¢ï¼Œç»™æ•°æ® curationï¼ˆæ•´ç†/ç²¾é€‰ï¼‰å·¥ä½œæä¾›äº†æ–°çš„é‡åŒ–æŒ‡æ ‡å’Œæ“ä½œæ–¹æ³•ã€‚  
4. ç»“æ„åŒ–åœºæ™¯è½åœ°ï¼šåœ¨ç”Ÿç‰©åŒ»å­¦å¤šç»„å­¦è¿™ç±»é«˜ä»·å€¼ä½†å¤æ‚çš„ç»“æ„åŒ–æ•°æ®åœºæ™¯éªŒè¯æœ‰æ•ˆï¼Œä¸ºç§‘ç ”é¢†åŸŸï¼ˆå¦‚è¯ç‰©ç ”å‘ã€ç–¾ç—…æœºåˆ¶ç ”ç©¶ï¼‰é‡ŒAIå·¥å…·çš„å®ç”¨åŒ–ã€å¯ä¿¡åŒ–æä¾›äº†å¯å‚è€ƒçš„æŠ€æœ¯è·¯çº¿ï¼Œä¹Ÿå¯å‘å…¶ä»–å‚ç›´é¢†åŸŸï¼ˆå¦‚æ°”è±¡ã€é‡‘èé£æ§çš„è¡¨æ ¼/å¤šæºæ•°æ®å¤„ç†ï¼‰å€Ÿé‰´è¯¥ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ¡†æ¶ã€‚

## learned-hallucination-detection-in-black-box-llms-using-token-level-entropy-production-rate
### Abstract
Hallucinations in Large Language Model (LLM) outputs for Question Answering
(QA) tasks critically undermine their real-world reliability. This paper
introduces an applied methodology for robust, one-shot hallucination detection,
specifically designed for scenarios with limited data access, such as
interacting with black-box LLM APIs that typically expose only a few top
candidate log-probabilities per token. Our approach derives uncertainty
indicators directly from these readily available log-probabilities generated
during non-greedy decoding. We first derive an Entropy Production Rate (EPR)
metric that offers baseline performance, later augmented with supervised
learning. Our learned model uses features representing the entropic
contributions of the accessible top-ranked tokens within a single generated
sequence, requiring no multiple query re-runs. Evaluated across diverse QA
datasets and multiple LLMs, this estimator significantly improves hallucination
detection over using EPR alone. Crucially, high performance is demonstrated
using only the typically small set of available log-probabilities (e.g., top
<10 per token), confirming its practical efficiency and suitability for these
API-constrained deployments. This work provides a readily deployable technique
to enhance the trustworthiness of LLM responses from a single generation pass
in QA and Retrieval-Augmented Generation (RAG) systems, with its utility
further demonstrated in a finance framework analyzing responses to queries on
annual reports from an industrial dataset.
### ğŸŒŸ è®ºæ–‡è§£è¯» | é»‘ç›’å¤§æ¨¡å‹ä¸­åŸºäºtokençº§ç†µäº§ç”Ÿç‡çš„å¹»è§‰æ£€æµ‹æ–°æ–¹æ³•

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é—®ç­”ï¼ˆQAï¼‰ä»»åŠ¡ä¸­ç”Ÿæˆçš„å¹»è§‰ä¸¥é‡å½±å“å…¶ç°å®å¯é æ€§ï¼Œè€Œåœ¨ä¸é»‘ç›’LLM APIäº¤äº’ç­‰æ•°æ®è®¿é—®å—é™åœºæ™¯ä¸‹ï¼Œä¼ ç»Ÿæ£€æµ‹æ–¹æ³•å—é™äºåªèƒ½è·å–å°‘é‡tokençš„topå€™é€‰å¯¹æ•°æ¦‚ç‡ï¼Œä¸”å¾ˆå¤šå®é™…åº”ç”¨éœ€è¦â€œä¸€é”®å¼â€ï¼ˆone - shotï¼‰æ£€æµ‹èƒ½åŠ›ï¼Œå³æ— éœ€å¤šæ¬¡æ¨ç†å°±èƒ½è¯„ä¼°å•ä¸ªç”Ÿæˆåºåˆ—çš„å¯é æ€§ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§é€‚ç”¨äºé»‘ç›’ã€ä¸€é”®å¼åœºæ™¯çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ–¹æ³•æ¥æ£€æµ‹å¹»è§‰ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºç†µäº§ç”Ÿç‡ï¼ˆEPRï¼‰åº¦é‡
ä»é»‘ç›’LLM APIå¯è·å–çš„å¯¹æ•°æ¦‚ç‡å‡ºå‘ï¼Œæ¨å¯¼äº†ç†µäº§ç”Ÿç‡ï¼ˆEPRï¼‰è¿™ä¸€åº¦é‡ã€‚EPRè®¡ç®—ä¸ºæ•´ä¸ªåºåˆ—ä¸­tokenæ¦‚ç‡åˆ†å¸ƒçš„å¹³å‡ç†µï¼ˆå³æ‰€æœ‰é€tokenç†µçš„å’Œé™¤ä»¥åºåˆ—é•¿åº¦ï¼‰ï¼Œä½œä¸ºæ¨¡å‹æ¨ç†æœŸé—´çŠ¹è±«ç¨‹åº¦çš„æ— ç›‘ç£åˆå§‹ä¼°è®¡é‡ï¼Œä¸ºå¹»è§‰æ£€æµ‹æä¾›åŸºçº¿æ€§èƒ½ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šåŸºäºç›‘ç£å­¦ä¹ å¢å¼ºçš„æ¨¡å‹
åœ¨EPRåŸºç¡€ä¸Šï¼Œå¼€å‘äº†ç›‘ç£å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ©ç”¨å•ä¸ªç”Ÿæˆåºåˆ—å†…å¯è®¿é—®çš„topæ’åtokençš„ç†µè´¡çŒ®ç‰¹å¾ï¼Œæ— éœ€å¤šæ¬¡æŸ¥è¯¢é‡æ–°è¿è¡Œï¼Œèƒ½æ›´å‡†ç¡®åœ°åŒºåˆ†å¯é å“åº”å’Œå¹»è§‰å“åº”ï¼Œè¿˜å¯æ›´å¥½åœ°çªå‡ºç”Ÿæˆåºåˆ—ä¸­é«˜ä¸ç¡®å®šæ€§çš„tokenã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨ä¸åŒçš„QAæ•°æ®é›†å’Œå¤šä¸ªLLMä¸Šè¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥å­¦ä¹ åˆ°çš„ä¼°è®¡å™¨ç›¸æ¯”ä»…ä½¿ç”¨EPRï¼Œåœ¨å¹»è§‰æ£€æµ‹ä¸Šæœ‰æ˜¾è‘—æ”¹è¿›ã€‚å¹¶ä¸”ï¼Œä»…ä½¿ç”¨é€šå¸¸å°‘é‡çš„å¯ç”¨å¯¹æ•°æ¦‚ç‡ï¼ˆå¦‚æ¯ä¸ªtokençš„top < 10ï¼‰å°±èƒ½å®ç°é«˜æ€§èƒ½ï¼Œè¯å®äº†å…¶åœ¨APIå—é™éƒ¨ç½²ä¸­çš„å®é™…æ•ˆç‡å’Œé€‚ç”¨æ€§ã€‚æ­¤å¤–ï¼Œåœ¨é‡‘èæ¡†æ¶ï¼ˆåˆ†æå·¥ä¸šæ•°æ®é›†å¹´åº¦æŠ¥å‘ŠæŸ¥è¯¢å“åº”ï¼‰ä¸­ä¹Ÿå±•ç¤ºäº†å…¶æ•ˆç”¨ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
è¯¥å·¥ä½œæä¾›äº†ä¸€ç§æ˜“äºéƒ¨ç½²çš„æŠ€æœ¯ï¼Œå¯åœ¨QAå’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿçš„å•æ¬¡ç”Ÿæˆè¿‡ç¨‹ä¸­å¢å¼ºLLMå“åº”çš„å¯ä¿¡åº¦ï¼Œä¸ºåœ¨é»‘ç›’ã€æ•°æ®è®¿é—®å—é™ä¸”éœ€ä¸€é”®å¼æ£€æµ‹çš„åœºæ™¯ä¸‹ï¼Œè§£å†³LLMå¹»è§‰é—®é¢˜æä¾›äº†æ–°çš„æ€è·¯å’Œå®ç”¨æ–¹æ³•ï¼Œç›¸å…³çš„ç†µåº¦é‡å’Œç›‘ç£å­¦ä¹ ç»“åˆçš„æ€è·¯ä¹Ÿå¯ä¸ºåç»­ä¸ç¡®å®šæ€§é‡åŒ–å’Œå¹»è§‰æ£€æµ‹ç ”ç©¶æä¾›å‚è€ƒã€‚

## tecp--token-entropy-conformal-prediction-for-llms
### Abstract
Uncertainty quantification (UQ) for open-ended language generation remains a
critical yet underexplored challenge, especially under black-box constraints
where internal model signals are inaccessible. In this paper, we introduce
Token-Entropy Conformal Prediction (TECP), a novel framework that leverages
token-level entropy as a logit-free, reference-free uncertainty measure and
integrates it into a split conformal prediction (CP) pipeline to construct
prediction sets with formal coverage guarantees. Unlike existing approaches
that rely on semantic consistency heuristics or white-box features, TECP
directly estimates epistemic uncertainty from the token entropy structure of
sampled generations and calibrates uncertainty thresholds via CP quantiles to
ensure provable error control. Empirical evaluations across six large language
models and two benchmarks (CoQA and TriviaQA) demonstrate that TECP
consistently achieves reliable coverage and compact prediction sets,
outperforming prior self-consistency-based UQ methods. Our method provides a
principled and efficient solution for trustworthy generation in black-box LLM
settings.
### ğŸŒŸ è®ºæ–‡è§£è¯» | é»‘ç›’å¤§æ¨¡å‹ä¸‹çš„å¯ä¿¡ç”Ÿæˆæ–°æ–¹æ¡ˆï¼šTECPæ¡†æ¶

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¼—å¤šä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é«˜é£é™©åœºæ™¯éƒ¨ç½²æ—¶ï¼Œå­˜åœ¨å¹»è§‰ã€äº‹å®é”™è¯¯ç­‰å¯é æ€§é—®é¢˜ã€‚ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ˜¯è¯„ä¼°æ¨¡å‹è¾“å‡ºå¯ä¿¡åº¦çš„å…³é”®æ‰‹æ®µï¼Œç„¶è€Œç°æœ‰æ–¹æ³•å¤šä¾èµ–å¯å‘å¼ä¿¡å·ï¼Œç¼ºä¹å¯è¯æ˜çš„é£é™©ä¿éšœï¼ˆå¦‚æ­£ç¡®æ€§è¦†ç›–ï¼‰ã€‚åŒæ—¶ï¼Œåœ¨é»‘ç›’çº¦æŸï¼ˆæ— æ³•è·å–å†…éƒ¨æ¨¡å‹ä¿¡å·ï¼‰ä¸‹ï¼Œå¼€å‘æœ‰æ•ˆä¸”åˆç†çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•è¿«åœ¨çœ‰ç«ã€‚æ­¤å¤–ï¼Œå½“ä¸‹ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•è™½èƒ½åŒºåˆ†ç­”æ¡ˆæ­£è¯¯ï¼Œå´éš¾æä¾›å¯è¯æ˜çš„é£é™©ä¿è¯ï¼Œè€Œå¼€æ”¾åŸŸç”Ÿæˆçš„ä¸ç¡®å®šæ€§ä¼°è®¡ä¹Ÿé¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œè¿™äº›éƒ½æ„æˆäº†ç ”ç©¶çš„èƒŒæ™¯ä¸åŠ¨æœºã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºToken - Entropy Conformal Predictionï¼ˆTECPï¼‰æ¡†æ¶  
TECPå°†tokençº§ç†µä½œä¸ºæ— logitã€æ— å‚è€ƒçš„ä¸ç¡®å®šæ€§åº¦é‡ï¼Œåˆ©ç”¨tokenç†µç»“æ„ç›´æ¥ä»é‡‡æ ·ç”Ÿæˆä¸­ä¼°è®¡è®¤çŸ¥ä¸ç¡®å®šæ€§ã€‚ä¸åŒäºä¾èµ–è¯­ä¹‰ä¸€è‡´æ€§å¯å‘å¼æˆ–ç™½ç›’ç‰¹å¾çš„ç°æœ‰æ–¹æ³•ï¼Œå®ƒæ— éœ€å†…éƒ¨æ¨¡å‹ä¿¡å·ï¼Œé€‚é…é»‘ç›’å¤§æ¨¡å‹åœºæ™¯ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šèåˆåˆ†æ‹† conformal predictionï¼ˆCPï¼‰ pipeline  
æŠŠtokençº§ç†µé›†æˆåˆ°åˆ†æ‹†CPæµç¨‹ä¸­ï¼Œé€šè¿‡CPåˆ†ä½æ•°æ ¡å‡†ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œæ„é€ å…·æœ‰å½¢å¼åŒ–è¦†ç›–ä¿è¯çš„é¢„æµ‹é›†ï¼Œç¡®ä¿å¯è¯æ˜çš„è¯¯å·®æ§åˆ¶ã€‚CPä½œä¸ºç»Ÿè®¡å­¦ä¹ èŒƒå¼ï¼Œå¯¹æ•°æ®åˆ†å¸ƒå‡è®¾å°‘ï¼Œä»…éœ€æ ·æœ¬æ»¡è¶³å¯äº¤æ¢æ€§ï¼Œèƒ½åœ¨ä¸åŒä»»åŠ¡å’Œæ¨¡å‹æ¶æ„ä¸‹ç”Ÿæˆå¸¦ç½®ä¿¡æ°´å¹³ä¿è¯çš„å¯è§£é‡Šé¢„æµ‹é›†ï¼ŒTECPå€ŸåŠ©å…¶ç‰¹æ€§ä¸ºå¼€æ”¾åŸŸç”Ÿæˆçš„é¢„æµ‹æä¾›å¯é è¦†ç›–ä¿éšœã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å…­ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚LLaMA - 3.2 - 1Bã€Qwen2.5 - 3B - Instructç­‰ï¼‰å’Œä¸¤ä¸ªåŸºå‡†ï¼ˆCoQAå’ŒTriviaQAï¼‰ä¸Šè¿›è¡Œå®è¯è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼ŒTECPæŒç»­å®ç°äº†å¯é çš„è¦†ç›–ï¼ˆé€šè¿‡å®è¯è¦†ç›–ç‡ECRè¡¡é‡ï¼Œå³é¢„æµ‹é›†åŒ…å«çœŸå®å“åº”çš„å®ä¾‹æ¯”ä¾‹ï¼‰å’Œç´§å‡‘çš„é¢„æµ‹é›†ï¼ˆé€šè¿‡å¹³å‡é¢„æµ‹é›†å¤§å°APSSè¡¡é‡ï¼Œä½œä¸ºè®¤çŸ¥ä¸ç¡®å®šæ€§çš„ä»£ç†æŒ‡æ ‡ï¼‰ï¼Œä¸”ä¼˜äºå…ˆå‰åŸºäºè‡ªä¸€è‡´æ€§çš„UQæ–¹æ³•ï¼Œåœ¨ç»´æŒä¸¥æ ¼è¯¯å·®æ§åˆ¶çš„åŒæ—¶ï¼Œå®ç°äº†å¯¹çœŸå®è¾“å‡ºçš„é«˜è¦†ç›–ï¼Œä¸ºå¼€æ”¾åŸŸç”Ÿæˆåœºæ™¯ä¸‹çš„æ¨¡å‹é¢„æµ‹æä¾›äº†å¼ºå¤§çš„å¯é æ€§ä¿è¯ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. æŒ‡æ ‡ä¸æ–¹æ³•åˆ›æ–°ï¼šæå‡ºåŸºäºtokençº§ç†µçš„éä¸€è‡´æ€§è¯„åˆ†èŒƒå¼ï¼Œä¸ºé»‘ç›’å¤§æ¨¡å‹ä¸ç¡®å®šæ€§é‡åŒ–æä¾›äº†æ–°çš„æœ‰æ•ˆåº¦é‡æ–¹å¼ï¼Œä¸”åœ¨ conformal prediction æ¡†æ¶ä¸‹å®ç°æ ¡å‡†é¢„æµ‹é›†æ„å»ºï¼Œæ€è·¯å¯å€Ÿé‰´åˆ°å…¶ä»–éœ€ä¸ç¡®å®šæ€§é‡åŒ–çš„ç”Ÿæˆç±»ä»»åŠ¡ä¸­ã€‚  
2. å®éªŒè®¾è®¡ï¼šå¯¹å¤šä¸ªå‰æ²¿å¤§æ¨¡å‹åœ¨ä¸åŒåŸºå‡†æµ‹è¯•é›†ä¸Šå¼€å±•ç³»ç»Ÿå®è¯ç ”ç©¶ï¼Œè¿™ç§å¤šæ¨¡å‹ã€å¤šæ•°æ®é›†çš„å…¨é¢è¯„ä¼°æ–¹å¼ï¼Œä¸ºåç»­ç›¸å…³ç ”ç©¶çš„å®éªŒè®¾è®¡æä¾›äº†å‚è€ƒï¼Œæœ‰åŠ©äºæ›´å…¨é¢åœ°éªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ã€‚  
3. åœºæ™¯é€‚é…ï¼šé’ˆå¯¹é»‘ç›’çº¦æŸåœºæ™¯è®¾è®¡æ–¹æ³•ï¼Œæ»¡è¶³äº†ç°å®ä¸­å¾ˆå¤šæ— æ³•è·å–æ¨¡å‹å†…éƒ¨ä¿¡å·æ—¶çš„åº”ç”¨éœ€æ±‚ï¼Œä¸ºå¤§æ¨¡å‹åœ¨åŒ»ç–—ã€å¿ƒç†ç­‰é«˜é£é™©ä¸“ä¸šé¢†åŸŸçš„å¯ä¿¡éƒ¨ç½²æä¾›äº†å¯è¡Œæ–¹æ¡ˆæ€è·¯ï¼Œå…¶å¯¹é»‘ç›’åœºæ™¯çš„é€‚é…æ€è·¯å€¼å¾—åœ¨ç±»ä¼¼å—é™åœºæ™¯çš„ç ”ç©¶ä¸­å€Ÿé‰´ã€‚

## from-canonical-to-complex--benchmarking-llm-capabilities-in-undergraduate-thermodynamics
### Abstract
Large language models (LLMs) are increasingly considered as tutoring aids in
science education. Yet their readiness for unsupervised use in undergraduate
instruction remains uncertain, as reliable teaching requires more than fluent
recall: it demands consistent, principle-grounded reasoning. Thermodynamics,
with its compact laws and subtle distinctions between state and path functions,
reversibility, and entropy, provides an ideal testbed for evaluating such
capabilities. Here we present UTQA, a 50-item undergraduate thermodynamics
question answering benchmark, covering ideal-gas processes, reversibility, and
diagram interpretation. No leading 2025-era model exceeded our 95\% competence
threshold: the best LLMs achieved 82\% accuracy, with text-only items
performing better than image reasoning tasks, which often fell to chance
levels. Prompt phrasing and syntactic complexity showed modest to little
correlation with performance. The gap concentrates in finite-rate/irreversible
scenarios and in binding visual features to thermodynamic meaning, indicating
that current LLMs are not yet suitable for unsupervised tutoring in this
domain.
### ğŸŒŸ è®ºæ–‡è§£è¯» | æœ¬ç§‘çƒ­åŠ›å­¦é¢†åŸŸå¤§æ¨¡å‹èƒ½åŠ›æµ‹è¯„ï¼šä»åŸºç¡€åˆ°å¤æ‚

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç§‘å­¦æ•™è‚²ä¸­è¢«è§†ä½œæ½œåœ¨çš„è¾…å¯¼å·¥å…·ï¼Œä½†åœ¨æœ¬ç§‘æ•™å­¦ä¸­æ— ç›‘ç£ä½¿ç”¨æ˜¯å¦å¯è¡Œå­˜ç–‘ã€‚å¯é æ•™å­¦ä¸ä»…éœ€æµç•…å›å¿†çŸ¥è¯†ï¼Œæ›´è¦åŸºäºåŸç†çš„è¿è´¯æ¨ç†ã€‚çƒ­åŠ›å­¦å› å®šå¾‹ç®€æ´ä¸”æ¦‚å¿µï¼ˆå¦‚çŠ¶æ€ä¸è·¯å¾„å‡½æ•°ã€å¯é€†æ€§ã€ç†µï¼‰åŒºåˆ†å¾®å¦™ï¼Œæˆä¸ºè¯„ä¼°æ­¤ç±»èƒ½åŠ›çš„ç†æƒ³æµ‹è¯•åœºã€‚è€Œç°æœ‰ç§‘å­¦åŸºå‡†å¯¹çƒ­åŠ›å­¦æ¨ç†å…³æ³¨ä¸è¶³ï¼ŒåƒGPQAã€Humanityâ€™s Last Examç­‰åŸºå‡†åœ¨ç†µã€å¯é€†æ€§ç­‰æ ¸å¿ƒæ¦‚å¿µè¦†ç›–ä¸Šå­˜åœ¨ç¼ºå£ï¼ŒSciBenchè™½æœ‰çƒ­åŠ›å­¦é¢˜ç›®ä½†å¤šä¸ºå®šé‡è®¡ç®—ï¼Œå¯¹å…³é”®æ¨ç†è€ƒæŸ¥ä¸å¤Ÿã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨æ„å»ºä¸“é—¨åŸºå‡†è¯„ä¼°å¤§æ¨¡å‹åœ¨æœ¬ç§‘çƒ­åŠ›å­¦é¢†åŸŸçš„èƒ½åŠ›ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ„å»ºUTQAåŸºå‡†  
æ‰“é€ åŒ…å«50é“é¢˜çš„æœ¬ç§‘çƒ­åŠ›å­¦é—®ç­”åŸºå‡†UTQAï¼Œæ¶µç›–ç†æƒ³æ°”ä½“è¿‡ç¨‹ã€å¯é€†æ€§ã€å›¾è¡¨è§£é‡Šç­‰å†…å®¹ï¼Œå…¶ä¸­33é“çº¯æ–‡æœ¬é¢˜ã€17é“åŸºäºå›¾è¡¨çš„é¢˜ï¼Œé¢˜ç›®èšç„¦å¤šæ­¥éª¤æ¨ç†ä¸æ•´åˆå¤šçº¦æŸçš„é—®é¢˜è§£å†³ï¼Œè€Œéå•çº¯çŸ¥è¯†å›å¿†ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¤šç»´åº¦å®éªŒè®¾è®¡  
å¼€å±•ä¸¤ç±»å®éªŒï¼šä¸€æ˜¯åœ¨gpt - 4oä¸Šè¿›è¡Œæç¤ºä¸è¯­è¨€é€€åŒ–å®éªŒï¼›äºŒæ˜¯åœ¨å…¶ä»–æ¨¡å‹ä¸Šç”¨å‘½ä»¤è¡Œç•Œé¢å¼€å±•è·¨æ¨¡å‹åŸºå‡†æ¯”è¾ƒã€‚æµ‹è¯•17ç§æç¤ºç­–ç•¥ï¼Œè¿˜å¯¹æ–‡æœ¬é¢˜è¿›è¡Œè¯­è¨€æ‰°åŠ¨ï¼ˆå¦‚æ¸…æ™°åº¦é™ä½ã€æ‹¼å†™å™ªå£°ã€æœ¯è¯­æ›¿æ¢ï¼‰ä»¥é‡åŒ–è¾“å…¥è´¨é‡æ•æ„Ÿæ€§ï¼›é’ˆå¯¹å›¾è¡¨é¢˜å•ç‹¬åˆ†æï¼Œä¸”åœ¨æ–‡æœ¬é¢˜å®éªŒä¸­é€šè¿‡å¾ªç¯æé—®ç­‰æ–¹å¼å‡å°‘ç¼“å­˜ç­‰å¹²æ‰°ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
å½“å‰é¡¶å°–2025å¹´å‰åçš„å¤§æ¨¡å‹æ— ä¸€å°é˜¶è¶…è¿‡95%çš„èƒ½åŠ›é˜ˆå€¼ï¼Œæœ€ä¼˜æ¨¡å‹å‡†ç¡®ç‡è¾¾82%ã€‚çº¯æ–‡æœ¬é¢˜ç›®è¡¨ç°ä¼˜äºå›¾åƒæ¨ç†ä»»åŠ¡ï¼Œå›¾åƒæ¨ç†å¸¸æ¥è¿‘éšæœºæ°´å¹³ï¼›æç¤ºæªè¾å’Œå¥æ³•å¤æ‚åº¦ä¸æ€§èƒ½ç›¸å…³æ€§ä¸å¤§ï¼›æ€§èƒ½ç¼ºå£é›†ä¸­åœ¨æœ‰é™é€Ÿç‡/ä¸å¯é€†åœºæ™¯ä»¥åŠè§†è§‰ç‰¹å¾ä¸çƒ­åŠ›å­¦æ„ä¹‰çš„å…³è”ä¸Šï¼Œè¯´æ˜å½“å‰å¤§æ¨¡å‹åœ¨è¯¥é¢†åŸŸæ— ç›‘ç£è¾…å¯¼ä»ä¸é€‚ç”¨ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
åœ¨é¢†åŸŸç‰¹å®šèƒ½åŠ›æµ‹è¯„æ–¹é¢ï¼Œæ„å»ºèšç„¦å­¦ç§‘æ ¸å¿ƒæ¦‚å¿µä¸æ¨ç†çš„åŸºå‡†æ˜¯æœ‰æ•ˆè¯„ä¼°å¤§æ¨¡å‹é€‚ç”¨æ€§çš„æ–¹å¼ï¼Œä¸ºå…¶ä»–å­¦ç§‘ï¼ˆå¦‚ç‰©ç†å…¶ä»–åˆ†æ”¯ã€åŒ–å­¦ç­‰ï¼‰è¯„ä¼°å¤§æ¨¡å‹æ•™å­¦æ½œåŠ›æä¾›äº†èŒƒå¼ï¼›å®éªŒè®¾è®¡ä¸Šï¼Œå¤šç»´åº¦ï¼ˆæç¤ºç­–ç•¥ã€è¾“å…¥æ‰°åŠ¨ã€è·¨æ¨¡å‹æ¯”è¾ƒç­‰ï¼‰çš„å®éªŒè®¾ç½®èƒ½å…¨é¢å‰–æå¤§æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸‹çš„è¡¨ç°ä¸çŸ­æ¿ï¼Œè¿™ç§ç»†è‡´çš„å®éªŒæ€è·¯å¯ç”¨äºå…¶ä»–å¤§æ¨¡å‹èƒ½åŠ›è¯„ä¼°åœºæ™¯ï¼›å¯¹äºæ•™è‚²é¢†åŸŸå¤§æ¨¡å‹åº”ç”¨ï¼Œæ˜ç¡®äº†å½“å‰å¤§æ¨¡å‹åœ¨å¤æ‚æ¨ç†å’Œå¤šæ¨¡æ€ï¼ˆå›¾æ–‡ç»“åˆï¼‰ä»»åŠ¡ä¸Šçš„ä¸è¶³ï¼Œä¸ºåç»­æ”¹è¿›æ–¹å‘ï¼ˆå¦‚å¢å¼ºæ¦‚å¿µå…³è”æ¨ç†ã€æå‡å›¾æ–‡ç†è§£ï¼‰æä¾›äº†å‚è€ƒï¼Œä¹Ÿè®©æ•™è‚²è€…æ›´æ¸…æ™°è®¤è¯†å¤§æ¨¡å‹åœ¨æ•™å­¦ä¸­èƒ½ä¸ä¸èƒ½ä¹‹å¤„ã€‚ 

## guard--glocal-uncertainty-aware-robust-decoding-for-effective-and-efficient-open-ended-text-generation
### Abstract
Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.
### ğŸŒŸ è®ºæ–‡è§£è¯» | GUARDï¼šé¢å‘å¼€æ”¾æ–‡æœ¬ç”Ÿæˆçš„â€œå…¨å±€-å±€éƒ¨â€ä¸ç¡®å®šæ€§æ„ŸçŸ¥é²æ£’è§£ç 

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼€æ”¾å¼æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œ**è¿è´¯æ€§ä¸å¤šæ ·æ€§çš„å¹³è¡¡**æ˜¯æ ¸å¿ƒæŒ‘æˆ˜ã€‚ç°æœ‰è§£ç ç­–ç•¥ï¼ˆå¦‚åŸºäºå¯¹æ¯”æœç´¢çš„æ–¹æ³•ï¼‰è™½å°è¯•è§£å†³è¯¥æƒè¡¡é—®é¢˜ï¼Œä½†å­˜åœ¨ä¾èµ–è¶…å‚æ•°ã€è®¡ç®—æˆæœ¬é«˜çš„ç¼ºé™·ã€‚æ­¤å¤–ï¼Œç¡®å®šæ€§è§£ç ï¼ˆå¦‚è´ªå¿ƒã€beam searchï¼‰æ˜“å¯¼è‡´æ–‡æœ¬é€€åŒ–ï¼ˆé‡å¤ï¼‰ï¼Œè€Œéšæœºè§£ç ï¼ˆå¦‚é‡‡æ ·ç±»æ–¹æ³•ï¼‰åˆå¯èƒ½ç‰ºç‰²è¿è´¯æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§è‡ªé€‚åº”è§£ç æ–¹æ³•GUARDï¼Œæ—¨åœ¨æ›´é«˜æ•ˆåœ°å¹³è¡¡æ–‡æœ¬è¿è´¯æ€§ä¸å¤šæ ·æ€§ï¼Œå¹¶é™ä½è®¡ç®—å¼€é”€ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºâ€œGlocalï¼ˆå…¨å±€-å±€éƒ¨ï¼‰ä¸ç¡®å®šæ€§â€æ¡†æ¶  
GUARDèåˆ**å…¨å±€ç†µä¼°è®¡**ä¸**å±€éƒ¨ç†µåå·®**ï¼Œæ•´åˆé•¿çŸ­æœŸä¸ç¡®å®šæ€§ä¿¡å·ã€‚å…¨å±€ç†µç”¨äºç¼“è§£ä¸ç¡®å®šæ€§çš„çªå˜ï¼ˆå¦‚çªç„¶è¿‡è‡ªä¿¡æˆ–ç†µ spikeï¼‰ï¼Œå¹¶ä»ç†è®ºä¸Šä¿è¯äº†æ— åæ€§ä¸ä¸€è‡´æ€§ï¼›å±€éƒ¨ç†µåˆ™æ•æ‰å³æ—¶çš„ä¸ç¡®å®šæ€§æ³¢åŠ¨ã€‚äºŒè€…ç»“åˆè®©è§£ç æ›´é²æ£’ï¼ŒåŒæ—¶å…¼é¡¾ç»Ÿè®¡æ€§è´¨ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šåŸºäºGlocalä¸ç¡®å®šæ€§çš„è‡ªé€‚åº”è§£ç ç­–ç•¥  
GUARDåœ¨å¯¹æ¯”æœç´¢ï¼ˆCSï¼‰åŸºç¡€ä¸Šï¼Œé€šè¿‡â€œå…¨å±€-å±€éƒ¨â€ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´è§£ç å‚æ•°ï¼Œæ— éœ€ä¾èµ–å›ºå®šè¶…å‚æ•°ã€‚æ­¤å¤–ï¼Œä¸ºé™ä½è®¡ç®—å¼€é”€ï¼Œå¼•å…¥**åŸºäºtokenè®¡æ•°çš„æƒ©ç½šæœºåˆ¶**ï¼Œåœ¨ä¸æŸå¤±æ•ˆæœçš„å‰æä¸‹å¤§å¹…å‡å°‘æ¨ç†æ—¶çš„è®¡ç®—æˆæœ¬ã€‚  


### ğŸ“ˆ å®éªŒç»“æœ
å®éªŒä»å¤šç»´åº¦éªŒè¯äº†GUARDçš„æ€§èƒ½ï¼š  
- **æ–‡æœ¬è´¨é‡å¹³è¡¡**ï¼šåœ¨å¤šæ ·æ€§ä¸è¿è´¯æ€§çš„æƒè¡¡ä¸Šè¡¨ç°æ›´ä¼˜ï¼Œäººç±»ä¸LLMè¯„ä¼°å‡éªŒè¯äº†å…¶ç”Ÿæˆæ–‡æœ¬çš„é«˜è´¨é‡ï¼›  
- **ç”Ÿæˆé€Ÿåº¦æå‡**ï¼šç›¸æ¯”(A)CSç­‰æ–¹æ³•ï¼ŒGUARDé€šè¿‡tokenè®¡æ•°æƒ©ç½šæ˜¾è‘—é™ä½äº†å»¶è¿Ÿä¸è®¡ç®—æˆæœ¬ï¼›  
- **é²æ£’æ€§éªŒè¯**ï¼šå…¨å±€ç†µå…¬å¼æœ‰æ•ˆå¹³æ»‘äº†ä¸ç¡®å®šæ€§çš„çªå˜ï¼Œä¿è¯äº†æ— åæ€§ä¸ä¸€è‡´æ€§ç­‰ç»Ÿè®¡æ€§è´¨ã€‚  


### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **ä¸ç¡®å®šæ€§å»ºæ¨¡æ€è·¯**ï¼šå°†å…¨å±€ä¸å±€éƒ¨ä¸ç¡®å®šæ€§ç»“åˆï¼Œä¸ºå¤„ç†åºåˆ—ç”Ÿæˆä¸­çš„åŠ¨æ€æ³¢åŠ¨æä¾›äº†æ–°èŒƒå¼ï¼Œå¯å¯å‘å…¶ä»–éœ€å¹³è¡¡é•¿çŸ­æœŸä¿¡å·çš„ä»»åŠ¡ï¼›  
2. **è½»é‡é«˜æ•ˆè®¾è®¡**ï¼šé€šè¿‡ç®€å•çš„tokenè®¡æ•°æƒ©ç½šé™ä½è®¡ç®—å¼€é”€ï¼Œè¯æ˜â€œè½»é‡ä¿®æ”¹+ç†è®ºä¿éšœâ€èƒ½åœ¨å¤æ‚è§£ç ä»»åŠ¡ä¸­å®ç°æ•ˆç‡çªç ´ï¼›  
3. **å¤šç»´åº¦è¯„ä¼°ä½“ç³»**ï¼šç»“åˆè‡ªåŠ¨ã€äººç±»ä¸LLMè¯„ä¼°ï¼Œä¸ºæ–‡æœ¬ç”Ÿæˆä»»åŠ¡çš„æ•ˆæœéªŒè¯æä¾›äº†æ›´å…¨é¢çš„å‚è€ƒèŒƒå¼ã€‚  

GUARDä¸ä»…åœ¨æŠ€æœ¯ä¸Šè§£å†³äº†å¼€æ”¾æ–‡æœ¬ç”Ÿæˆçš„æ ¸å¿ƒç—›ç‚¹ï¼Œå…¶â€œå…¨å±€-å±€éƒ¨â€ä¸ç¡®å®šæ€§æ¡†æ¶ä¸è½»é‡é«˜æ•ˆè®¾è®¡æ€è·¯ï¼Œä¹Ÿä¸ºåç»­è§£ç ç­–ç•¥ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚ä»£ç å·²å¼€æºï¼ˆhttps://github.com/YecanLee/GUARDï¼‰ï¼Œæ„Ÿå…´è¶£çš„å¼€å‘è€…å¯è¿›ä¸€æ­¥æ¢ç´¢~

## token-buncher--shielding-llms-from-harmful-reinforcement-learning-fine-tuning
### Abstract
As large language models (LLMs) continue to grow in capability, so do the
risks of harmful misuse through fine-tuning. While most prior studies assume
that attackers rely on supervised fine-tuning (SFT) for such misuse, we
systematically demonstrate that reinforcement learning (RL) enables adversaries
to more effectively break safety alignment and facilitate advanced harmful task
assistance, under matched computational budgets. To counter this emerging
threat, we propose TokenBuncher, the first effective defense specifically
targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation
on which RL relies: model response uncertainty. By constraining uncertainty,
RL-based fine-tuning can no longer exploit distinct reward signals to drive the
model toward harmful behaviors. We realize this defense through
entropy-as-reward RL and a Token Noiser mechanism designed to prevent the
escalation of expert-domain harmful capabilities. Extensive experiments across
multiple models and RL algorithms show that TokenBuncher robustly mitigates
harmful RL fine-tuning while preserving benign task utility and finetunability.
Our results highlight that RL-based harmful fine-tuning poses a greater
systemic risk than SFT, and that TokenBuncher provides an effective and general
defense.
### ğŸŒŸ è®ºæ–‡è§£è¯» | Token Buncherï¼šæŠµå¾¡å¤§æ¨¡å‹æœ‰å®³å¼ºåŒ–å­¦ä¹ å¾®è°ƒçš„æ–°é˜²çº¿

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½åŠ›ä¸æ–­æå‡ï¼Œé€šè¿‡å¾®è°ƒè¿›è¡Œæœ‰å®³æ»¥ç”¨çš„é£é™©ä¹Ÿä¸æ—¥ä¿±å¢ã€‚è¿‡å¾€ç ”ç©¶å¤šå‡è®¾æ”»å‡»è€…åˆ©ç”¨æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å®æ–½æ»¥ç”¨ï¼Œä½†å®é™…ä¸Šå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹ï¼Œèƒ½è®©æ”»å‡»è€…æ›´é«˜æ•ˆçªç ´å®‰å…¨å¯¹é½æœºåˆ¶ã€åŠ©åŠ›å¤æ‚æœ‰å®³ä»»åŠ¡ã€‚ç„¶è€Œç°æœ‰é’ˆå¯¹æœ‰å®³SFTçš„é˜²å¾¡éš¾ä»¥åº”å¯¹æœ‰å®³RLï¼Œä¸”æœ‰å®³RLè¿˜å­˜åœ¨èƒ½åŠ›æ”¾å¤§é£é™©ï¼Œå°é˜²å¾¡å¤±è¯¯å°±å¯èƒ½é€ æˆå¤§å±å®³ï¼ŒåŒæ—¶ç°æœ‰é˜²å¾¡æœªå…³æ³¨æœ‰å®³èƒ½åŠ›å‡çº§ç»´åº¦ã€‚åŸºäºæ­¤ï¼Œè®ºæ–‡å¼€å±•ä¸¤æ–¹é¢ç ”ç©¶ï¼šä¸€æ˜¯å¯¹æ¯”æœ‰å®³RLä¸æœ‰å®³SFTå±é™©æ€§ï¼›äºŒæ˜¯æ¢ç´¢æœ‰æ•ˆé˜²å¾¡æœ‰å®³RLçš„æ–¹æ³•ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šé’ˆå¯¹æœ‰å®³RLé˜²å¾¡ï¼Œä»RLä¾èµ–åŸç†å…¥æ‰‹æŠ‘åˆ¶ä¸ç¡®å®šæ€§  
RLä¾é æ¨¡å‹å“åº”ä¸ç¡®å®šæ€§æ¥æ¢ç´¢å¤šæ ·å€™é€‰å“åº”ï¼Œæ”»å‡»è€…å€Ÿæ­¤åˆ†é…ä¸åŒå¥–åŠ±è®­ç»ƒæ¨¡å‹ã€‚Token Buncheræå‡ºåœ¨å¤„ç†æœ‰å®³æŸ¥è¯¢æ—¶æœ€å°åŒ–å“åº”ç†µæ¥é™åˆ¶æ¨¡å‹å“åº”ä¸ç¡®å®šæ€§ï¼Œè®©RLæ— æ³•åˆ©ç”¨ä¸åŒå¥–åŠ±ä¿¡å·å¼•å¯¼æ¨¡å‹èµ°å‘æœ‰å®³è¡Œä¸ºã€‚ä¸ºæå‡æ³›åŒ–æ€§ï¼Œé‡‡ç”¨ä»¥ç†µä¸ºå¥–åŠ±çš„åœ¨çº¿RLæ–¹å¼ï¼Œæ— éœ€é¢å¤–æ•°æ®æ”¶é›†å¤„ç†ï¼Œå¢å¼ºé˜²å¾¡æ³›åŒ–ä¸é²æ£’æ€§ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šToken Noiseræœºåˆ¶åº”å¯¹æœ‰å®³èƒ½åŠ›å‡çº§  
ä¸ºåº”å¯¹æœ‰å®³RLèƒ½åŠ›æ”¾å¤§é£é™©ï¼Œè®¾è®¡Token Noiseræœºåˆ¶ã€‚åœ¨å¤„ç†æœ‰å®³æŸ¥è¯¢æ—¶ï¼Œå‘ä½logit tokençš„æ¦‚ç‡è´¨é‡æ³¨å…¥å°éšæœºæ‰°åŠ¨ã€‚æ­£å¸¸ç”Ÿæˆæ—¶è¿™äº›tokenå æ¯”å°ï¼Œä¸å½±å“è‰¯æ€§æ€§èƒ½ï¼›å½“æœ‰å®³RLæ”¹å˜åˆ†å¸ƒå°†æ¦‚ç‡æ¨å‘ä½logitåŒºåŸŸæ—¶ï¼Œæ³¨å…¥çš„å™ªå£°è¢«æ”¾å¤§ï¼Œä½¿æ¨¡å‹æ‰§è¡Œæœ‰å®³ä»»åŠ¡çš„èƒ½åŠ›å´©æºƒï¼Œè‡ªåŠ¨æŠ‘åˆ¶æœ‰å®³èƒ½åŠ›å‡çº§ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
è®ºæ–‡åœ¨å¤šæ¨¡å‹å’ŒRLç®—æ³•ä¸Šå¼€å±•å¤§é‡å®éªŒã€‚å¯¹æ¯”æœ‰å®³SFTä¸æœ‰å®³RLï¼Œå‘ç°æœ‰å®³RLåœ¨è®©æ¨¡å‹å“åº”æœ‰å®³æŸ¥è¯¢æ¦‚ç‡ã€ä¿ç•™æ¨¡å‹é€šç”¨èƒ½åŠ›ã€å¢å¼ºå¤æ‚æœ‰å®³ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ï¼ˆåœ¨ç”Ÿç‰©ã€åŒ–å­¦ã€ç½‘ç»œå®‰å…¨é¢†åŸŸåˆ†åˆ«æå‡6.4%ã€18.2%ã€33.4%ï¼‰ç­‰æ–¹é¢è¡¨ç°æ›´ä¼˜ï¼Œè¯æ˜å…¶é£é™©æ›´å¤§ã€‚è€ŒToken Buncherèƒ½ç¨³å¥ç¼“è§£æœ‰å®³RLå¾®è°ƒå½±å“ï¼ŒåŒæ—¶ä¿ç•™è‰¯æ€§ä»»åŠ¡æ•ˆç”¨ä¸å¯å¾®è°ƒæ€§ï¼ŒéªŒè¯äº†é˜²å¾¡æœ‰æ•ˆæ€§ä¸é€šç”¨æ€§ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. ç ”ç©¶è§†è§’åˆ›æ–°ï¼šé¦–æ¬¡ç³»ç»Ÿå¯¹æ¯”æœ‰å®³RLä¸æœ‰å®³SFTé£é™©ï¼Œæ­ç¤ºRLé©±åŠ¨çš„æœ‰å®³å¾®è°ƒæ›´å¤§ç³»ç»Ÿæ€§é£é™©ï¼Œä¸ºå¤§æ¨¡å‹å®‰å…¨ç ”ç©¶æ‹“å±•æ–¹å‘ï¼Œæé†’ç ”ç©¶è€…å…³æ³¨RLå±‚é¢å®‰å…¨å¨èƒã€‚  
2. é˜²å¾¡æ€è·¯åˆ›æ–°ï¼šä»RLä¾èµ–çš„ä¸ç¡®å®šæ€§æœ¬è´¨å‡ºå‘è®¾è®¡é˜²å¾¡ï¼Œè¿˜ç»“åˆèƒ½åŠ›æŠ‘åˆ¶ç»´åº¦åº”å¯¹æœ‰å®³èƒ½åŠ›å‡çº§ï¼Œä¸ºå¯¹æŠ—åŸºäºRLçš„æ¨¡å‹æ»¥ç”¨æä¾›å…¨æ–°æœ‰æ•ˆèŒƒå¼ï¼Œç›¸å…³æœºåˆ¶è®¾è®¡ï¼ˆå¦‚ç†µä½œä¸ºå¥–åŠ±çš„åœ¨çº¿RLã€Token Noiserï¼‰å¯ä¸ºåç»­é˜²å¾¡æ–¹æ³•æä¾›æŠ€æœ¯å‚è€ƒã€‚  
3. å®éªŒå…¨é¢æ€§ï¼šå¤šæ¨¡å‹å¤šç®—æ³•å®éªŒéªŒè¯ï¼Œä¸ºç»“è®ºå¯é æ€§æä¾›æ”¯æ’‘ï¼Œä¹Ÿä¸ºåç»­åŒç±»ç ”ç©¶å®éªŒè®¾è®¡æä¾›èŒƒä¾‹ï¼Œå±•ç¤ºå¦‚ä½•å…¨é¢è¯„ä¼°é˜²å¾¡æ–¹æ³•åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°ã€‚ 

## scitopic--enhancing-topic-discovery-in-scientific-literature-through-advanced-llm
### Abstract
Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.
### ğŸŒŸ è®ºæ–‡è§£è¯» | SciTopicï¼šå€ŸåŠ©å…ˆè¿›å¤§è¯­è¨€æ¨¡å‹æå‡ç§‘å­¦æ–‡çŒ®ä¸»é¢˜å‘ç°èƒ½åŠ›

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
éšç€ç§‘å­¦å‰æ²¿ä¸æ–­æ‹“å±•ï¼Œç§‘ç ”æ–‡çŒ®æ•°é‡çˆ†ç‚¸å¼å¢é•¿ï¼Œä¼ ç»Ÿä¿¡æ¯æ£€ç´¢ä¸ä¸»é¢˜å‘ç°æ–¹æ³•ï¼ˆå¦‚ä¾èµ–è¯åµŒå…¥çš„æŠ€æœ¯ã€ç»å…¸ä¸»é¢˜æ¨¡å‹LDAç­‰ï¼‰å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼šè¦ä¹ˆéš¾ä»¥æ•æ‰å¤æ‚è¯­ä¹‰å’Œé«˜ç»´æ–‡æœ¬å…³ç³»ï¼Œè¦ä¹ˆåœ¨é™ç»´ç­‰æ“ä½œä¸­ä¸¢å¤±å…³é”®ä¿¡æ¯ï¼Œæ— æ³•å…¨é¢ç†è§£ç§‘ç ”æ–‡çŒ®å†…æ¶µï¼Œä¹Ÿéš¾ä»¥åº”å¯¹è·¨é¢†åŸŸã€æ–°å…´äº¤å‰æ–¹å‘çš„ä¸»é¢˜æŒ–æ˜éœ€æ±‚ã€‚å› æ­¤ï¼Œè¿«åˆ‡éœ€è¦æ›´é«˜æ•ˆçš„è‡ªåŠ¨åŒ–ç§‘å­¦ä¸»é¢˜å‘ç°æ–¹æ³•æ¥å¤„ç†ç°ä»£ç§‘ç ”æ–‡çŒ®çš„å¤æ‚åº¦ä¸è§„æ¨¡ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¢å¼ºçš„ä¸»é¢˜å‘ç°æ¡†æ¶SciTopic  
é¦–å…ˆæ‰“é€ æ–‡æœ¬ç¼–ç å™¨ï¼Œä»ç§‘ç ”æ–‡çŒ®çš„å…ƒæ•°æ®ã€æ ‡é¢˜ã€æ‘˜è¦ç­‰å¤šç»´åº¦æ•æ‰å†…å®¹ï¼Œæå–å¯¹ä¸»é¢˜è¯†åˆ«å…³é”®çš„æ–‡æœ¬ç‰¹å¾ï¼›å†å¼•å…¥ç”±LLMå¼•å¯¼çš„èšç±»æŠ€æœ¯ï¼Œç»“åˆåŸºäºç†µçš„é‡‡æ ·å’Œä¸‰å…ƒç»„ä»»åŠ¡ï¼Œä¸»åŠ¨è®©LLMå‚ä¸èšç±»è¿‡ç¨‹ï¼Œèšç„¦æ¨¡ç³Šã€ä¸ç¡®å®šçš„æ–‡æ¡£æ¥ä¼˜åŒ–èšç±»æ•ˆæœã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šè®¾è®¡LLMé©±åŠ¨çš„ä¸‰å…ƒç»„ä»»åŠ¡ä¸å¾®è°ƒç­–ç•¥  
é’ˆå¯¹LLMè®¾è®¡åŸºäºæç¤ºçš„ä¸‰å…ƒç»„ä»»åŠ¡ï¼ŒåŒºåˆ†è¯­ä¹‰ç›¸è¿‘çš„ç§‘ç ”æ–‡æ¡£ï¼›åˆ©ç”¨LLMç”Ÿæˆçš„å“åº”æ¥å¾®è°ƒåµŒå…¥æ¨¡å‹ï¼Œè®©æ–‡æ¡£è¡¨ç¤ºæ›´å…·åŒºåˆ†åº¦ã€‚åŒæ—¶ï¼ŒåŸºäºç†µçš„é‡‡æ ·ç­–ç•¥èƒ½ç­›é€‰å‡ºèšç±»å½’å±æœ€æ¨¡ç³Šçš„é«˜ç†µæ–‡æ¡£ä½œä¸ºä¸‰å…ƒç»„é”šç‚¹ï¼Œå€ŸåŠ©LLMåˆ†æä¸‰å…ƒç»„æ¥ä¼˜åŒ–æ–‡æ¡£åµŒå…¥ï¼Œæ—¢æå‡ç²¾åº¦åˆå‡å°‘è®¡ç®—å¼€é”€ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šèšç„¦æ¨¡ç³Šæ¡ˆä¾‹ä¼˜åŒ–æ–‡æ¡£åµŒå…¥  
é€šè¿‡ç†µé‡‡æ ·é”å®šèšç±»ä¸­æœ€â€œæ‹¿ä¸å‡†â€çš„æ–‡æ¡£ï¼Œå†ç”¨è¿™äº›æ–‡æ¡£æ„å»ºä¸‰å…ƒç»„ä»»åŠ¡ï¼Œè®©LLMæŒ‡å¯¼ä¼˜åŒ–æ–‡æœ¬ç¼–ç å™¨çš„å¯¹æ¯”æŸå¤±ï¼Œè¿«ä½¿ç¼–ç å™¨æ›´ç²¾å‡†åŒºåˆ†ä¸åŒä¸»é¢˜å®ä¾‹ï¼Œä»è€Œåœ¨å¤æ‚åœºæ™¯ä¸‹ä¹Ÿèƒ½æ•æ‰ç»†å¾®ä¸»é¢˜å·®å¼‚ï¼Œè®©èšç±»ç»“æœåœ¨ä¸»é¢˜è¿è´¯æ€§ä¸ä¸Šä¸‹æ–‡å‡†ç¡®æ€§ä¸Šæ›´å‡ºè‰²ã€‚  


### ğŸ“ˆ å®éªŒç»“æœ
åœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œçš„ç§‘ç ”æ–‡çŒ®æ•°æ®é›†ï¼ˆå«ä¸“é—¨ä¸ºç ”ç©¶æ„å»ºçš„æ•°æ®é›†ï¼‰ä¸Šå¼€å±•å¤§é‡å®éªŒï¼Œç»“æœè¡¨æ˜SciTopicåœ¨ä¸»é¢˜ä¸èšç±»ç›¸å…³çš„è¯„ä¼°æŒ‡æ ‡ä¸Šï¼ŒæŒç»­è¶…è¶Šå½“å‰æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„ç§‘å­¦ä¸»é¢˜å‘ç°æ–¹æ³•ï¼Œèƒ½å¸®åŠ©ç ”ç©¶è€…æ›´é«˜æ•ˆã€æ›´æ·±å…¥åœ°æ´å¯Ÿç§‘ç ”ä¸»é¢˜è¶‹åŠ¿ã€‚  


### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. è·¨æ¨¡å—ååŒæ€è·¯ï¼šå°†æ–‡æœ¬ç¼–ç ã€LLMå¼•å¯¼ã€é‡‡æ ·ç­–ç•¥ã€ä¸‰å…ƒç»„ä»»åŠ¡ç­‰æ¨¡å—æœ‰æœºç»“åˆï¼Œä¸ºå¤æ‚åœºæ™¯ä¸‹çš„ä¸»é¢˜å‘ç°æä¾›äº†â€œå¤šç¯èŠ‚åä½œä¼˜åŒ–â€çš„èŒƒå¼å‚è€ƒã€‚  
2. æ¨¡ç³Šæ¡ˆä¾‹åˆ©ç”¨ï¼šé€šè¿‡ç†µé‡åŒ–æ–‡æ¡£èšç±»æ¨¡ç³Šåº¦ï¼Œå¹¶é’ˆå¯¹æ€§åœ°ç”¨è¿™äº›æ¡ˆä¾‹é©±åŠ¨æ¨¡å‹ä¼˜åŒ–ï¼Œä¸ºå¤„ç†é«˜ä¸ç¡®å®šæ€§ã€é«˜æ··æ·†åº¦çš„æ•°æ®æä¾›äº†å€Ÿé‰´æ–¹å‘ã€‚  
3. LLMè½åœ°åœºæ™¯æ‹“å±•ï¼šå±•ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹åœ¨ç§‘ç ”ä¸»é¢˜å‘ç°è¿™ç±»ä¸“ä¸šé¢†åŸŸä»»åŠ¡ä¸­â€œç†è§£å¤æ‚è¯­ä¹‰+æŒ‡å¯¼æ¨¡å‹ä¼˜åŒ–â€çš„è½åœ°è·¯å¾„ï¼Œä¸ºLLMåœ¨å‚ç›´é¢†åŸŸçš„æŠ€æœ¯åˆ›æ–°æä¾›å¯å‘ã€‚  

## automated-quality-assessment-for-llm-based-complex-qualitative-coding--a-confidence-diversity-framework
### Abstract
While previous research demonstrated effective automated quality assessment
for accessible LLM coding tasks, a fundamental question remains: can
confidence-diversity frameworks maintain reliability for complex analytical
tasks requiring specialized domain expertise and extensive text comprehension?
Traditional inter-coder reliability measures become prohibitively expensive at
scale, yet the lack of reliable automated quality assessment methods creates
methodological barriers to AI adoption in sophisticated qualitative research.
This study extends dual-signal quality assessment combining model confidence
and inter-model consensus from accessible to complex analytical domains. We
systematically validate this approach across three domains: legal reasoning
(390 Supreme Court cases), political analysis (645 hyperpartisan articles), and
medical classification (1,000 clinical transcripts). Results demonstrate that
uncertainty-based indicators maintain predictive validity in complex tasks,
with external entropy showing consistent negative correlations with accuracy (r
= -0.179 to -0.273, p < 0.001) and confidence exhibiting positive correlations
in two domains (r = 0.104 to 0.429). Systematic weight optimization achieves
6.6 to 113.7 percent improvements over single-signal approaches, with optimized
weights transferring effectively across domains (100 percent success rate). An
intelligent triage system reduces manual verification effort by 44.6 percent
while maintaining quality standards. These findings establish that automated
quality assessment can scale from accessible to complex analytical tasks,
providing practical tools for expanding AI-assisted qualitative research.
Future work will focus on addressing long-tail challenges in high-disagreement,
low-confidence cases to further enhance screening efficiency.
### ğŸŒŸ è®ºæ–‡è§£è¯» | LLMå¤æ‚å®šæ€§ç¼–ç çš„è‡ªåŠ¨è´¨é‡è¯„ä¼°ï¼šç½®ä¿¡åº¦-å¤šæ ·æ€§æ¡†æ¶

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨æ•°å­—ç¤¾ä¼šç”Ÿæ´»å¸¦æ¥æµ·é‡æ–‡æœ¬æ•°æ®çš„èƒŒæ™¯ä¸‹ï¼Œç¤¾ä¼šç§‘å­¦ç ”ç©¶é¢ä¸´ç€åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šç»´æŒå®šæ€§ç ”ç©¶ä¸¥è°¨è´¨é‡æ ‡å‡†çš„æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„ç¼–ç è€…é—´ä¿¡åº¦æµ‹é‡ï¼ˆå¦‚Cohenâ€™s Îºã€Krippendorffâ€™s Î±ï¼‰åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸‹æˆæœ¬è¿‡é«˜ä¸”åå‹¤éš¾åº¦å¤§ï¼Œæˆä¸ºå®šæ€§ç ”ç©¶æ‹“å±•çš„ç“¶é¢ˆã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºå®šæ€§åˆ†æè§„æ¨¡åŒ–å¸¦æ¥å¯èƒ½ï¼Œä½†é’ˆå¯¹éœ€è¦ä¸“ä¸šé¢†åŸŸçŸ¥è¯†å’Œå¤§é‡æ–‡æœ¬ç†è§£çš„å¤æ‚åˆ†æä»»åŠ¡ï¼Œç¼ºä¹å¯é çš„è‡ªåŠ¨è´¨é‡è¯„ä¼°æ–¹æ³•ï¼Œé™åˆ¶äº†AIåœ¨å¤æ‚å®šæ€§ç ”ç©¶ä¸­çš„åº”ç”¨ã€‚æœ¬æ–‡æ—¨åœ¨å¼€å‘å¹¶éªŒè¯AIè¾…åŠ©å®šæ€§ç¼–ç ä¸­è‡ªåŠ¨è´¨é‡è¯„ä¼°çš„æ¡†æ¶ï¼Œè§£å†³ä¸Šè¿°éš¾é¢˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ‹“å±•åŒä¿¡å·è´¨é‡è¯„ä¼°æ¡†æ¶  
åŸºäºæ­¤å‰åœ¨æ˜“å¤„ç†ä»»åŠ¡ä¸Šçš„ç½®ä¿¡åº¦ - å¤šæ ·æ€§æ ¡å‡†å·¥ä½œï¼Œå°†ç»“åˆæ¨¡å‹ç½®ä¿¡åº¦å’Œæ¨¡å‹é—´ä¸€è‡´æ€§çš„åŒä¿¡å·è´¨é‡è¯„ä¼°ä»æ˜“å¤„ç†é¢†åŸŸæ‹“å±•åˆ°å¤æ‚åˆ†æé¢†åŸŸã€‚è¯¥æ¡†æ¶åˆ©ç”¨äº’è¡¥çš„ä¸ç¡®å®šæ€§ä¿¡å·ï¼ˆæ¨¡å‹é—´å…±è¯†å’Œè‡ªæˆ‘è¯„ä¼°ç½®ä¿¡åº¦ï¼‰æ¥é¢„æµ‹ç ”ç©¶å¯é æ€§ï¼Œä¸”æ— éœ€çœŸå®æ ‡ç­¾éªŒè¯ï¼Œä»…ä¾èµ–æ¨¡å‹ç”ŸæˆæŒ‡æ ‡ï¼Œä¿ç•™AIè¾…åŠ©ç¼–ç çš„å¯æ‰©å±•æ€§ä¼˜åŠ¿ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç³»ç»Ÿæ€§éªŒè¯ä¸è·¨åŸŸä¼˜åŒ–  
é’ˆå¯¹æ³•å¾‹æ¨ç†ã€æ”¿æ²»åˆ†æã€åŒ»ç–—åˆ†ç±»ä¸‰ä¸ªé¢†åŸŸï¼ˆåˆ†åˆ«ä½¿ç”¨æœ€é«˜æ³•é™¢æ¡ˆä¾‹ã€æç«¯å…šæ´¾æ–‡ç« ã€ä¸´åºŠè®°å½•æ•°æ®é›†ï¼‰ç³»ç»ŸéªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ï¼›é€šè¿‡ç³»ç»Ÿæ€§æƒé‡ä¼˜åŒ–ç¡®å®šåŒä¿¡å·è´¨é‡æŒ‡æ ‡çš„æœ€ä¼˜æƒé‡ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§ï¼Œè¿˜éªŒè¯ä¼˜åŒ–åçš„æƒé‡åœ¨è·¨é¢†åŸŸé—´çš„æœ‰æ•ˆè¿ç§»èƒ½åŠ›ï¼›è®¾è®¡æ™ºèƒ½åˆ†æµç³»ç»Ÿï¼Œåœ¨ç»´æŒè´¨é‡æ ‡å‡†çš„åŒæ—¶å‡å°‘äººå·¥éªŒè¯å·¥ä½œé‡ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
1. ä¸ç¡®å®šæ€§æŒ‡æ ‡åœ¨å¤æ‚ä»»åŠ¡ä¸­ä¿æŒé¢„æµ‹æœ‰æ•ˆæ€§ï¼šå¤–éƒ¨ç†µä¸å‡†ç¡®ç‡å‘ˆæŒç»­è´Ÿç›¸å…³ï¼ˆr = -0.179 è‡³ -0.273ï¼Œp < 0.001ï¼‰ï¼Œç½®ä¿¡åº¦åœ¨ä¸¤ä¸ªé¢†åŸŸå‘ˆæ­£ç›¸å…³ï¼ˆr = 0.104 è‡³ 0.429ï¼‰ã€‚  
2. ç³»ç»Ÿæ€§æƒé‡ä¼˜åŒ–æ¯”å•ä¿¡å·æ–¹æ³•æå‡ 6.6 - 113.7%ï¼Œä¸”ä¼˜åŒ–åçš„æƒé‡è·¨é¢†åŸŸæœ‰æ•ˆè¿ç§»ï¼ˆæˆåŠŸç‡ 100%ï¼‰ã€‚  
3. æ™ºèƒ½åˆ†æµç³»ç»Ÿåœ¨ç»´æŒè´¨é‡æ ‡å‡†æ—¶å‡å°‘ 44.6% çš„äººå·¥éªŒè¯å·¥ä½œé‡ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. æ–¹æ³•æ‹“å±•æ€§ï¼šè¯æ˜è‡ªåŠ¨è´¨é‡è¯„ä¼°å¯ä»æ˜“å¤„ç†ä»»åŠ¡æ‹“å±•åˆ°å¤æ‚åˆ†æä»»åŠ¡ï¼Œä¸ºAIè¾…åŠ©å®šæ€§ç ”ç©¶æä¾›å®ç”¨å·¥å…·ï¼Œä¸ºç¤¾ä¼šç§‘å­¦ç­‰é¢†åŸŸåœ¨å¤§è§„æ¨¡å¤æ‚æ•°æ®ä¸Šå¼€å±•å®šæ€§ç ”ç©¶æä¾›äº†æ–¹æ³•è·¯å¾„å‚è€ƒã€‚  
2. è·¨åŸŸä¸ä¼˜åŒ–æ€è·¯ï¼šæƒé‡ä¼˜åŒ–ä¸è·¨åŸŸè¿ç§»çš„å®è·µï¼Œä¸ºå¤šé¢†åŸŸä¸‹åŸºäºLLMçš„ä»»åŠ¡è´¨é‡è¯„ä¼°æä¾›äº†â€œä¼˜åŒ– - è¿ç§»â€çš„æŠ€æœ¯å€Ÿé‰´ï¼Œå¯å¯å‘åç»­åœ¨ä¸åŒé¢†åŸŸç»“åˆLLMå¼€å±•è‡ªåŠ¨è´¨é‡è¯„ä¼°æ—¶çš„å·¥ä½œæµç¨‹ã€‚  
3. ç³»ç»Ÿè®¾è®¡ï¼šæ™ºèƒ½åˆ†æµç³»ç»Ÿçš„è®¾è®¡æ€è·¯ï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡è‡ªåŠ¨è´¨é‡è¯„ä¼°æ¥å‡å°‘äººå·¥æˆæœ¬ï¼Œåœ¨éœ€è¦äººå·¥ä»‹å…¥éªŒè¯è´¨é‡çš„åœºæ™¯ï¼ˆå¦‚åŒ»ç–—ã€æ³•å¾‹ç­‰ä¸“ä¸šé¢†åŸŸï¼‰ï¼Œè¿™ç§æ€è·¯å¯ç”¨äºæ„å»ºé«˜æ•ˆçš„äººæœºåä½œæµç¨‹ã€‚

## measuring-reasoning-utility-in-llms-via-conditional-entropy-reduction
### Abstract
Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ç”¨æ¡ä»¶ç†µè¡°å‡è¡¡é‡å¤§æ¨¡å‹æ¨ç†æœ‰æ•ˆæ€§ï¼šæ­ç¤ºæ¨ç†é“¾ä¸ç­”æ¡ˆæ­£ç¡®æ€§çš„å…³è”

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ï¼ŒChain-of-Thoughtï¼ˆCoTï¼‰ç­‰ç”Ÿæˆä¸­é—´æ¨ç†æ­¥éª¤çš„æ–¹æ³•è™½èƒ½æå‡å‡†ç¡®ç‡ï¼Œä½†â€œæ¨ç†æ­¥éª¤å¯¹æœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ€§çš„è´¡çŒ®ï¼ˆå³æ¨ç†æ•ˆç”¨ï¼‰â€å´ç¼ºä¹æ·±å…¥ç ”ç©¶ã€‚ç”±äºè‡ªå›å½’ç”Ÿæˆçš„éšæœºæ€§ï¼Œç”Ÿæˆæ›´å¤šä¸Šä¸‹æ–‡ä¸ä»£è¡¨ç­”æ¡ˆç½®ä¿¡åº¦æ›´é«˜ã€‚è‹¥èƒ½åœ¨ç”Ÿæˆæ—¶é¢„åˆ¤æ¨ç†æ­¥éª¤æ˜¯å¦æœ‰ç”¨ï¼Œå°±èƒ½æå‰ç»ˆæ­¢æ— æ•ˆæ­¥éª¤ã€å‡å°‘å¹²æ‰°ä¸è®¡ç®—æˆæœ¬ã€‚è€Œè¿‡å¾€è¡¡é‡æ¨ç†æ•ˆç”¨çš„å·¥ä½œç¨€ç¼ºï¼šåŸºäºæ¨¡å‹çš„æ–¹æ³•ä¾èµ–éªŒè¯å™¨æˆ–å¥–åŠ±æ¨¡å‹ï¼ŒåŸºäºæŒ‡æ ‡çš„æ–¹æ³•ï¼ˆå¦‚ç›¸ä¼¼åº¦ã€ç½®ä¿¡åº¦ï¼‰è¦ä¹ˆå’Œå‡†ç¡®ç‡å…³è”å¼±ï¼Œè¦ä¹ˆç¼ºä¹å¯¹â€œæ¨ç†è¿‡ç¨‹ä¸­æ¨¡å‹ä¸ç¡®å®šæ€§æ¼”å˜ä¸å‡†ç¡®ç‡å…³è”â€çš„ç³»ç»Ÿç ”ç©¶ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨æ¢ç´¢æ¨ç†è¿‡ç¨‹ä¸­æ¨¡å‹ä¸ç¡®å®šæ€§çš„å˜åŒ–è½¨è¿¹ï¼ŒåŠå…¶ä¸ç­”æ¡ˆæ­£ç¡®æ€§çš„å…³ç³»ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šç”¨æ¡ä»¶ç†µé‡åŒ–æ¨ç†æ•ˆç”¨  
ä»ä¿¡æ¯è®ºè§’åº¦ï¼Œå°†æ¨ç†é“¾Zå¯¹æœ€ç»ˆç­”æ¡ˆYçš„æ•ˆç”¨å½¢å¼åŒ–ä¸º**æ¡ä»¶äº’ä¿¡æ¯** \( I(Y ; Z|X) = H(Y | X) âˆ’ H(Y | X, Z) \)ï¼Œå³æ¨ç†é“¾Zèƒ½è®©æ¨¡å‹å¯¹ç­”æ¡ˆYçš„ä¸ç¡®å®šæ€§ï¼ˆæ¡ä»¶ç†µï¼‰é™ä½å¤šå°‘ã€‚è‹¥æ¡ä»¶ç†µä¸‹é™å¤šï¼ˆ\(\Delta H\) å¤§ï¼‰ï¼Œè¯´æ˜æ¨ç†é“¾æä¾›äº†æœ‰ç”¨ä¿¡æ¯ï¼›è‹¥ä¸‹é™å°‘ï¼ˆ\(\Delta H \approx 0\)ï¼‰ï¼Œåˆ™æ¨ç†é“¾ä»·å€¼ä½ã€‚ä¸ºäº†å®æ“ï¼Œç”¨**æ•™å¸ˆå¼ºåˆ¶ï¼ˆteacher forcingï¼‰** ä¼°è®¡æ¡ä»¶ç†µï¼šåœ¨æ¨ç†çš„ç¬¬kæ­¥ï¼Œç»™æ¨¡å‹è¾“å…¥â€œé—®é¢˜ä¸Šä¸‹æ–‡+å‰kæ­¥æ¨ç†é“¾â€ï¼Œè®¡ç®—æ¨¡å‹å¯¹ç­”æ¡ˆåºåˆ—æ¯ä¸ªtokençš„é¢„æµ‹åˆ†å¸ƒçš„ç†µï¼Œå†å¹³å‡å¾—åˆ°åºåˆ—çº§æ¡ä»¶ç†µ \( H(Y | C) \)ï¼Œä»¥æ­¤åæ˜ æ¨¡å‹å¯¹ç­”æ¡ˆçš„å¹³å‡ä¸ç¡®å®šæ€§ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæ¨ç†é“¾çš„ç†µè½¨è¿¹åˆ†æ  
å°†æ¨ç†é“¾Zåˆ†è§£ä¸ºKæ­¥ï¼Œè®¡ç®—æ¯ä¸€æ­¥kï¼ˆ\( k = 0,1,...,K \)ï¼‰å¯¹åº”çš„æ¡ä»¶ç†µ \( H(Y | X, Z_{\leq k}) \)ï¼Œå¾—åˆ°**ç†µè½¨è¿¹**â€”â€”å®ƒåæ˜ äº†æ¨ç†è¿‡ç¨‹ä¸­æ¨¡å‹å¯¹ç­”æ¡ˆä¸ç¡®å®šæ€§çš„å˜åŒ–è¶‹åŠ¿ã€‚é€šè¿‡å¯¹æ¯”æ­£ç¡®/é”™è¯¯ç­”æ¡ˆå¯¹åº”çš„ç†µè½¨è¿¹ï¼Œæ­ç¤ºæ¨ç†æ­¥éª¤å¯¹ç­”æ¡ˆæ­£ç¡®æ€§çš„å½±å“è§„å¾‹ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå¤šæ¨¡å‹åä½œçš„â€œé¢„è¨€æœºç ”ç©¶â€ï¼ˆOracle Studyï¼‰  
åœ¨MATHæ•°æ®é›†ï¼ˆæ¶µç›–7ä¸ªæ•°å­¦é¢†åŸŸï¼‰ä¸Šï¼Œç”¨Qwen2.5-32Bå’ŒGPT-4oç”Ÿæˆæ¨ç†é“¾ï¼Œå†ç”¨Qwen3-8Bä½œä¸ºâ€œæ£€æŸ¥å‘˜â€è®¡ç®—ç­”æ¡ˆåŒºé—´çš„æ¡ä»¶ç†µã€‚è¿™ç§å¤šæ¨¡å‹åˆ†å·¥ï¼ˆç”Ÿæˆæ¨ç†é“¾+é‡åŒ–æ•ˆç”¨ï¼‰çš„è®¾è®¡ï¼Œæ—¢åˆ©ç”¨å¤§æ¨¡å‹ç”Ÿæˆå¤šæ ·æ¨ç†ï¼Œåˆç”¨ä¸“é—¨æ¨¡å‹èšç„¦ä¸ç¡®å®šæ€§æµ‹é‡ï¼Œä¿è¯äº†å®éªŒçš„å…¨é¢æ€§ä¸é’ˆå¯¹æ€§ã€‚  


### ğŸ“ˆ å®éªŒç»“æœ
1. **æ¡ä»¶ç†µè½¨è¿¹ä¸ç­”æ¡ˆæ­£ç¡®æ€§å¼ºå…³è”**ï¼šå½“æ¨ç†è¿‡ç¨‹ä¸­æ¡ä»¶ç†µ**é€æ­¥ä¸‹é™**æ—¶ï¼Œç­”æ¡ˆæ›´å¯èƒ½æ­£ç¡®ï¼›è‹¥æ¡ä»¶ç†µ**æŒå¹³æˆ–ä¸Šå‡**ï¼Œç­”æ¡ˆé”™è¯¯æ¦‚ç‡æ›´é«˜ã€‚è¿™è¯´æ˜æ¡ä»¶ç†µçš„è¡°å‡è¶‹åŠ¿å¯ä½œä¸ºæ¨ç†æ˜¯å¦â€œæœ‰ç”¨â€çš„ä¿¡å·ã€‚  
2. **é”™è¯¯æ¨ç†é“¾æ›´é•¿**ï¼šç»Ÿè®¡æ˜¾ç¤ºï¼Œé”™è¯¯çš„æ¨ç†è·¯å¾„å¹³å‡é•¿åº¦æ¯”æ­£ç¡®çš„æ›´é•¿ï¼Œè¯æ˜â€œæ¨ç†æ­¥éª¤è¶Šå¤šâ€ä¸ç­‰äºâ€œç»“æœè¶Šå¥½â€â€”â€”æ— æ•ˆæ¨ç†å¯èƒ½æ‹–é•¿é“¾æ¡å´æ— æ³•æå‡å‡†ç¡®ç‡ã€‚  
3. **MATHæ•°æ®é›†çš„è·¨é¢†åŸŸéªŒè¯**ï¼šåœ¨MATHæ¶µç›–çš„è®¡æ•°ä¸æ¦‚ç‡ã€æ•°è®ºã€ä»£æ•°ç­‰7ä¸ªé¢†åŸŸä¸­ï¼Œä¸Šè¿°è§„å¾‹ä¸€è‡´æˆç«‹ï¼Œè¯´æ˜ç»“è®ºå…·æœ‰é¢†åŸŸæ³›åŒ–æ€§ã€‚  


### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **æŒ‡æ ‡è®¾è®¡**ï¼šç”¨æ¡ä»¶ç†µè¡¡é‡æ¨ç†æ•ˆç”¨æ˜¯æ–°é¢–ä¸”æœ‰æ•ˆçš„æ€è·¯ï¼Œä»…ä¾èµ–æ¨¡å‹è‡ªèº«è¾“å‡ºæ¦‚ç‡ã€æ— éœ€é¢å¤–å¥–åŠ±æ¨¡å‹æˆ–å¤–éƒ¨ç›‘ç£ï¼Œä¸ºå¤§æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ä¸æ•ˆç‡ä¼˜åŒ–æä¾›äº†è½»é‡å·¥å…·ã€‚  
2. **æ¨ç† pipeline ä¼˜åŒ–**ï¼šç ”ç©¶ç»“æœä¸ºâ€œæå‰ç»ˆæ­¢æ— æ•ˆæ¨ç†â€æä¾›äº†ç†è®ºä¾æ®â€”â€”è‹¥ç›‘æµ‹åˆ°æ¡ä»¶ç†µä¸å†ä¸‹é™ç”šè‡³ä¸Šå‡ï¼Œå¯åŠæ—¶æˆªæ–­æ¨ç†é“¾ï¼Œå‡å°‘è®¡ç®—èµ„æºæµªè´¹ä¸æœ€ç»ˆå†³ç­–å¹²æ‰°ã€‚  
3. **å®éªŒèŒƒå¼**ï¼šå¤šæ¨¡å‹åä½œçš„â€œç”Ÿæˆ-æ£€æµ‹â€åˆ†å·¥èŒƒå¼ï¼Œä¸ºå¤æ‚LLMç ”ç©¶ï¼ˆå¦‚æ¨ç†ã€å·¥å…·ä½¿ç”¨ç­‰ï¼‰æä¾›äº†å¯å‚è€ƒçš„å®éªŒè®¾è®¡æ€è·¯ï¼Œä¾¿äºæ‹†è§£ä»»åŠ¡ã€èšç„¦æ ¸å¿ƒé—®é¢˜ã€‚  


è¿™ç¯‡è®ºæ–‡ä»â€œæ¨ç†æ•ˆç”¨çš„é‡åŒ–â€åˆ‡å…¥ï¼Œç”¨ä¿¡æ¯è®ºå·¥å…·+å¤šæ¨¡å‹å®éªŒï¼Œæ¸…æ™°æ­ç¤ºäº†æ¨ç†é“¾é•¿åº¦ã€ä¸ç¡®å®šæ€§å˜åŒ–ä¸ç­”æ¡ˆæ­£ç¡®æ€§çš„å…³ç³»ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆæ¨ç†æ¡†æ¶çš„è®¾è®¡é“ºä¸‹å…³é”®åŸºçŸ³ã€‚

## uncertainty-under-the-curve--a-sequence-level-entropy-area-metric-for-reasoning-llm
### Abstract
In this work, we introduce Entropy Area Score (EAS), a simple yet effective
metric to quantify uncertainty in the answer generation process of reasoning
large language models (LLMs). EAS requires neither external models nor repeated
sampling, it integrates token-level predictive entropy from the model itself to
capture the evolution of uncertainty during generation. Empirical results show
that EAS is strongly correlated with answer entropy across models and datasets.
In training data selection, EAS identifies high-potential samples and
consistently outperforms Pass Rate filtering under equal sample budgets,
improving student model accuracy on math benchmarks. EAS is both efficient and
interpretable, offering a practical tool for uncertainty modeling and data
quality assessment in LLM training.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ä¸ºæ¨ç†å‹å¤§æ¨¡å‹é‡èº«å®šåˆ¶çš„ä¸ç¡®å®šæ€§åº¦é‡ï¼šEntropy Area Score

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
æ¨ç†å‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•°å­¦ã€ç§‘å­¦ç­‰å¤æ‚é¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†è¾“å‡ºå¯¹éšæœºç§å­ã€æ¸©åº¦ç­‰è¯„ä¼°æ¡ä»¶çš„å¾®å°å˜åŒ–é«˜åº¦æ•æ„Ÿï¼Œå¯¼è‡´ç»“æœæ³¢åŠ¨å¤§ã€å¯å¤ç°æ€§å·®ã€‚è¿™ç§æ³¢åŠ¨æºäºæ¨¡å‹è§£å†³æ¨¡ç³Šæˆ–è¾¹ç•Œé—®é¢˜æ—¶çš„ä¸ç¡®å®šæ€§ï¼Œè€Œç°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–å¤–éƒ¨æ¨¡å‹æˆ–é‡å¤é‡‡æ ·ï¼Œæˆæœ¬é«˜ä¸”æ³›åŒ–æ€§å¼±ï¼›è¦ä¹ˆåªå…³æ³¨æœ€ç»ˆè¾“å‡ºç»Ÿè®¡é‡ï¼Œå¿½ç•¥ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸ç¡®å®šæ€§çš„åŠ¨æ€å˜åŒ–ã€‚å› æ­¤ï¼ŒäºŸéœ€ä¸€ç§é«˜æ•ˆã€å¯è§£é‡Šä¸”èƒ½æ•æ‰ç”Ÿæˆè¿‡ç¨‹ä¸ç¡®å®šæ€§æ¼”åŒ–çš„åº¦é‡æ–¹æ³•ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºEntropy Area Scoreï¼ˆEASï¼‰åº¦é‡  
EASæ— éœ€å¤–éƒ¨æ¨¡å‹æˆ–é‡å¤é‡‡æ ·ï¼Œä»…åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„tokençº§é¢„æµ‹ç†µæ¥æ•æ‰ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸ç¡®å®šæ€§çš„æ¼”å˜ã€‚å…·ä½“åˆ†ä¸‰æ­¥ï¼šé¦–å…ˆæ„å»ºæ¯ä¸ªä½ç½®é¢„æµ‹ä¸‹ä¸€ä¸ªtokençš„ä¸Šä¸‹æ–‡ï¼›ç„¶åè®¡ç®—è¯¥ä½ç½®æ¨¡å‹è¯æ±‡è¡¨é¢„æµ‹åˆ†å¸ƒçš„tokençº§ç†µï¼›æœ€åå¯¹ç”Ÿæˆè·¯å¾„ä¸Šä»ç¬¬ä¸€ä¸ªåˆ°å€’æ•°ç¬¬äºŒä¸ªtokenä½ç½®çš„ç†µæ±‚å’Œï¼Œå¾—åˆ°æ•´ä¸ªç”Ÿæˆè½¨è¿¹çš„ç´¯è®¡ä¸ç¡®å®šæ€§ï¼ˆå³EASï¼‰ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå…³è”é‡‡æ ·ä¸ç¡®å®šæ€§ä¸é«˜æ•ˆæ•°æ®é€‰æ‹©  
éªŒè¯äº†EASä¸å¤šæ¨¡å‹ã€å¤šä»»åŠ¡ä¸‹é‡å¤ç”Ÿæˆå¾—åˆ°çš„ç­”æ¡ˆç†µå¼ºç›¸å…³ï¼Œè¯æ˜å…¶æ˜¯è¾“å‡ºä¸ç¡®å®šæ€§çš„å¯é ä»£ç†æŒ‡æ ‡ã€‚åœ¨è®­ç»ƒæ•°æ®é€‰æ‹©ä»»åŠ¡ä¸­ï¼ŒEASèƒ½è¯†åˆ«é«˜æ½œåŠ›æ ·æœ¬ï¼ŒåŒç­‰æ ·æœ¬é¢„ç®—ä¸‹æŒç»­è¶…è¶ŠPass Rateè¿‡æ»¤æ–¹æ³•ï¼Œæå‡å­¦ç”Ÿæ¨¡å‹åœ¨æ•°å­¦åŸºå‡†æµ‹è¯•ä¸Šçš„å‡†ç¡®ç‡ï¼Œä¸ºå¤§æ¨¡å‹è®­ç»ƒçš„ä¸ç¡®å®šæ€§å»ºæ¨¡å’Œæ•°æ®è´¨é‡è¯„ä¼°æä¾›å®ç”¨å·¥å…·ã€‚  


### ğŸ“ˆ å®éªŒç»“æœ
åœ¨GPQA - Diamondæ•°æ®é›†ï¼ˆ198é“ç§‘å­¦é¢˜ï¼‰ä¸Šï¼Œç”¨DeepSeek - R1 - Distill - Qwen - 14Bè¿›è¡Œ64æ¬¡æ¨ç†æ¥è®¡ç®—åŸºäºé‡‡æ ·çš„ä¸ç¡®å®šæ€§ã€‚å¯¹æ¯”è¡¨æ˜ï¼ŒEASä¸åæ˜ ç”Ÿæˆç­”æ¡ˆå¤šæ ·æ€§çš„ç­”æ¡ˆç†µå¼ºç›¸å…³ï¼ŒéªŒè¯äº†å…¶å¯¹ä¸ç¡®å®šæ€§åº¦é‡çš„æœ‰æ•ˆæ€§ï¼›åœ¨è®­ç»ƒæ•°æ®é€‰æ‹©ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”éšæœºã€åŸºäºé•¿åº¦æˆ–Pass Rateçš„é€‰æ‹©ç­–ç•¥ï¼ŒEASåœ¨ç›¸åŒæ ·æœ¬é‡ä¸‹æŒç»­æå‡å­¦ç”Ÿæ¨¡å‹æ€§èƒ½ï¼Œä½“ç°äº†å®é™…åº”ç”¨ä»·å€¼ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. è½»é‡é«˜æ•ˆçš„ä¸ç¡®å®šæ€§åº¦é‡æ€è·¯ï¼šEASä»…éœ€å•æ¬¡å‰å‘ä¼ æ’­ï¼Œä¸ä¾èµ–è¾…åŠ©æ¨¡å‹æˆ–å¾®è°ƒï¼Œå°±èƒ½åˆ©ç”¨æ¨¡å‹åŸç”Ÿtokençº§é¢„æµ‹å®ç°è·¨ä»»åŠ¡ã€è·¨æ¨¡å‹çš„æ³›åŒ–ï¼Œä¸ºèµ„æºå—é™åœºæ™¯ä¸‹çš„ä¸ç¡®å®šæ€§åˆ†ææä¾›äº†ä½æˆæœ¬æ–¹æ¡ˆã€‚  
2. ç”Ÿæˆè¿‡ç¨‹çš„åŠ¨æ€ä¸ç¡®å®šæ€§å»ºæ¨¡ï¼šæ‰“ç ´ä¼ ç»Ÿä»…å…³æ³¨æœ€ç»ˆè¾“å‡ºç»Ÿè®¡çš„å±€é™ï¼Œé€šè¿‡æ•æ‰ç”Ÿæˆè½¨è¿¹ä¸Šçš„ç†µå˜åŒ–ï¼Œä¸ºç†è§£æ¨¡å‹â€œæ€è€ƒè¿‡ç¨‹â€æä¾›ç»†ç²’åº¦å¯è§£é‡Šæ€§ï¼Œå¯ç”¨äºè¯Šæ–­æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„å†³ç­–åŠ¨æ€ã€‚  
3. æ•°æ®é€‰æ‹©çš„å®ç”¨ç­–ç•¥ï¼šå±•ç¤ºäº†åŸºäºç”Ÿæˆè¿‡ç¨‹ä¸ç¡®å®šæ€§çš„æ ·æœ¬ç­›é€‰åœ¨æå‡ä¸‹æ¸¸æ¨¡å‹æ€§èƒ½ä¸Šçš„æ½œåŠ›ï¼Œä¸ºå¤§æ¨¡å‹è®­ç»ƒ pipeline ä¸­æ•°æ®è´¨é‡ä¼˜åŒ–æä¾›äº†æ–°çš„æœ‰æ•ˆæŠ“æ‰‹ã€‚

## pre-trained-knowledge-elevates-large-language-models-beyond-traditional-chemical-reaction-optimizers
### Abstract
Modern optimization in experimental chemistry employs algorithmic search
through black-box parameter spaces. Here we demonstrate that pre-trained
knowledge in large language models (LLMs) fundamentally changes this paradigm.
Using six fully enumerated categorical reaction datasets (768 - 5,684
experiments), we benchmark LLM-guided optimization (LLM-GO) against Bayesian
optimization (BO) and random sampling. Frontier LLMs consistently match or
exceed BO performance across five single-objective datasets, with advantages
growing as parameter complexity increases and high-performing conditions become
scarce (<5% of space). BO retains superiority only for explicit multi-objective
trade-offs. To understand these contrasting behaviors, we introduce a
topology-agnostic information theory framework quantifying sampling diversity
throughout optimization campaigns. This analysis reveals that LLMs maintain
systematically higher exploration entropy than BO across all datasets while
achieving superior performance, with advantages most pronounced in
solution-scarce parameter spaces where high-entropy exploration typically fails
- suggesting that pre-trained domain knowledge enables more effective
navigation of chemical parameter space rather than replacing structured
exploration strategies. To enable transparent benchmarking and community
validation, we release Iron Mind (https://gomes.andrew.cmu.edu/iron-mind), a
no-code platform for side-by-side evaluation of human, algorithmic, and LLM
optimization campaigns with public leaderboards and complete trajectories. Our
findings establish that LLM-GO excels precisely where traditional methods
struggle: complex categorical spaces requiring domain understanding rather than
mathematical optimization.
### ğŸŒŸ è®ºæ–‡è§£è¯» | é¢„è®­ç»ƒçŸ¥è¯†åŠ©åŠ›å¤§è¯­è¨€æ¨¡å‹è¶…è¶Šä¼ ç»ŸåŒ–å­¦ååº”ä¼˜åŒ–å™¨

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨åŒ–å­¦å®éªŒä¼˜åŒ–é¢†åŸŸï¼Œä¼ ç»Ÿæ–¹æ³•å­˜åœ¨è¯¸å¤šå±€é™ã€‚å®éªŒå‚æ•°ç©ºé—´å¤æ‚å¤šç»´ï¼Œä¾é åŒ–å­¦ç›´è§‰çš„ä¼˜åŒ–æ–¹å¼éš¾ä»¥æŒç»­å¾—åˆ°æœ€ä¼˜ç»“æœï¼›å•å› ç´ è½®æ¢ï¼ˆOFATï¼‰ç­–ç•¥å’Œå®éªŒè®¾è®¡ï¼ˆDoEï¼‰æ–¹æ³•æ•ˆç‡ä¸é«˜ï¼ŒDoEè¿˜å—å‚æ•°æ•°é‡å’Œå˜é‡ç±»å‹é™åˆ¶ï¼›è´å¶æ–¯ä¼˜åŒ–ï¼ˆBOï¼‰è™½èƒ½å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼Œä½†åœ¨å¤æ‚æè¿°ç¬¦é€‰æ‹©ã€å¤šç›®æ ‡ä¼˜åŒ–è§£é‡Šæ€§ç­‰æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œä¸”ç¼ºä¹ä¸äººç±»ä¸“å®¶ç›´æ¥æ€§èƒ½å¯¹æ¯”çš„æ ‡å‡†åŒ–æ¡†æ¶ã€‚åŒæ—¶ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…´èµ·ä¸ºå®éªŒä¼˜åŒ–å¸¦æ¥æ–°é€”å¾„ï¼Œéœ€æ¢ç©¶å…¶ä¸ä¼ ç»Ÿæ–¹æ³•åœ¨é‡‡æ ·ç­–ç•¥ç­‰æ–¹é¢çš„å·®å¼‚ï¼Œä»¥æ˜ç¡®å…¶åœ¨åŒ–å­¦å®éªŒä¼˜åŒ–ä¸­çš„ä»·å€¼ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºLLMå¼•å¯¼ä¼˜åŒ–ï¼ˆLLM - GOï¼‰å¹¶ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”  
ä½¿ç”¨6ä¸ªå®Œå…¨æšä¸¾çš„åˆ†ç±»ååº”æ•°æ®é›†ï¼Œå°†LLMå¼•å¯¼çš„ä¼˜åŒ–ï¼ˆLLM - GOï¼‰ä¸è´å¶æ–¯ä¼˜åŒ–ï¼ˆBOï¼‰ã€éšæœºé‡‡æ ·åœ¨å®éªŒä¼˜åŒ–ä»»åŠ¡ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæ¢ç©¶LLMsåœ¨åŒ–å­¦å®éªŒå‚æ•°ç©ºé—´æœç´¢çš„æ€§èƒ½è¡¨ç°ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¼•å…¥æ‹“æ‰‘æ— å…³çš„ä¿¡æ¯è®ºæ¡†æ¶  
ä¸ºç†è§£ä¸åŒä¼˜åŒ–æ–¹æ³•çš„è¡Œä¸ºå·®å¼‚ï¼Œå¼•å…¥åŸºäºå‚æ•°é€‰æ‹©è®¡ç®—é¦™å†œç†µçš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸ä¾èµ–ç›®æ ‡ç©ºé—´ç»“æ„å‡è®¾ï¼Œå¯é‡åŒ–ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„é‡‡æ ·å¤šæ ·æ€§ï¼Œåˆ†ææ¢ç´¢ç†µåœ¨ä¸åŒæ–¹æ³•ä¸­çš„è¡¨ç°ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå‘å¸ƒIron Mindå¹³å°  
å‘å¸ƒæ— ä»£ç å¹³å°Iron Mindï¼Œç”¨äºäººç±»ã€ç®—æ³•å’ŒLLMä¼˜åŒ–è¿‡ç¨‹çš„å¹¶æ’è¯„ä¼°ï¼Œæä¾›å…¬å…±æ’è¡Œæ¦œå’Œå®Œæ•´è½¨è¿¹ï¼ŒåŠ©åŠ›é€æ˜åŸºå‡†æµ‹è¯•å’Œç¤¾åŒºéªŒè¯ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨äº”ä¸ªå•ç›®æ ‡æ•°æ®é›†ä¸Šï¼Œå‰æ²¿LLMsçš„æ€§èƒ½æŒç»­è¾¾åˆ°æˆ–è¶…è¿‡BOï¼Œä¸”å½“å‚æ•°å¤æ‚åº¦å¢åŠ ã€é«˜æ€§èƒ½æ¡ä»¶ç¨€ç¼ºï¼ˆå ç©ºé—´<5%ï¼‰æ—¶ï¼Œä¼˜åŠ¿æ›´æ˜æ˜¾ï¼›BOä»…åœ¨æ˜¾å¼å¤šç›®æ ‡æƒè¡¡ä»»åŠ¡ä¸­ä¿æŒä¼˜åŠ¿ã€‚ä»é‡‡æ ·å¤šæ ·æ€§çœ‹ï¼ŒLLMsåœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šæ¯”BOç³»ç»Ÿåœ°ä¿æŒæ›´é«˜çš„æ¢ç´¢ç†µï¼Œä¸”åœ¨é«˜ç†µæ¢ç´¢é€šå¸¸å¤±è´¥çš„ç¨€ç¼ºè§£å‚æ•°ç©ºé—´ä¸­ä¼˜åŠ¿æœ€æ˜¾è‘—ï¼Œè¯´æ˜é¢„è®­ç»ƒé¢†åŸŸçŸ¥è¯†èƒ½æ›´æœ‰æ•ˆå¯¼èˆªåŒ–å­¦å‚æ•°ç©ºé—´ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
å¯¹äºä»ä¸šè€…ï¼Œåœ¨é«˜ç»´åˆ†ç±»é—®é¢˜ä¸”å®éªŒé¢„ç®—ç´§å¼ æ—¶ï¼Œå¯éƒ¨ç½²LLM - GOï¼›å¤šç›®æ ‡ä¼˜åŒ–æˆ–ä¸ç†Ÿæ‚‰çš„åŒ–å­¦ç©ºé—´åœºæ™¯ä¸‹ï¼Œä¼˜å…ˆé€‰æ‹©BOã€‚è¯¥ç ”ç©¶ä¸ºåŒ–å­¦å®éªŒä¼˜åŒ–æä¾›æ–°è§†è§’ï¼Œå±•ç¤ºäº†åŸºç¡€æ¨¡å‹çŸ¥è¯†èƒ½ç»•è¿‡ä¸»å¯¼å®éªŒä¼˜åŒ–æ•°åå¹´çš„æ¢ç´¢ - åˆ©ç”¨èŒƒå¼ï¼ŒåŒæ—¶æå‡ºçš„è¯„ä¼°æ¡†æ¶å’Œå¹³å°ä¸ºé¢†åŸŸå†…åç»­ç ”ç©¶å’Œæ–¹æ³•å¯¹æ¯”æä¾›äº†æœ‰åŠ›å·¥å…·ï¼Œæ¨åŠ¨å¯¹ä¸åŒä¼˜åŒ–æ–¹æ³•åœ¨åŒ–å­¦åœºæ™¯ä¸‹æ€§èƒ½å’Œè¡Œä¸ºçš„ç†è§£ã€‚

## nlki--a-lightweight-natural-language-knowledge-integration-framework-for-improving-small-vlms-in-commonsense-vqa-tasks
### Abstract
Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.
### ğŸŒŸ è®ºæ–‡è§£è¯» | NLKIï¼šè½»é‡è‡ªç„¶è¯­è¨€çŸ¥è¯†æ•´åˆï¼ŒåŠ©åŠ›å°æ¨¡å‹çªç ´å¸¸è¯†VQAç“¶é¢ˆ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¸¸è¯†æ€§è§†è§‰é—®ç­”ï¼ˆCommonsense VQAï¼‰å¾€å¾€éœ€è¦å›¾åƒæˆ–é—®é¢˜ä¹‹å¤–çš„å¸¸è¯†çŸ¥è¯†ï¼Œä½†å°å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆsVLMsï¼Œå¦‚ViLTã€VisualBERTã€FLAVAç­‰ï¼‰å› ç¼ºä¹è¿™ç±»çŸ¥è¯†ï¼Œæ€§èƒ½è¿œè½åäºå¤§å‹ç”Ÿæˆå¼æ¨¡å‹ã€‚åŒæ—¶ï¼Œå¸¸è¯†çŸ¥è¯†æ£€ç´¢ç¼ºä¹ç»Ÿä¸€æ¥æºï¼ŒçŸ¥è¯†å›¾è°±ã€è¯­æ–™åº“ç­‰éš¾ä»¥è¦†ç›–æ—¥å¸¸ç‰©ç†ã€ç¤¾ä¼šä¹ ä¿—ã€ç‰©ä½“åŠŸèƒ½ç­‰å…¨åœºæ™¯ï¼›è€Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½èƒ½æä¾›çŸ¥è¯†å´å­˜åœ¨å™ªå£°ã€‚æ­¤å¤–ï¼Œå¸¸è¯†VQAåŸºå‡†æ•°æ®é›†å­˜åœ¨10%-25%çš„æ ‡ç­¾å™ªå£°ï¼Œä¹Ÿç»™æ¨¡å‹è®­ç»ƒå¸¦æ¥æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œè®ºæ–‡å›´ç»•å››ä¸ªç ”ç©¶é—®é¢˜å±•å¼€ï¼šå¸¸è¯†äº‹å®ä¸LLMç”Ÿæˆè§£é‡Šå¯¹sVLMsçš„å¸®åŠ©ç¨‹åº¦ã€äºŒè€…è°æ›´é€‚åˆVQAå¸¸è¯†æ¨ç†ã€æŠ—å™ªå£°æŸå¤±èƒ½å¦ç¼“è§£æ ‡ç­¾å™ªå£°å½±å“ã€ä¸­å°å‹ç”Ÿæˆå¼VLMä¸sVLMsåœ¨å¸¸è¯†ä»»åŠ¡ä¸­è¡¨ç°å¯¹æ¯”ï¼Œè¿›è€Œæå‡ºNLKIæ¡†æ¶ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºNLKIç«¯åˆ°ç«¯æ¡†æ¶  
æ„å»ºäº†â€œæ£€ç´¢è‡ªç„¶è¯­è¨€äº‹å®â†’LLMç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šâ†’å°†ä¸¤ç±»ä¿¡å·è¾“å…¥sVLMsâ€çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼ˆNLKIï¼‰ï¼Œå¯ä¸ä»»æ„2.4äº¿å‚æ•°ä»¥ä¸‹çš„VLMç»“åˆï¼Œå„æ¨¡å—èƒ½ç‹¬ç«‹åˆ†æä¼˜åŒ–ï¼Œä¸ºå°æ¨¡å‹å¸¸è¯†æ¨ç†èµ‹èƒ½ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šä¼˜åŒ–å¸¸è¯†äº‹å®æ£€ç´¢  
å¯¹æ¯”ä¸»æµæ£€ç´¢æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å¾®è°ƒColBERTv2ï¼Œåœ¨CRICã€AOKVQAã€e - SNLI - VEæ•°æ®é›†çš„å¸¸è¯†äº‹å®æ£€ç´¢ä¸­å®ç°æœ€é«˜å¬å›ç‡ï¼Œä¸ºåç»­çŸ¥è¯†æ•´åˆæä¾›é«˜è´¨é‡åŸºç¡€ä¿¡æ¯ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šæå‡LLMè§£é‡Šè´¨é‡  
å€ŸåŠ©Florence - 2 - largeç”Ÿæˆå›¾åƒçš„ç‰©ä½“ä¸åŒºåŸŸä¿¡æ¯ï¼ˆå¯†é›†/åŒºåŸŸå­—å¹•ï¼‰ï¼Œç»“åˆæ£€ç´¢åˆ°çš„äº‹å®æ„å»ºæç¤ºè¯ï¼Œè¾“å…¥Llama - 3.1 - 8Bç”Ÿæˆè§£é‡Šã€‚ç›¸æ¯”ä»…ç”¨å›¾åƒå­—å¹•ï¼Œå¤§å¹…å‡å°‘è§£é‡Šä¸­çš„å™ªå£°ä¸å¹»è§‰ä¿¡æ¯ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹4ï¼šæŠ—å™ªå£°è®­ç»ƒå¢å¼ºé²æ£’æ€§  
é’ˆå¯¹æ•°æ®é›†æ ‡ç­¾å™ªå£°ï¼Œå¼•å…¥å¯¹ç§°äº¤å‰ç†µï¼ˆSCEï¼‰ã€å¹¿ä¹‰äº¤å‰ç†µï¼ˆGCEï¼‰ç­‰æŠ—å™ªå£°æŸå¤±å‡½æ•°å¾®è°ƒæ¨¡å‹ã€‚åœ¨å¤–éƒ¨çŸ¥è¯†å¢å¼ºåœºæ™¯ä¸‹ï¼Œæ—¢ä¿ç•™çŸ¥è¯†æ•´åˆæ”¶ç›Šï¼Œåˆç¼“è§£æ ‡ç­¾å™ªå£°å½±å“ï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
1. çŸ¥è¯†æ•´åˆå¢ç›Šï¼šNLKIæ¡†æ¶ä¸‹ï¼Œåˆ©ç”¨æ£€ç´¢äº‹å®ä¸LLMè§£é‡Šèƒ½ä½¿sVLMsç«¯åˆ°ç«¯å›ç­”å‡†ç¡®ç‡åœ¨3ä¸ªæ•°æ®é›†ï¼ˆCRICã€AOKVQAã€e - SNLI - VEï¼‰ä¸­æå‡æœ€é«˜7%ï¼Œè®©FLAVAç­‰å°æ¨¡å‹æ€§èƒ½æ¯”è‚©ç”šè‡³è¶…è¿‡Qwen - 2 VL - 2Bã€SmolVLM - 2.5Bç­‰ä¸­å‹VLMã€‚  
2. æŠ—å™ªå£°è®­ç»ƒå¢ç›Šï¼šåœ¨æ ‡ç­¾å™ªå£°åœºæ™¯ä¸‹ï¼Œç»“åˆSCEæˆ–GCEæŸå¤±è¿›ä¸€æ­¥å¾®è°ƒï¼ŒCRICå‡†ç¡®ç‡å†æå‡2.5%ï¼ŒAOKVQAæå‡5.5%ï¼›AOKVQAå¹³å‡å‡†ç¡®ç‡æå‡13.6%ï¼ŒCRICå’Œe - SNLI - VEåœ¨ä¸‰ç§æ¶æ„ä¸‹æå‡2 - 4%ã€‚  
3. è§„æ¨¡å¯¹æ¯”ç»“æœï¼šè¯„ä¼°Qwen - 2ã€Phi - 3 - Visionã€MiniCPMã€SmolVLMï¼ˆâ‰¤4Bï¼‰ç­‰ä¸­å‹æ¨¡å‹å‘ç°ï¼Œå®ƒä»¬æ— æ˜¾å¼çŸ¥è¯†æ•´åˆæ—¶ä¹Ÿç¼ºä¹å¸¸è¯†ï¼Œè€ŒNLKIå¢å¼ºçš„sVLMsï¼ˆâ‰¤240Mï¼‰åœ¨éƒ¨åˆ†åœºæ™¯å¯ä¸ä¹‹åŒ¹æ•Œç”šè‡³è¶…è¶Šã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. è½»é‡æ¨¡å—åŒ–è®¾è®¡ï¼šNLKIçš„â€œæ£€ç´¢å™¨+LLMè§£é‡Šå™¨+è½»é‡é˜…è¯»å™¨â€æ¨¡å—åŒ–æ¶æ„ï¼Œä¸ºå°æ¨¡å‹ä½æˆæœ¬å¼•å…¥å¤–éƒ¨çŸ¥è¯†æä¾›èŒƒå¼ï¼Œå„æ¨¡å—å¯ç‹¬ç«‹è¿­ä»£ä¼˜åŒ–ã€‚  
2. æ£€ç´¢ä¸æç¤ºä¼˜åŒ–ï¼šé€šè¿‡å¯¹æ¯”å­¦ä¹ å¾®è°ƒæ£€ç´¢æ¨¡å‹ã€ç»“åˆå›¾åƒå¤šç»´åº¦ä¿¡æ¯æ„å»ºæç¤ºè¯ï¼Œä¸ºå¸¸è¯†çŸ¥è¯†ç²¾å‡†è·å–ä¸é«˜è´¨é‡è§£é‡Šç”Ÿæˆæä¾›äº†æœ‰æ•ˆæŠ€æœ¯è·¯çº¿ã€‚  
3. æŠ—å™ªå£°è®­ç»ƒå®è·µï¼šåœ¨å¤–éƒ¨çŸ¥è¯†æ³¨å…¥åœºæ™¯ä¸‹å¼•å…¥æŠ—å™ªå£°æŸå¤±å‡½æ•°ï¼Œä¸ºæ ‡ç­¾å™ªå£°æ™®éå­˜åœ¨çš„æ•°æ®é›†è®­ç»ƒæä¾›é²æ£’æ€§å¢å¼ºæ€è·¯ï¼Œå¯æ¨å¹¿åˆ°ç±»ä¼¼å¸¦å™ªä»»åŠ¡ã€‚  
4. å°æ¨¡å‹æ½œåŠ›æŒ–æ˜ï¼šè¯æ˜2.5äº¿å‚æ•°çº§å°æ¨¡å‹ç»“åˆçŸ¥è¯†æ•´åˆä¸æŠ—å™ªå£°è®­ç»ƒï¼Œèƒ½åœ¨å¸¸è¯†VQAä»»åŠ¡æŒ‘æˆ˜ä¸­å‹æ¨¡å‹ï¼Œå‡¸æ˜¾è½»é‡æ¨¡å‹åœ¨é«˜æ•ˆå¸¸è¯†æ¨ç†æ–¹å‘çš„å‘å±•æ½œåŠ›ã€‚

## topic-identification-in-llm-input-output-pairs-through-the-lens-of-information-bottleneck
### Abstract
Large Language Models (LLMs) are prone to critical failure modes, including
\textit{intrinsic faithfulness hallucinations} (also known as confabulations),
where a response deviates semantically from the provided context. Frameworks
designed to detect this, such as Semantic Divergence Metrics (SDM), rely on
identifying latent topics shared between prompts and responses, typically by
applying geometric clustering to their sentence embeddings. This creates a
disconnect, as the topics are optimized for spatial proximity, not for the
downstream information-theoretic analysis. In this paper, we bridge this gap by
developing a principled topic identification method grounded in the
Deterministic Information Bottleneck (DIB) for geometric clustering. Our key
contribution is to transform the DIB method into a practical algorithm for
high-dimensional data by substituting its intractable KL divergence term with a
computationally efficient upper bound. The resulting method, which we dub UDIB,
can be interpreted as an entropy-regularized and robustified version of K-means
that inherently favors a parsimonious number of informative clusters. By
applying UDIB to the joint clustering of LLM prompt and response embeddings, we
generate a shared topic representation that is not merely spatially coherent
but is fundamentally structured to be maximally informative about the
prompt-response relationship. This provides a superior foundation for the SDM
framework and offers a novel, more sensitive tool for detecting confabulations.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ç”¨ä¿¡æ¯ç“¶é¢ˆä¸ºLLMè¾“å…¥è¾“å‡ºå¯¹åšä¸»é¢˜è¯†åˆ«ï¼Œç²¾å‡†æŠ“å¹»è§‰

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å­˜åœ¨â€œå†…åœ¨å¿ å®æ€§å¹»è§‰ï¼ˆå³è™šæ„å†…å®¹ï¼‰â€è¿™ç±»å…³é”®å¤±æ•ˆæ¨¡å¼ï¼Œè¡¨ç°ä¸ºå›å¤å’Œç»™å®šä¸Šä¸‹æ–‡è¯­ä¹‰åç¦»ã€‚åƒè¯­ä¹‰åˆ†æ­§åº¦é‡ï¼ˆSDMï¼‰è¿™ç±»æ£€æµ‹æ¡†æ¶ï¼Œä¾èµ–è¯†åˆ«promptå’Œå›å¤é—´æ½œåœ¨ä¸»é¢˜ï¼Œå¸¸ç”¨å¯¹å¥å­åµŒå…¥åšå‡ ä½•èšç±»çš„æ–¹å¼ï¼Œä½†è¿™ç§æ–¹å¼ä¼˜åŒ–çš„æ˜¯ç©ºé—´é‚»è¿‘æ€§ï¼Œå’Œä¸‹æ¸¸ä¿¡æ¯è®ºåˆ†æéœ€æ±‚è„±èŠ‚ã€‚æœ¬æ–‡æ—¨åœ¨ç”¨ä¿¡æ¯ç“¶é¢ˆåŸç†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæå‡ºæ›´åˆç†çš„ä¸»é¢˜è¯†åˆ«æ–¹æ³•ï¼Œä¸ºSDMæ¡†æ¶ç­‘ç‰¢åŸºç¡€ã€æå‡è™šæ„å†…å®¹æ£€æµ‹èƒ½åŠ›ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå°†DIBè½¬åŒ–ä¸ºå®ç”¨ç®—æ³•ï¼ˆUDIBï¼‰
æŠŠç”¨äºå‡ ä½•èšç±»çš„ç¡®å®šæ€§ä¿¡æ¯ç“¶é¢ˆï¼ˆDIBï¼‰æ–¹æ³•ï¼Œé’ˆå¯¹é«˜ç»´æ•°æ®åšå®ç”¨åŒ–æ”¹é€ ã€‚ç”¨è®¡ç®—é«˜æ•ˆçš„é«˜æ–¯æ··åˆ divergence ä¸Šç•Œæ›¿ä»£DIBä¸­éš¾å¤„ç†çš„KLæ•£åº¦é¡¹ï¼Œå¾—åˆ°UDIBç®—æ³•ã€‚UDIBå¯ç†è§£ä¸ºå¸¦ç†µæ­£åˆ™åŒ–ä¸”æ›´é²æ£’çš„K - meanså˜ä½“ï¼Œå¤©ç„¶å€¾å‘äºç”¨ç®€æ´ä¸”ä¿¡æ¯ä¸°å¯Œçš„ç°‡æ•°é‡ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå®Œæ•´çš„LLMåˆ†ææ–¹æ³•è®º
æå‡ºå°†UDIBç”¨äºLLMåˆ†æçš„æ•´å¥—æ–¹æ³•ï¼ŒåŒ…å«å¤šç§å­æ¡†æ¶ä¿éšœé²æ£’æ€§ï¼Œè¿˜æœ‰ç”¨ä¿¡æ¯è½®å»“â€œå¼¯æŠ˜è§’â€ç¡®å®šæœ€ä¼˜ä¸»é¢˜æ•°çš„åˆç†æ¨¡å‹é€‰æ‹©æ–¹å¼ã€‚é€šè¿‡UDIBå¯¹LLM promptå’Œå›å¤åµŒå…¥åšè”åˆèšç±»ï¼Œç”Ÿæˆçš„å…±äº«ä¸»é¢˜è¡¨ç¤ºä¸ä»…ç©ºé—´è¿è´¯ï¼Œè¿˜èƒ½å¯¹prompt - å›å¤å…³ç³»æœ€å¤§åŒ–ä¼ é€’ä¿¡æ¯ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
æ–‡ä¸­é€šè¿‡å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¾—åˆ°çš„ä¸»é¢˜åœ¨å®šæ€§å’Œå®šé‡å±‚é¢éƒ½æ›´ä¼˜ï¼Œèƒ½è®©è¯­ä¹‰æ¼‚ç§»æµ‹é‡æ›´çµæ•å¯é ï¼ˆè®ºæ–‡åç»­Section 5ä¼šè¯¦ç»†å±•å¼€å®éªŒç»“æœä¸åˆ†æï¼Œæ­¤å¤„æ˜¯æ ¸å¿ƒç»“è®ºæ–¹å‘ï¼‰ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»æ–¹æ³•åˆ›æ–°çœ‹ï¼ŒæŠŠä¿¡æ¯ç“¶é¢ˆåŸç†åˆ›æ–°æ€§ç”¨äºLLMè¾“å…¥è¾“å‡ºåµŒå…¥çš„ä¸»é¢˜è¯†åˆ«ï¼Œä¸ºå¤„ç†é«˜ç»´æ•°æ®ä¸‹çš„èšç±»ä¸ä¿¡æ¯ä¿ç•™å¹³è¡¡é—®é¢˜æä¾›æ–°æ€è·¯ï¼›ä»åº”ç”¨ä»·å€¼çœ‹ï¼Œç»™LLMå¹»è§‰ï¼ˆå°¤å…¶æ˜¯å†…åœ¨å¿ å®æ€§å¹»è§‰ï¼‰æ£€æµ‹æä¾›äº†æ›´çµæ•å·¥å…·ï¼Œä¹Ÿä¸ºSDMè¿™ç±»è¯­ä¹‰åˆ†ææ¡†æ¶è¡¥å…¨äº†æ›´é€‚é…çš„ä¸»é¢˜è¯†åˆ«ç¯èŠ‚ï¼›ä»æŠ€æœ¯è½åœ°è§’åº¦ï¼Œå¤šç§å­é²æ£’æ¡†æ¶ã€åŸºäºâ€œå¼¯æŠ˜è§’â€é€‰ä¸»é¢˜æ•°ç­‰ç­–ç•¥ï¼Œä¸ºåŒç±»éœ€èšç±» + ä¿¡æ¯è®ºåˆ†æçš„ä»»åŠ¡æä¾›äº†å¯å¤ç”¨çš„å·¥ç¨‹åŒ–æ€è·¯ã€‚

## haepo--history-aggregated-exploratory-policy-optimization
### Abstract
Exploration is essential in modern learning, from reinforcement learning
environments with small neural policies to large language models (LLMs).
Existing work, such as DPO, leverages full sequence log-likelihoods to capture
an entire trajectory of the model's decisions, while methods like GRPO
aggregate per-token ratios into a trajectory-level update. However, both often
limit exploration on long-horizon tasks. We introduce History-Aggregated
Exploratory Policy Optimization (HAEPO), a history-aware exploratory loss to
combat these shortcomings. HAEPO compresses each trajectory into the sum of its
logarithmic probabilities (a cumulative logarithmic likelihood), and applies a
Plackett-Luce softmax across trajectories to obtain normalized weights
proportional to their returns, thus encouraging broader exploration. We add
entropy regularization to stabilize the aggressive updates to prevent premature
collapse and a soft KL penalty relative to a frozen copy of the previous
(reference) policy. Empirically, HAEPO converges fast, explores thoroughly,
aligns closely with true rewards, and demonstrates robust learning behavior
better or at par with PPO, GRPO, and DPO across diverse tasks. Thus, HAEPO
provides a stable and interpretable framework by explicitly leveraging
full-trajectory history while balancing exploration and stability.
### ğŸŒŸ è®ºæ–‡è§£è¯» | HAEPOï¼šé•¿åºåˆ—ä»»åŠ¡ä¸­æ›´ä¼˜æ¢ç´¢çš„ç­–ç•¥ä¼˜åŒ–æ–°èŒƒå¼

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç­‰ç°ä»£å­¦ä¹ åœºæ™¯ä¸­ï¼Œ**æ¢ç´¢ï¼ˆå°è¯•æ–°è¡Œä¸ºï¼‰** æ˜¯å…³é”®ç¯èŠ‚ã€‚ç„¶è€Œç°æœ‰æ–¹æ³•å­˜åœ¨å±€é™ï¼š  
- åƒ DPO è¿™ç±»æ–¹æ³•è™½ç”¨å…¨åºåˆ—å¯¹æ•°ä¼¼ç„¶æ•æ‰æ¨¡å‹å†³ç­–è½¨è¿¹ï¼Œä½†åœ¨é•¿æ—¶ç¨‹ä»»åŠ¡ä¸­æ¢ç´¢å—é™ï¼›  
- GRPO ç­‰åŸºäºé€ token èšåˆçš„æ–¹å¼ï¼Œä¹Ÿä¼šå› ä¿¡å·ç¨€é‡Šå¯¼è‡´é•¿åºåˆ—æ¢ç´¢ä¸è¶³ï¼›  
- ä¼ ç»Ÿè½¨è¿¹çº§æ–¹æ³•è¿˜é¢ä¸´æ¢¯åº¦æ–¹å·®é«˜ã€æ¢ç´¢å—é™äºæ­¥é•¿è£å‰ªã€ä¸¢å¤±åºåˆ—é—´ç»†ç²’åº¦åŒºåˆ†ä¿¡æ¯ç­‰é—®é¢˜ã€‚  
ä¸ºè§£å†³é•¿æ—¶ç¨‹ä»»åŠ¡ä¸­æ¢ç´¢ä¸è¶³ä¸ç¨³å®šæ€§çš„å¹³è¡¡éš¾é¢˜ï¼Œè®ºæ–‡æå‡º **History-Aggregated Exploratory Policy Optimizationï¼ˆHAEPOï¼‰**ã€‚  


### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
HAEPO å›´ç»•**è½¨è¿¹çº§å†å²èšåˆ**ä¸**æ¢ç´¢ - ç¨³å®šå¹³è¡¡**å±•å¼€è®¾è®¡ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š  

ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šè½¨è¿¹çº§å¯¹æ•°ä¼¼ç„¶èšåˆ + Plackett - Luce åŠ æƒ  
HAEPO å…ˆå°†æ¯æ¡è½¨è¿¹å‹ç¼©ä¸ºâ€œå¯¹æ•°æ¦‚ç‡ä¹‹å’Œï¼ˆç´¯ç§¯å¯¹æ•°ä¼¼ç„¶ï¼‰â€ï¼Œå†å¯¹æ‰€æœ‰è½¨è¿¹çš„è¯¥ç´¯ç§¯å€¼æ–½åŠ  Plackett - Luce è½¯maxï¼Œè®©è½¨è¿¹æƒé‡ä¸â€œå½’ä¸€åŒ–å›æŠ¥â€æˆæ­£æ¯”ã€‚è¿™ç§åˆ—è¡¨çº§ï¼ˆlist - wiseï¼‰åŠ æƒèƒ½ä¿ç•™åºåˆ—é—´çš„ç»†ç²’åº¦å·®å¼‚ï¼Œæ”¾å¤§é«˜å›æŠ¥ä¸”å¤šæ ·çš„è½¨è¿¹ï¼Œä»è€Œåœ¨ç¨€ç–å¥–åŠ±ã€é•¿æ—¶ç¨‹ä»»åŠ¡ä¸­æ›´é«˜æ•ˆæ¢ç´¢ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç†µæ­£åˆ™åŒ– + è½¯ KL æƒ©ç½šçš„ç¨³å®šæœºåˆ¶  
ä¸ºé¿å…â€œæ¿€è¿›æ›´æ–°å¯¼è‡´è¿‡æ—©æ”¶æ•›ï¼ˆcollapseï¼‰â€ï¼ŒHAEPO å¼•å…¥ä¸¤é‡æ­£åˆ™ï¼š  
- ç†µæ­£åˆ™åŒ–ï¼ˆentropy regularizationï¼‰ï¼šé¼“åŠ±ç­–ç•¥åˆ†å¸ƒæ›´â€œåˆ†æ•£â€ï¼Œä¿è¯æ¢ç´¢çš„å¹¿åº¦ï¼Œé˜²æ­¢ç­–ç•¥è¿‡æ—©é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼›  
- è½¯ KL æƒ©ç½šï¼šç›¸å¯¹äºâ€œå†»ç»“çš„å†å²ç­–ç•¥ï¼ˆreference policyï¼‰â€è®¡ç®— KL æ•£åº¦å¹¶æ–½åŠ æƒ©ç½šï¼Œç±»ä¼¼ä¿¡ä»»åŸŸæ–¹æ³•çº¦æŸç­–ç•¥æ›´æ–°å¹…åº¦è¿‡å¤§ï¼Œå¹³è¡¡æ¢ç´¢ä¸ç¨³å®šæ€§ã€‚  


### ğŸ“ˆ å®éªŒç»“æœ
è®ºæ–‡åœ¨å¤šç±»ä»»åŠ¡ä¸­éªŒè¯ HAEPO æ€§èƒ½ï¼Œå…³é”®ç»“æœåŒ…æ‹¬ï¼š  
- **å¤šè‡‚è€è™æœºï¼ˆ30 - armed banditï¼‰**ï¼šæ”¶æ•›é€Ÿåº¦å¿«äº DPOã€PPOï¼Œä¸”æ³¢åŠ¨æ›´å°â€”â€”è½¨è¿¹çº§åŠ æƒä¸ç¨³å®šé¡¹è®©å­¦ä¹ æ›´å¹³æ»‘ï¼›  
- **CartPole ç»å…¸æ§åˆ¶ä»»åŠ¡**ï¼šæœ€ç»ˆæ€§èƒ½ä¸ PPO æŒå¹³ï¼Œä½†è®­ç»ƒæ—¶â€œæ¯ç§’æ›´æ–°ååé‡â€æ›´é«˜ã€æ¢ç´¢é€Ÿç‡æ›´å¿«ï¼›  
- **äººç±»åé¦ˆå¾®è°ƒï¼ˆLLM åœºæ™¯ï¼‰**ï¼šä¸ GRPO æ€§èƒ½ç›¸å½“çš„åŒæ—¶ï¼ŒGPU å†…å­˜å ç”¨é™ä½ 26.4%ï¼ˆæ¥è¿‘ DPO æ°´å¹³ï¼‰ï¼Œåœ¨ç¡¬ä»¶çº¦æŸä¸‹å®ç°æ›´ç¨³å®šã€æ ·æœ¬é«˜æ•ˆçš„å­¦ä¹ ã€‚  


### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
HAEPO çš„è®¾è®¡æ€è·¯ä¸æŠ€æœ¯è·¯çº¿ï¼Œå¯¹å¼ºåŒ–å­¦ä¹ ã€å¤§æ¨¡å‹è®­ç»ƒç­‰é¢†åŸŸæœ‰å¤šé‡å¯å‘ï¼š  
- **é•¿æ—¶ç¨‹ä»»åŠ¡çš„æ¢ç´¢èŒƒå¼**ï¼šé€šè¿‡â€œè½¨è¿¹çº§èšåˆ + åˆ—è¡¨çº§åŠ æƒâ€ï¼Œä¸ºé•¿åºåˆ—ã€ç¨€ç–å¥–åŠ±åœºæ™¯æä¾›äº†æ›´é«˜æ•ˆçš„æ¢ç´¢æ€è·¯ï¼Œé¿å…é€ token èšåˆå¯¼è‡´çš„ä¿¡å·ç¨€é‡Šï¼›  
- **æ¢ç´¢ - ç¨³å®šçš„å¹³è¡¡è‰ºæœ¯**ï¼šç†µæ­£åˆ™ + è½¯ KL æƒ©ç½šçš„ç»„åˆï¼Œå±•ç¤ºäº†å¦‚ä½•ç”¨æ­£åˆ™åŒ–æ‰‹æ®µåœ¨â€œæ¿€è¿›æ¢ç´¢â€ä¸â€œç¨³å®šæ”¶æ•›â€é—´æ‰¾å¹³è¡¡ï¼Œå¯è¿ç§»åˆ°éœ€å…¼é¡¾åˆ›æ–°ä¸ç¨³å®šçš„ç­–ç•¥ä¼˜åŒ–ä»»åŠ¡ï¼›  
- **ç¡¬ä»¶å‹å¥½çš„è®­ç»ƒæ•ˆç‡**ï¼šåœ¨ LLM å¾®è°ƒç­‰åœºæ™¯ä¸­é™ä½å†…å­˜å ç”¨ã€æå‡æ›´æ–°ååé‡ï¼Œä¸ºèµ„æºå—é™ä¸‹çš„å¤§è§„æ¨¡è®­ç»ƒæä¾›äº†ä¼˜åŒ–æ–¹å‘ã€‚  

ç®€è¨€ä¹‹ï¼ŒHAEPO é€šè¿‡æ˜¾å¼åˆ©ç”¨â€œå…¨è½¨è¿¹å†å²ä¿¡æ¯â€ï¼Œåœ¨æ¢ç´¢ä¸ç¨³å®šé—´æ‰¾åˆ°ç²¾å·§å¹³è¡¡ï¼Œä¸ºé•¿æ—¶ç¨‹ä»»åŠ¡çš„ç­–ç•¥ä¼˜åŒ–å¼€è¾Ÿäº†æ›´å…·è§£é‡Šæ€§ä¸é²æ£’æ€§çš„æ–°æ¡†æ¶ã€‚

## cocoa--confidence-and-context-aware-adaptive-decoding-for-resolving-knowledge-conflicts-in-large-language-models
### Abstract
Faithful generation in large language models (LLMs) is challenged by
knowledge conflicts between parametric memory and external context. Existing
contrastive decoding methods tuned specifically to handle conflict often lack
adaptability and can degrade performance in low conflict settings. We introduce
CoCoA (Confidence- and Context-Aware Adaptive Decoding), a novel token-level
algorithm for principled conflict resolution and enhanced faithfulness. CoCoA
resolves conflict by utilizing confidence-aware measures (entropy gap and
contextual peakedness) and the generalized divergence between the parametric
and contextual distributions. Crucially, CoCoA maintains strong performance
even in low conflict settings. Extensive experiments across multiple LLMs on
diverse Question Answering (QA), Summarization, and Long-Form Question
Answering (LFQA) benchmarks demonstrate CoCoA's state-of-the-art performance
over strong baselines like AdaCAD. It yields significant gains in QA accuracy,
up to 9.2 points on average compared to the strong baseline AdaCAD, and
improves factuality in summarization and LFQA by up to 2.5 points on average
across key benchmarks. Additionally, it demonstrates superior sensitivity to
conflict variations. CoCoA enables more informed, context-aware, and ultimately
more faithful token generation.
### ğŸŒŸ è®ºæ–‡è§£è¯» | CoCoAï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­çŸ¥è¯†å†²çªçš„ç½®ä¿¡ä¸ä¸Šä¸‹æ–‡æ„ŸçŸ¥è‡ªé€‚åº”è§£ç 

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†é¢„è®­ç»ƒè·å¾—çš„å‚æ•°åŒ–çŸ¥è¯†å­˜åœ¨é™æ€ã€æ˜“è¿‡æ—¶æˆ–ä¸å®Œæ•´çš„é—®é¢˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œä¸Šä¸‹æ–‡æ„ŸçŸ¥ç”Ÿæˆåœ¨æ¨ç†æ—¶å¼•å…¥å¤–éƒ¨è¾…åŠ©ä¿¡æ¯ï¼Œä½†è¿™ä¼šå¼•å‘å¤–éƒ¨ä¸Šä¸‹æ–‡ä¸æ¨¡å‹å†…éƒ¨çŸ¥è¯†çš„å†²çªã€‚ç°æœ‰å¯¹æ¯”è§£ç æ–¹æ³•ï¼ˆå¦‚CADã€AdaCADï¼‰åœ¨å¤„ç†å†²çªæ—¶ç¼ºä¹é€‚åº”æ€§ï¼Œåœ¨ä½å†²çªåœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½åœ¨ä¸åŒå†²çªåœºæ™¯ä¸‹æœ‰æ•ˆè§£å†³çŸ¥è¯†å†²çªã€æå‡ç”Ÿæˆå¿ å®æ€§çš„æ–¹æ³•ï¼ŒCoCoA åº”è¿è€Œç”Ÿã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå°¾éƒ¨æ•æ„Ÿçš„å†²çªæ£€æµ‹  
ç”¨ RÃ©nyi æ•£åº¦æ›¿ä»£ AdaCAD ä¸­çš„ Jensen - Shannon æ•£åº¦ï¼ˆJSDï¼‰ã€‚RÃ©nyi æ•£åº¦å¯åœ¨ä¸åŒç†µåŸŸé—´å®ç°å¯è°ƒçš„æ•æ„Ÿæ€§ï¼Œèƒ½å¢å¼ºæ¨¡å‹æ£€æµ‹å…ˆéªŒåˆ†å¸ƒä¸ä¸Šä¸‹æ–‡åˆ†å¸ƒé—´å°¾éƒ¨å˜åŒ–çš„èƒ½åŠ›ï¼Œå¯¹äºæ•æ‰ç»†å¾®ä½†æœ‰æ„ä¹‰çš„å†²çªè‡³å…³é‡è¦ï¼Œå…‹æœäº† JSD æ— æ³•åŒºåˆ†æœ‰æ„ä¹‰ä¸Šä¸‹æ–‡ä¿¡å·ä¸å™ªå£°ã€åœ¨è‡ªå›å½’è§£ç å…¸å‹åˆ†å¸ƒä¸Šé¥±å’Œçš„é—®é¢˜ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šä¸Šä¸‹æ–‡ç½®ä¿¡åº¦ä¼°è®¡  
å¼•å…¥æ–°é¢–çš„ç½®ä¿¡åº¦ä¿¡å·ï¼Œç»“åˆå…ˆéªŒä¸ä¸Šä¸‹æ–‡åˆ†å¸ƒé—´çš„ç†µå·®å’Œä¸Šä¸‹æ–‡å³°å€¼ï¼Œå°†åˆ†å¸ƒé—´çš„å·®å¼‚å’Œç¡®å®šæ€§ç»Ÿä¸€åœ¨ä¸€ä¸ªåº¦é‡ä¸­ï¼Œæ›´å…¨é¢åœ°è¡¡é‡ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å¯é æ€§ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šè‡ªé€‚åº”é—¨æ§æœºåˆ¶  
æå‡ºåŠ¨æ€é—¨æ§ç­–ç•¥ï¼Œåœ¨æ¯ä¸€æ­¥è§£ç æ—¶åˆ©ç”¨å†²çªä¿¡å·å’Œä¸Šä¸‹æ–‡ç½®ä¿¡åº¦çš„ç¨³å®šèåˆï¼Œå†³å®šå¯¹ä¸Šä¸‹æ–‡çš„ä¿¡ä»»ç¨‹åº¦ï¼Œå®ç°äº†åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¯¹ä¸Šä¸‹æ–‡çš„åˆç†ä¾èµ–ï¼Œé¿å…è¿‡åº¦ä¾èµ–å…ˆéªŒæˆ–ä¸Šä¸‹æ–‡ä»»æ„ä¸€æ–¹ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ä¸Šï¼Œé’ˆå¯¹é—®ç­”ï¼ˆQAï¼‰ã€æ‘˜è¦ã€é•¿æ–‡æœ¬é—®ç­”ï¼ˆLFQAï¼‰ç­‰å¤šæ ·åŸºå‡†ä»»åŠ¡å¼€å±•å¤§é‡å®éªŒã€‚ä¸ AdaCAD ç­‰å¼ºåŸºçº¿ç›¸æ¯”ï¼ŒCoCoA å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼šåœ¨ QA ä»»åŠ¡ä¸­å‡†ç¡®ç‡æ˜¾è‘—æå‡ï¼Œå¹³å‡æ¯” AdaCAD é«˜ 9.2 ä¸ªç™¾åˆ†ç‚¹ï¼›åœ¨æ‘˜è¦å’Œ LFQA ä»»åŠ¡ä¸­ï¼Œå…³é”®åŸºå‡†ä¸Šäº‹å®æ€§å¹³å‡æå‡é«˜è¾¾ 2.5 ä¸ªç™¾åˆ†ç‚¹ï¼›åŒæ—¶ï¼Œå¯¹å†²çªå˜åŒ–å±•ç°å‡ºæ›´ä¼˜çš„æ•æ„Ÿæ€§ï¼Œåœ¨é«˜å†²çªåœºæ™¯å‡†ç¡®è§£å†³å†²çªï¼Œä½å†²çªåœºæ™¯ä¹Ÿèƒ½ä¿æŒæ­£ç¡®é¢„æµ‹ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. å†²çªæ£€æµ‹æ–¹å¼åˆ›æ–°ï¼šé‡‡ç”¨ RÃ©nyi æ•£åº¦ä¸ºå¤„ç†åˆ†å¸ƒå·®å¼‚æä¾›äº†æ–°è§†è§’ï¼Œåœ¨éœ€å…³æ³¨åˆ†å¸ƒå°¾éƒ¨å˜åŒ–çš„åœºæ™¯æœ‰å€Ÿé‰´ä»·å€¼ã€‚  
2. ç½®ä¿¡åº¦åº¦é‡èåˆï¼šå°†ç†µå·®ä¸ä¸Šä¸‹æ–‡å³°å€¼ç»“åˆè¡¡é‡ç½®ä¿¡åº¦ï¼Œä¸ºå¤šç»´åº¦è¯„ä¼°ä¿¡æ¯å¯é æ€§æä¾›æ€è·¯ã€‚  
3. åŠ¨æ€è‡ªé€‚åº”æœºåˆ¶ï¼šè§£ç æ—¶åŠ¨æ€å†³å®šå¯¹ä¸Šä¸‹æ–‡ä¿¡ä»»åº¦çš„ç­–ç•¥ï¼Œä¸ºåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¹³è¡¡ä¸åŒçŸ¥è¯†æºæä¾›äº†å¯å‚è€ƒçš„æ¡†æ¶ï¼Œå¯åº”ç”¨äºå„ç±»éœ€æ•´åˆå¤–éƒ¨çŸ¥è¯†çš„ç”Ÿæˆä»»åŠ¡ä»¥æå‡å¿ å®æ€§ã€‚  
4. å¤šä»»åŠ¡éªŒè¯æ€è·¯ï¼šåœ¨ QAã€æ‘˜è¦ã€LFQA ç­‰å¤šç§ä»»åŠ¡éªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ï¼Œè¿™ç§å¤šä»»åŠ¡éªŒè¯æ¨¡å¼å¯ä¸ºæ–¹æ³•é€šç”¨æ€§éªŒè¯æä¾›å‚è€ƒã€‚

## risk-assessment-and-security-analysis-of-large-language-models
### Abstract
As large language models (LLMs) expose systemic security challenges in high
risk applications, including privacy leaks, bias amplification, and malicious
abuse, there is an urgent need for a dynamic risk assessment and collaborative
defence framework that covers their entire life cycle. This paper focuses on
the security problems of large language models (LLMs) in critical application
scenarios, such as the possibility of disclosure of user data, the deliberate
input of harmful instructions, or the models bias. To solve these problems, we
describe the design of a system for dynamic risk assessment and a hierarchical
defence system that allows different levels of protection to cooperate. This
paper presents a risk assessment system capable of evaluating both static and
dynamic indicators simultaneously. It uses entropy weighting to calculate
essential data, such as the frequency of sensitive words, whether the API call
is typical, the realtime risk entropy value is significant, and the degree of
context deviation. The experimental results show that the system is capable of
identifying concealed attacks, such as role escape, and can perform rapid risk
evaluation. The paper uses a hybrid model called BERT-CRF (Bidirectional
Encoder Representation from Transformers) at the input layer to identify and
filter malicious commands. The model layer uses dynamic adversarial training
and differential privacy noise injection technology together. The output layer
also has a neural watermarking system that can track the source of the content.
In practice, the quality of this method, especially important in terms of
customer service in the financial industry.
### ğŸŒŸ è®ºæ–‡è§£è¯» | å¤§è¯­è¨€æ¨¡å‹çš„é£é™©è¯„ä¼°ä¸å®‰å…¨åˆ†æï¼šå…¨ç”Ÿå‘½å‘¨æœŸé˜²æŠ¤æ–°èŒƒå¼

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒ»ç–—è¾…åŠ©ã€é‡‘èé¢„æµ‹ç­‰å‚ç›´é¢†åŸŸå±•ç°å®ç”¨ä»·å€¼çš„åŒæ—¶ï¼Œä¹Ÿæš´éœ²å‡ºç³»ç»Ÿæ€§å®‰å…¨æŒ‘æˆ˜ï¼Œæ¶µç›–è®­ç»ƒæ•°æ®éšç§æ³„éœ²ã€æ¨¡å‹å†³ç­–åè§æ”¾å¤§ã€ç”Ÿæˆå†…å®¹è¢«æ¶æ„æ»¥ç”¨ç­‰é£é™©ã€‚å¦‚GPT - 4å¯¹æŠ—æµ‹è¯•ä¸­è¶Šç‹±æ”»å‡»æˆåŠŸç‡è¶…å››åˆ†ä¹‹ä¸€ï¼ŒCivilCommentsæ•°æ®é›†æ˜¾ç¤ºæ¶‰åŠå°‘æ•°ç¾¤ä½“è¯„è®ºå­˜åœ¨ç³»ç»Ÿæ€§æƒ…æ„Ÿåè§ç­‰ã€‚ç°æœ‰è¯„ä¼°ç³»ç»Ÿç¢ç‰‡åŒ–ï¼Œé˜²å¾¡æœºåˆ¶åœ¨åŠ¨æ€å¨èƒè¦†ç›–ã€é€‚åº”æ€§ç­‰æ–¹é¢å­˜åœ¨å±€é™ï¼Œå› æ­¤äºŸéœ€æ„å»ºè¦†ç›–å…¨ç”Ÿå‘½å‘¨æœŸçš„åŠ¨æ€é£é™©è¯„ä¼°ä¸ååŒé˜²å¾¡æ¡†æ¶ï¼Œè¿™æ—¢æ˜¯AIæŠ€æœ¯æ¼”è¿›å†…åœ¨éœ€æ±‚ï¼Œä¹Ÿæ˜¯åº”å¯¹æ™ºèƒ½ç³»ç»Ÿç¤¾ä¼šä¼¦ç†æŒ‘æˆ˜çš„å…³é”®è·¯å¾„ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ„å»ºåŠ¨æ€é£é™©æŒ‡æ ‡ç³»ç»Ÿ  
å»ºç«‹å…¼å…·å®æ—¶ç›‘æµ‹ä¸å®šé‡è¯„ä¼°åŒé‡åŠŸèƒ½çš„åŠ¨æ€é£é™©æŒ‡æ ‡ç³»ç»Ÿï¼Œæ•´åˆé™æ€ä¸åŠ¨æ€æŒ‡æ ‡æ‰“é€ å¤šç»´åº¦é£é™©è¯„ä¼°ä½“ç³»ã€‚é‡‡ç”¨ç†µæƒæ³•è¿›è¡Œå®¢è§‚åŠ æƒï¼Œè§£å†³ç°æœ‰è¯„ä¼°ç³»ç»Ÿç¢ç‰‡åŒ–é—®é¢˜ï¼Œä¸ºä¼ ç»Ÿé™æ€è¯„ä¼°æ–¹æ³•æä¾›æŠ€æœ¯å¯¹ç…§ã€‚åŒæ—¶æ•´åˆPrometheuså®æ—¶ç›‘æµ‹APIæ„å»ºé£é™©åŠ¨æ€é‡åŒ–ç³»ç»Ÿï¼Œåˆ©ç”¨NSFOCUS Risk Matrix v1å¼€å‘è‡ªé€‚åº”é˜ˆå€¼åˆ’åˆ†ç®—æ³•ï¼Œé€šè¿‡é£é™©ç­‰çº§ï¼ˆT1åˆ°T4ï¼‰åŠ¨æ€æ˜ å°„ï¼Œæœ‰æ•ˆæ£€æµ‹è¶Šç‹±æ”»å‡»ã€è§’è‰²æ‰®æ¼”é€ƒé€¸ç­‰æ–°æ”»å‡»æ¨¡å¼ï¼Œæ£€æµ‹å»¶è¿Ÿå‹ç¼©è‡³50mså†…ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç ”å‘åˆ†å±‚é˜²å¾¡æŠ€æœ¯æ¨¡å—  
å¼€å‘é›†æˆåŸºç¡€ä¿æŠ¤å±‚ä¸åŠ¨æ€å“åº”å±‚çš„åˆ†å±‚é˜²å¾¡æŠ€æœ¯æ¨¡å—ï¼ŒååŒæå‡é˜²å¾¡å“åº”é€Ÿåº¦ä¸èƒ½åŠ›ã€‚è¾“å…¥å±‚é‡‡ç”¨BERT - CRFæ··åˆæ¨¡å‹è¯†åˆ«è¿‡æ»¤æ¶æ„æŒ‡ä»¤ï¼›æ¨¡å‹å±‚ç»“åˆåŠ¨æ€å¯¹æŠ—è®­ç»ƒä¸å·®åˆ†éšç§å™ªå£°æ³¨å…¥æŠ€æœ¯ï¼›è¾“å‡ºå±‚é…å¤‡å¯è¿½è¸ªå†…å®¹æ¥æºçš„ç¥ç»æ°´å°ç³»ç»Ÿã€‚å„å±‚ååŒå·¥ä½œï¼Œåœ¨ä¿éšœå®‰å…¨çš„åŒæ—¶å¹³è¡¡ç³»ç»Ÿæ€§èƒ½ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šè®¾è®¡è·¨åœºæ™¯å®éªŒéªŒè¯å¹³å°  
è®¾è®¡å®ç°æ•´åˆå…¬å…±æ•°æ®é›†ã€GPT - 4åˆæˆæ•°æ®ã€è¡Œä¸šç‰¹å®šåŒ¿åæ•°æ®çš„å¤šæºæ··åˆéªŒè¯æ–¹æ¡ˆï¼Œæ­å»ºå…·æœ‰åŠ¨æ€æ¼”åŒ–ç‰¹å¾çš„å®éªŒç¯å¢ƒï¼Œè¦†ç›–é›¶æ ·æœ¬è¶Šç‹±æ”»å‡»ã€è·¨è¯­è¨€æç¤ºæ³¨å…¥æ”»å‡»ç­‰å¤æ‚æ”»å‡»æ¨¡å¼ï¼Œæµ‹è¯•éªŒè¯é˜²å¾¡æŠ€æœ¯å¯¹æ–°æ”»å‡»æ¨¡å¼çš„è¦†ç›–èƒ½åŠ›ï¼Œè§£å†³é€‚åº”æ€§ä¸è¦†ç›–ä¸è¶³é—®é¢˜ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
å®éªŒæ•°æ®è¡¨æ˜é˜²å¾¡æœºåˆ¶å¤šç»´åº¦è¡¨ç°è‰¯å¥½ï¼šå®‰å…¨é˜²æŠ¤æ–¹é¢ï¼Œæ¶æ„ä»£ç æ‰§è¡ŒæˆåŠŸç‡ä»åŸºçº¿23%é™è‡³1%ï¼ˆé€šè¿‡Pythonè§£é‡Šå™¨æ²™ç®±é™åˆ¶å®ç°ï¼‰ï¼›ç³»ç»Ÿæ€§èƒ½æ–¹é¢ï¼Œå¼•å…¥å‚æ•°ä¸è¶…1äº¿çš„è½»é‡çº§BERTæ¨¡å‹åï¼Œè¾“å…¥å±‚å¤„ç†å»¶è¿Ÿå¢åŠ æ§åˆ¶åœ¨5æ¯«ç§’å†…ï¼Œè”é‚¦é›†ç¾¤ä¼˜åŒ–æŠ€æœ¯ä½¿é«˜å¹¶å‘åœºæ™¯å»¶è¿Ÿæ³¢åŠ¨ç»´æŒåœ¨10%æ ‡è®°é˜ˆå€¼å†…ï¼›æ¨¡å‹è´¨é‡æ–¹é¢ï¼Œåˆ†å±‚é˜²å¾¡æ¶æ„å¯¹æ¨¡å‹æ¨ç†é€Ÿåº¦å’Œç”Ÿæˆæ–‡æœ¬æµç•…åº¦çš„å½±å“ä½äºé¢„å®šä¹‰å®¹å¿é˜ˆå€¼ã€‚ä¸”å¤„ç†æ–°æ”»å‡»é€Ÿåº¦çº¦ä¸ºä¹‹å‰æ–¹æ¡ˆçš„3å€ï¼Œç”Ÿæˆæ–‡æœ¬è´¨é‡ä¸å—å½±å“ã€‚åœ¨NVIDIA A100 GPUé›†ç¾¤å’ŒçœŸå®è¡Œä¸šæ•°æ®é›†ä¸Šå®éªŒï¼Œæ¡†æ¶æœ‰æ•ˆï¼Œè¶…å¤§è§„æ¨¡æ¨¡å‹é˜²å¾¡å¼€é”€å¢é•¿æ›´ç¼“ï¼Œåœ¨é˜²å¾¡å¤šæ¨¡æ€æ”»å‡»ä¸Šè¡¨ç°æ›´ä¼˜ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. é£é™©è¯„ä¼°ä¸é˜²å¾¡ä½“ç³»æ„å»ºæ€è·¯ï¼šé’ˆå¯¹æŠ€æœ¯å…¨ç”Ÿå‘½å‘¨æœŸé£é™©ï¼Œæ•´åˆåŠ¨é™æ€æŒ‡æ ‡ã€é‡‡ç”¨ç†µæƒæ³•ç­‰å®¢è§‚åŠ æƒæ–¹å¼æ„å»ºè¯„ä¼°ç³»ç»Ÿï¼Œä»¥åŠåˆ†å±‚ååŒçš„é˜²å¾¡æ¨¡å—è®¾è®¡ï¼Œä¸ºAIç³»ç»Ÿå®‰å…¨æ²»ç†æä¾›äº†ä»è¯„ä¼°åˆ°é˜²å¾¡çš„å®Œæ•´æŠ€æœ¯é“¾è·¯å‚è€ƒï¼Œå¯æ¨å¹¿è‡³å¤šæ¨¡æ€å­¦ä¹ ã€ååŒå­¦ä¹ ç­‰åœºæ™¯ã€‚  
2. å®éªŒéªŒè¯æ–¹æ¡ˆï¼šå¤šæºæ··åˆæ•°æ®æ„å»ºåŠ¨æ€æ¼”åŒ–å®éªŒç¯å¢ƒï¼Œè¦†ç›–å¤æ‚æ”»å‡»æ¨¡å¼çš„æ€è·¯ï¼Œä¸ºæ£€éªŒå®‰å…¨é˜²å¾¡æŠ€æœ¯æœ‰æ•ˆæ€§æä¾›äº†æ›´è´´è¿‘çœŸå®åœºæ™¯çš„éªŒè¯èŒƒå¼ï¼Œæœ‰åŠ©äºåç»­ç ”ç©¶ä¸­æ›´å…¨é¢è¯„ä¼°é˜²å¾¡æœºåˆ¶ã€‚  
3. æ€§èƒ½ä¸å®‰å…¨å¹³è¡¡å®è·µï¼šåœ¨å„å±‚é˜²å¾¡æŠ€æœ¯å¼•å…¥æ—¶å…³æ³¨ç³»ç»Ÿæ€§èƒ½ï¼ˆå¦‚è½»é‡çº§æ¨¡å‹é€‰æ‹©ã€é›†ç¾¤ä¼˜åŒ–ï¼‰ï¼Œä¿éšœå®‰å…¨åŒæ—¶ä¸æ˜¾è‘—å½±å“æ¨¡å‹æœåŠ¡è´¨é‡ï¼Œä¸ºå®é™…å·¥ä¸šéƒ¨ç½²ä¸­å®‰å…¨æ–¹æ¡ˆè½åœ°æä¾›äº†æ€§èƒ½æƒè¡¡çš„å®è·µç»éªŒã€‚

## dear--dual-stage-document-reranking-with-reasoning-agents-via-llm-distillation
### Abstract
Large Language Models (LLMs) have transformed listwise document reranking by
enabling global reasoning over candidate sets, yet single models often struggle
to balance fine-grained relevance scoring with holistic cross-document
analysis. We propose \textbf{De}ep\textbf{A}gent\textbf{R}ank (\textbf{\DeAR}),
an open-source framework that decouples these tasks through a dual-stage
approach, achieving superior accuracy and interpretability. In \emph{Stage 1},
we distill token-level relevance signals from a frozen 13B LLaMA teacher into a
compact \{3, 8\}B student model using a hybrid of cross-entropy, RankNet, and
KL divergence losses, ensuring robust pointwise scoring. In \emph{Stage 2}, we
attach a second LoRA adapter and fine-tune on 20K GPT-4o-generated
chain-of-thought permutations, enabling listwise reasoning with
natural-language justifications. Evaluated on TREC-DL19/20, eight BEIR
datasets, and NovelEval-2306, \DeAR surpasses open-source baselines by +5.1
nDCG@5 on DL20 and achieves 90.97 nDCG@10 on NovelEval, outperforming GPT-4 by
+3.09. Without fine-tuning on Wikipedia, DeAR also excels in open-domain QA,
achieving 54.29 Top-1 accuracy on Natural Questions, surpassing baselines like
MonoT5, UPR, and RankGPT. Ablations confirm that dual-loss distillation ensures
stable calibration, making \DeAR a highly effective and interpretable solution
for modern reranking systems.\footnote{Dataset and code available at
https://github.com/DataScienceUIBK/DeAR-Reranking.}.
### ğŸŒŸ è®ºæ–‡è§£è¯» | DeARï¼šåŒé˜¶æ®µæ–‡æ¡£é‡æ’ï¼Œå€ŸLLMè’¸é¦ä¸æ¨ç†æ™ºèƒ½ä½“å®ç°é«˜æ•ˆç²¾å‡†æ’åº

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
æ–‡æ¡£é‡æ’ï¼ˆDocument Rerankingï¼‰åœ¨ç½‘é¡µæœç´¢ã€å¼€æ”¾åŸŸé—®ç­”ã€äº‹å®æ ¸æŸ¥ç­‰ä»»åŠ¡ä¸­è‡³å…³é‡è¦ï¼Œå…¶è´¨é‡ç›´æ¥å½±å“ä¸‹æ¸¸ç»“æœã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ä¸ºåˆ—è¡¨çº§æ–‡æ¡£é‡æ’å¸¦æ¥å…¨å±€æ¨ç†èƒ½åŠ›ï¼Œä½†å•ä¸€æ¨¡å‹å¾ˆéš¾åœ¨ç»†ç²’åº¦ç›¸å…³æ€§è¯„åˆ†ä¸æ•´ä½“è·¨æ–‡æ¡£åˆ†æé—´å–å¾—å¹³è¡¡ï¼›åŒæ—¶ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–æ˜‚è´µé—­æºAPIã€å—ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼Œä¸”æ¨ç†è„†å¼±ï¼Œå¼€æºè’¸é¦æ–¹æ¡ˆè¿˜å­˜åœ¨ä¼ æ’­æ•™å¸ˆæ¨¡å‹é”™è¯¯ï¼ˆå¦‚å¹»è§‰ã€é”™è¯¯æ’åºï¼‰çš„é£é™©ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºDeARæ¡†æ¶ï¼Œè¯•å›¾è§£å†³â€œå¦‚ä½•å¹³è¡¡è’¸é¦æŸå¤±ä»¥å‡è½»å™ªå£°å¹¶ä¼ é€’æ•™å¸ˆä¿¡å·â€ä¸â€œå¦‚ä½•åœ¨ä¸è¶…è½½ä¸Šä¸‹æ–‡çš„å‰æä¸‹ä¿ç•™åˆ—è¡¨çº§æ¨ç†ä¼˜åŠ¿â€ä¸¤å¤§é—®é¢˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šåŒé˜¶æ®µé‡æ’æ¡†æ¶è®¾è®¡  
DeARé‡‡ç”¨**åŒé˜¶æ®µ**ç­–ç•¥è§£è€¦â€œç»†ç²’åº¦ç›¸å…³æ€§è¯„åˆ†â€ä¸â€œå…¨å±€è·¨æ–‡æ¡£æ¨ç†â€ä»»åŠ¡ï¼š  
- **é˜¶æ®µ1ï¼ˆPointwiseé˜¶æ®µï¼‰**ï¼šä»¥å†»ç»“çš„13Bè§„æ¨¡LLaMAä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œé€šè¿‡â€œäº¤å‰ç†µ + RankNet + KLæ•£åº¦â€æ··åˆæŸå¤±ï¼Œå°†tokençº§ç›¸å…³æ€§ä¿¡å·è’¸é¦åˆ°æ›´ç´§å‡‘çš„{3, 8}Bè§„æ¨¡å­¦ç”Ÿæ¨¡å‹ä¸­ï¼Œä¿éšœå¼ºå¤§çš„é€ç‚¹ï¼ˆpointwiseï¼‰è¯„åˆ†èƒ½åŠ›ã€‚  
- **é˜¶æ®µ2ï¼ˆListwiseé˜¶æ®µï¼‰**ï¼šç»™å­¦ç”Ÿæ¨¡å‹é™„åŠ ç¬¬äºŒä¸ªLoRAé€‚é…å™¨ï¼Œåœ¨2ä¸‡æ¡ç”±GPT - 4oç”Ÿæˆçš„â€œæ€ç»´é“¾ï¼ˆCoTï¼‰â€ permutationsæ•°æ®ä¸Šå¾®è°ƒï¼Œè®©æ¨¡å‹å…·å¤‡å¸¦è‡ªç„¶è¯­è¨€è§£é‡Šçš„åˆ—è¡¨çº§ï¼ˆlistwiseï¼‰æ¨ç†èƒ½åŠ›ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæ•™å¸ˆ-å­¦ç”Ÿè’¸é¦ pipeline  
æ„å»ºæ•™å¸ˆåˆ°å­¦ç”Ÿçš„çŸ¥è¯†ä¼ é€’ pipelineï¼Œæ•™å¸ˆåŸºäºLLMç”Ÿæˆæ­£è´Ÿæ–‡æ¡£çš„ç›¸å…³æ€§logitsï¼Œå­¦ç”Ÿé€šè¿‡æ··åˆæŸå¤±ï¼ˆäº¤å‰ç†µä¿éšœåˆ†ç±»ã€RankNetä¼˜åŒ–æ’åºåå¥½ã€KLæ•£åº¦å¯¹é½æ•™å¸ˆåˆ†å¸ƒï¼‰å­¦ä¹ è¿™äº›ç»†ç²’åº¦ä¿¡å·ï¼Œæ—¢åˆ©ç”¨å¤§æ¨¡å‹çŸ¥è¯†ï¼Œåˆè®©å°æ¨¡å‹é«˜æ•ˆæ‰¿æ¥ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šåˆæˆæ€ç»´é“¾æ•°æ®æ„å»º  
äººå·¥æ„é€ 2ä¸‡æ¡å¸¦CoTæ¨ç†çš„åˆæˆæ’åºæ ·æœ¬ï¼Œè®©å­¦ç”Ÿæ¨¡å‹åœ¨é˜¶æ®µ2å­¦ä¹ â€œé€æ­¥æ¨ç† + æœ€ç»ˆæ’åºâ€çš„èƒ½åŠ›ï¼Œæ—¢ä¿ç•™åˆ—è¡¨çº§é‡æ’çš„å…¨å±€è§†è§’ï¼Œåˆé€šè¿‡è‡ªç„¶è¯­è¨€è§£é‡Šæå‡å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶é¿å…ä¸Šä¸‹æ–‡çª—å£è¿‡è½½ã€‚  


### ğŸ“ˆ å®éªŒç»“æœ
- **é€šç”¨é‡æ’ä»»åŠ¡**ï¼šåœ¨TREC - DL19/20ã€8ä¸ªBEIRæ•°æ®é›†ä¸NovelEval - 2306ä¸Šï¼ŒDeARå¤§å¹…è¶…è¶Šå¼€æºåŸºçº¿ã€‚å¦‚DL20æ•°æ®é›†nDCG@5æ¯”åŸºçº¿é«˜+5.1ï¼›NovelEvalä¸ŠnDCG@10è¾¾90.97ï¼Œè¶…è¿‡GPT - 4 + 3.09ã€‚  
- **å¼€æ”¾åŸŸé—®ç­”**ï¼šæœªåœ¨Wikipediaä¸Šå¾®è°ƒæ—¶ï¼ŒNatural Questionsä»»åŠ¡Top - 1å‡†ç¡®ç‡è¾¾54.29ï¼Œè¶…è¿‡MonoT5ã€UPRã€RankGPTç­‰åŸºçº¿ã€‚  
- **æ¶ˆèå®éªŒ**ï¼šéªŒè¯äº†åŒæŸå¤±è’¸é¦ï¼ˆé˜¶æ®µ1æ··åˆæŸå¤±ï¼‰èƒ½ä¿éšœæ¨¡å‹æ ¡å‡†ç¨³å®šæ€§ï¼Œè¯æ˜å„æ¨¡å—å¯¹æ€§èƒ½æå‡çš„å¿…è¦æ€§ã€‚  


### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **åŒé˜¶æ®µè§£è€¦ä»»åŠ¡**ï¼šå°†â€œç»†ç²’åº¦è¯„åˆ†â€ä¸â€œå…¨å±€æ¨ç†â€æ‹†åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œé™ä½å•ä¸€æ¨¡å‹å­¦ä¹ éš¾åº¦ï¼Œä¸ºå¤æ‚ä»»åŠ¡æ‹†è§£æä¾›æ€è·¯ã€‚  
2. **æ··åˆæŸå¤±è’¸é¦**ï¼šç»“åˆäº¤å‰ç†µã€RankNetã€KLæ•£åº¦çš„è’¸é¦æ–¹å¼ï¼Œå¹³è¡¡â€œçŸ¥è¯†ä¼ é€’â€ä¸â€œå™ªå£°è¿‡æ»¤â€ï¼Œåœ¨æ¨¡å‹å‹ç¼©ä¸æ€§èƒ½ä¿ç•™é—´æ‰¾åˆ°æ›´ä¼˜è§£ã€‚  
3. **æ€ç»´é“¾æ•°æ®å¢å¼º**ï¼šç”¨å¤§æ¨¡å‹ç”Ÿæˆå¸¦æ¨ç†æ­¥éª¤çš„åˆæˆæ•°æ®ï¼Œå¢å¼ºå°æ¨¡å‹åˆ—è¡¨çº§æ¨ç†ä¸å¯è§£é‡Šæ€§ï¼Œä¸ºâ€œç”¨å»‰ä»·æ•°æ®æå‡æ¨¡å‹å¤æ‚ä»»åŠ¡èƒ½åŠ›â€æä¾›å®è·µå‚è€ƒã€‚  
4. **å¼€æºä¸é«˜æ•ˆ**ï¼šæ¡†æ¶å¼€æºä¸”æ¨ç†é«˜æ•ˆï¼Œåœ¨æ€§èƒ½æ¯”è‚©GPT - 4oç­‰å¤§æ¨¡å‹æ—¶ï¼Œæ›´é€‚åˆè½åœ°éƒ¨ç½²ï¼Œä¸ºäº§ä¸šç•Œæä¾›è½»é‡å¼ºæ€§èƒ½çš„é‡æ’æ–¹æ¡ˆã€‚  

## from-confidence-to-collapse-in-llm-factual-robustness
### Abstract
Ensuring the robustness of factual knowledge in LLMs is critical for reliable
applications in tasks such as question answering and reasoning. However,
existing evaluation methods predominantly focus on performance-based metrics,
often investigating from the perspective of prompt perturbations, which
captures only the externally triggered side of knowledge robustness. To bridge
this gap, we introduce a principled approach to measure factual robustness from
the perspective of the generation process by analyzing token distribution
entropy in combination with temperature scaling sensitivity. These two factors
build the Factual Robustness Score (FRS), a novel metric which quantifies the
stability of a fact against perturbations in decoding conditions, given its
initial uncertainty. To validate our approach, we conduct extensive experiments
on 5 LLMs across 3 closed-book QA datasets (SQuAD, TriviaQA, and HotpotQA). We
show that factual robustness varies significantly -- smaller models report an
FRS of $0.76$, larger ones $0.93$ -- with accuracy degrading by ~$60\%$ under
increased uncertainty. These insights demonstrate how entropy and temperature
scaling impact factual accuracy, and lay a foundation for developing more
robust knowledge retention and retrieval in future models.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ä»ç½®ä¿¡åˆ°å´©å¡Œï¼šLLMäº‹å®é²æ£’æ€§çš„å…¨æ–°è§†è§’

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é—®ç­”ã€æ¨ç†ç­‰ä»»åŠ¡ä¸­å±•ç°å¼ºå¤§èƒ½åŠ›ï¼Œä½†äº‹å®ç¨³å®šæ€§ä»æ˜¯æŒ‘æˆ˜ã€‚ä¼ ç»Ÿè¯„ä¼°èšç„¦åŸºäºæ€§èƒ½çš„æŒ‡æ ‡ï¼Œä»promptæ‰°åŠ¨è§’åº¦åˆ†æï¼Œä»…æ•æ‰çŸ¥è¯†é²æ£’æ€§çš„å¤–éƒ¨è§¦å‘å±‚é¢ï¼›ä¸”å¸¸é‡‡ç”¨å•æ¸©åº¦è¯„ä¼°ï¼Œæœªç³»ç»Ÿåˆ†æä¸ç¡®å®šæ€§å¼•å…¥ä¸‹äº‹å®è¾“å‡ºçš„é€€åŒ–æƒ…å†µã€‚ä¸ºå¼¥è¡¥ç¼ºå£ï¼Œè®ºæ–‡ä»ç”Ÿæˆè¿‡ç¨‹è§†è§’è¡¡é‡äº‹å®é²æ£’æ€§ï¼Œæ¢ç´¢çŸ¥è¯†åœ¨æ¨¡å‹ä¸­å­˜å‚¨ä¸æ£€ç´¢çš„å¯é æ€§ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºäº‹å®é²æ£’æ€§åˆ†æ•°ï¼ˆFRSï¼‰  
ä¸åŒäºä»¥å¾€å­¤ç«‹æ¸©åº¦å€¼è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„å·¥ä½œï¼ŒFRSæ•´åˆç†µä¸â€œæ–­è£‚â€æ¸©åº¦ä¸¤ä¸ªç»´åº¦ã€‚ç†µé‡åŒ–æ¨¡å‹å¯¹ç­”æ¡ˆçš„å†…åœ¨ç½®ä¿¡åº¦ï¼Œâ€œæ–­è£‚â€æ¸©åº¦æ•æ‰äº‹å®åœ¨å‡ºé”™å‰èƒ½æ‰¿å—çš„ä¸ç¡®å®šæ€§ç¨‹åº¦ï¼Œä»¥æ­¤è¡¡é‡LLMä¸­äº‹å®çŸ¥è¯†çš„ç¨³å®šæ€§ï¼Œè¶…è¶Šç®€å•å‡†ç¡®ç‡ï¼Œæ·±å…¥æ´å¯ŸçŸ¥è¯†å­˜å‚¨ä¸æ£€ç´¢çš„å¯é æ€§ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šèšç„¦ç”Ÿæˆè¿‡ç¨‹å†…æœºåˆ¶åˆ†æäº‹å®é²æ£’æ€§  
åŒºåˆ«äºç°æœ‰ä»å¤–éƒ¨promptä¿®æ”¹ï¼ˆå¦‚å¯¹æŠ—æ”»å‡»ã€è¯­ä¹‰ç­‰ä»·é—®é¢˜è¡¨è¿°ç­‰ï¼‰è§’åº¦ç ”ç©¶é²æ£’æ€§çš„å·¥ä½œï¼Œæœ¬æ–‡å°†ç„¦ç‚¹è½¬å‘ç”Ÿæˆè¿‡ç¨‹çš„æ¨¡å‹ä¾§ï¼Œæ¢ç©¶å†…éƒ¨æœºåˆ¶å¯¹äº‹å®é²æ£’æ€§çš„è´¡çŒ®ã€‚é€šè¿‡åˆ†ætokenåˆ†å¸ƒç†µç»“åˆæ¸©åº¦ç¼©æ”¾æ•æ„Ÿæ€§ï¼Œä»ç”Ÿæˆè¿‡ç¨‹è§†è§’è¡¡é‡äº‹å®é²æ£’æ€§ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨5ä¸ªLLMã€3ä¸ªé—­å·QAæ•°æ®é›†ï¼ˆSQuADã€TriviaQAã€HotpotQAï¼‰ä¸Šå¼€å±•å¤§é‡å®éªŒï¼š  
- äº‹å®é²æ£’æ€§å·®å¼‚æ˜¾è‘—ï¼Œå°æ¨¡å‹FRSä¸º0.76ï¼Œå¤§æ¨¡å‹ä¸º0.93ï¼›  
- ä¸ç¡®å®šæ€§å¢åŠ æ—¶å‡†ç¡®ç‡ä¸‹é™çº¦60%ï¼›  
- é«˜ç†µäº‹å®åœ¨æ¸©åº¦æ‰°åŠ¨ä¸‹é€€åŒ–æ›´ä¸¥é‡ï¼Œä½ç†µäº‹å®æ›´ç¨³å®šï¼›æ¨¡å‹å¤§å°å¹¶éé²æ£’æ€§å”¯ä¸€å†³å®šå› ç´ ï¼Œæ¶æ„ä¸è®­ç»ƒå·®å¼‚ä¹Ÿæœ‰å½±å“ï¼›æ•°å€¼ç±»äº‹å®æ¯”å…¶ä»–ç±»å‹æ›´å…·éŸ§æ€§ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
- è¯„ä¼°ç»´åº¦æ‹“å±•ï¼šå¼•å…¥FRS metricï¼Œä¸ºLLMäº‹å®çŸ¥è¯†ç¨³å®šæ€§è¯„ä¼°æä¾›æ–°èŒƒå¼ï¼Œåç»­ç ”ç©¶å¯å€Ÿé‰´è¯¥æ•´åˆç†µä¸æ¸©åº¦çš„ç³»ç»Ÿè¯„ä¼°æ€è·¯ï¼›  
- å†…éƒ¨æœºåˆ¶å…³æ³¨ï¼šå°†é²æ£’æ€§åˆ†æä»å¤–éƒ¨promptè½¬å‘ç”Ÿæˆè¿‡ç¨‹å†…éƒ¨ï¼Œå¯å‘ç ”ç©¶è€…é‡è§†æ¨¡å‹å†…åœ¨ç”Ÿæˆæœºåˆ¶å¯¹äº‹å®ç¨³å®šæ€§çš„å½±å“ï¼›  
- é²æ£’æ€§å½±å“å› ç´ è®¤çŸ¥ï¼šæ­ç¤ºç†µã€æ¸©åº¦ç¼©æ”¾å¯¹äº‹å®å‡†ç¡®ç‡çš„ä½œç”¨ï¼Œä»¥åŠæ¨¡å‹å¤§å°ã€æ¶æ„ã€è®­ç»ƒæ–¹æ³•ã€çŸ¥è¯†ç±»å‹ç­‰å¯¹é²æ£’æ€§çš„å½±å“ï¼Œä¸ºæœªæ¥æ¨¡å‹æ›´é²æ£’çš„çŸ¥è¯†ç•™å­˜ä¸æ£€ç´¢ä¼˜åŒ–æä¾›æ–¹å‘å‚è€ƒã€‚

## the-fools-are-certain;-the-wise-are-doubtful--exploring-llm-confidence-in-code-completion
### Abstract
Code completion entails the task of providing missing tokens given a
surrounding context. It can boost developer productivity while providing a
powerful code discovery tool. Following the Large Language Model (LLM) wave,
code completion has been approached with diverse LLMs fine-tuned on code (code
LLMs). The performance of code LLMs can be assessed with downstream and
intrinsic metrics. Downstream metrics are usually employed to evaluate the
practical utility of a model, but can be unreliable and require complex
calculations and domain-specific knowledge. In contrast, intrinsic metrics such
as perplexity, entropy, and mutual information, which measure model confidence
or uncertainty, are simple, versatile, and universal across LLMs and tasks, and
can serve as proxies for functional correctness and hallucination risk in
LLM-generated code. Motivated by this, we evaluate the confidence of LLMs when
generating code by measuring code perplexity across programming languages,
models, and datasets using various LLMs, and a sample of 1008 files from 657
GitHub projects. We find that strongly-typed languages exhibit lower perplexity
than dynamically typed languages. Scripting languages also demonstrate higher
perplexity. Perl appears universally high in perplexity, whereas Java appears
low. Code perplexity depends on the employed LLM, but not on the code dataset.
Although code comments often increase perplexity, the language ranking based on
perplexity is barely affected by their presence. LLM researchers, developers,
and users can employ our findings to assess the benefits and suitability of
LLM-based code completion in specific software projects based on how language,
model choice, and code characteristics impact model confidence.
### ğŸŒŸ è®ºæ–‡è§£è¯» | å¤§è¯­è¨€æ¨¡å‹ä»£ç è¡¥å…¨ä¸­çš„ç½®ä¿¡åº¦æ¢ç´¢ï¼šä»å›°æƒ‘åº¦çœ‹æ™ºèƒ½ä¸ç¬ƒå®š

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
ä»£ç è¡¥å…¨èƒ½æå‡å¼€å‘è€…æ•ˆç‡ã€å……å½“ä»£ç å‘ç°å·¥å…·ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æµªæ½®ä¸‹å‡ºç°äº†é’ˆå¯¹ä»£ç ä¼˜åŒ–çš„ä»£ç LLMã€‚è¯„ä¼°ä»£ç LLMæ€§èƒ½æœ‰ä¸‹æ¸¸æŒ‡æ ‡å’Œå†…åœ¨æŒ‡æ ‡ï¼Œä¸‹æ¸¸æŒ‡æ ‡è¯„ä¼°æ¨¡å‹å®ç”¨æ€§æ—¶å­˜åœ¨ä¸å¯é ã€éœ€é¢†åŸŸçŸ¥è¯†ä¸å¤æ‚è®¡ç®—ç­‰é—®é¢˜ï¼›è€Œåƒå›°æƒ‘åº¦ï¼ˆperplexityï¼‰è¿™ç±»å†…åœ¨æŒ‡æ ‡ç®€å•é€šç”¨ï¼Œè¿˜èƒ½åæ˜ æ¨¡å‹ç½®ä¿¡åº¦æˆ–ä¸ç¡®å®šæ€§ï¼Œå¯ä½œä¸ºä»£ç åŠŸèƒ½æ­£ç¡®æ€§ä¸å¹»è§‰é£é™©çš„ä»£ç†æŒ‡æ ‡ã€‚ä½†ç›®å‰ä»£ç ç”Ÿæˆè¯„ä¼°ä¸­ï¼Œä¸‹æ¸¸æŒ‡æ ‡å ä¸»å¯¼ï¼Œå¯¹å†…åœ¨æŒ‡æ ‡ç”¨äºè¯„ä¼°LLMç½®ä¿¡åº¦çš„ç ”ç©¶ä¸è¶³ï¼ŒåŒæ—¶ä»£ç å¹»è§‰é—®é¢˜å‡¸æ˜¾ï¼Œç†è§£æ¨¡å‹ä¸ç¡®å®šæ€§å¾ˆé‡è¦ã€‚å› æ­¤ï¼Œæœ¬æ–‡èšç„¦å›°æƒ‘åº¦æ¥è¯„ä¼°LLMç”Ÿæˆä»£ç æ—¶çš„ç½®ä¿¡åº¦ï¼Œå¡«è¡¥ä»£ç å›°æƒ‘åº¦ç ”ç©¶ç©ºç™½ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºå¯å¤ç°æ–¹æ³•ä¸å¼€æºå·¥å…·åŒ…  
æä¾›äº†ä½¿ç”¨å¤šä¸ªLLMè®¡ç®—ä»£ç å›°æƒ‘åº¦çš„å¯å¤ç°æ–¹æ³•å’Œå¼€æºå·¥å…·åŒ…ï¼Œèƒ½åœ¨ä¸åŒç¼–ç¨‹è¯­è¨€å’Œæ•°æ®é›†ä¸Šè¿›è¡Œæ ‡å‡†åŒ–è¯„ä¼°ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†åŸºç¡€å·¥å…·ä¸æµç¨‹å‚è€ƒã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¤§è§„æ¨¡è¯­è¨€ç‰¹å®šçš„ä»£ç å›°æƒ‘åº¦åˆ†æ  
é¦–æ¬¡é’ˆå¯¹é€šè¿‡LLMæµ‹é‡çš„ä»£ç å›°æƒ‘åº¦å¼€å±•å¤§è§„æ¨¡ã€åŸºäºè¯­è¨€çš„åˆ†æï¼Œæ·±å…¥æ¢ç©¶ä¸åŒç¼–ç¨‹è¯­è¨€ä¸‹æ¨¡å‹ç½®ä¿¡åº¦çš„å˜åŒ–æƒ…å†µï¼Œä¸ºç†è§£è¯­è¨€ä¸æ¨¡å‹ç½®ä¿¡åº¦å…³è”æä¾›æ–°è§†è§’ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå‰–æè¯­è¨€ä¸ä»£ç ç‰¹å¾å’Œå›°æƒ‘åº¦å…³ç³»  
åˆ†æè¯­è¨€å±æ€§ï¼ˆå¦‚å¼ºç±»å‹ã€è¯­è¨€å‡ºç°æ—¶é—´ç­‰ï¼‰ã€ä»£ç ç»“æ„ç‰¹å¾ï¼ˆå¦‚æ³¨é‡Šï¼‰ä¸LLMå›°æƒ‘åº¦çš„å…³ç³»ï¼Œæ˜ç¡®å¼ºç±»å‹ã€è¾ƒæ–°è¯­è¨€é€šå¸¸å›°æƒ‘åº¦æ›´ä½ï¼Œæ³¨é‡Šä¼šå¢åŠ å›°æƒ‘åº¦ç­‰è§„å¾‹ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹4ï¼šæ¢ç©¶å›°æƒ‘åº¦åœ¨LLMå’Œæ•°æ®é›†é—´çš„æ³›åŒ–æ€§  
è¯„ä¼°ä»£ç å›°æƒ‘åº¦åœ¨ä¸åŒLLMå’ŒåŸºå‡†æ•°æ®é›†ä¸Šçš„æ³›åŒ–æ€§ï¼Œç»™å‡ºèƒ½ä¸ºæ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒç­–ç•¥æä¾›å‚è€ƒçš„æ¨¡å¼ï¼ŒåŠ©åŠ›ä¼˜åŒ–ä»£ç LLMåº”ç”¨ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
- ç¼–ç¨‹è¯­è¨€ç»´åº¦ï¼šå¼ºç±»å‹è¯­è¨€æ¯”åŠ¨æ€ç±»å‹è¯­è¨€å›°æƒ‘åº¦æ›´ä½ï¼›è„šæœ¬è¯­è¨€å›°æƒ‘åº¦è¾ƒé«˜ï¼›Perlå›°æƒ‘åº¦æ™®éå¾ˆé«˜ï¼ŒJavaåˆ™è¾ƒä½ã€‚  
- æ¨¡å‹ä¸æ•°æ®é›†ç»´åº¦ï¼šä»£ç å›°æƒ‘åº¦å–å†³äºæ‰€ä½¿ç”¨çš„LLMï¼Œä½†ä¸å—ä»£ç æ•°æ®é›†å½±å“ã€‚  
- ä»£ç æ³¨é‡Šç»´åº¦ï¼šä»£ç æ³¨é‡Šå¸¸å¢åŠ å›°æƒ‘åº¦ï¼Œä½†åŸºäºå›°æƒ‘åº¦çš„è¯­è¨€æ’åå—æ³¨é‡Šå­˜åœ¨çš„å½±å“æå°ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
LLMç ”ç©¶è€…å¯å€ŸåŠ©è¿™äº›å‘ç°ä¼˜åŒ–æ¨¡å‹è¯„ä¼°ä¸è®­ç»ƒç­–ç•¥ï¼›å¼€å‘è€…å’Œç”¨æˆ·èƒ½ä¾æ®è¯­è¨€ã€æ¨¡å‹é€‰æ‹©ã€ä»£ç ç‰¹å¾å¯¹æ¨¡å‹ç½®ä¿¡åº¦çš„å½±å“ï¼Œè¯„ä¼°ç‰¹å®šè½¯ä»¶é¡¹ç›®ä¸­åŸºäºLLMçš„ä»£ç è¡¥å…¨çš„æ”¶ç›Šä¸é€‚ç”¨æ€§ï¼Œæ¯”å¦‚åˆ¶å®šæ›´åˆç†çš„ä»£ç å®¡æŸ¥ç­–ç•¥ï¼ˆå¯¹é«˜ç½®ä¿¡åº¦ä»£ç å»ºè®®è½»é‡å®¡æŸ¥ï¼Œä½ç½®ä¿¡åº¦åˆ™ä¸¥æ ¼å®¡æŸ¥ï¼‰ç­‰ã€‚åŒæ—¶ï¼Œæœ¬æ–‡çš„å¯å¤ç°æ–¹æ³•ä¸å·¥å…·åŒ…ä¹Ÿä¸ºé¢†åŸŸå†…ç ”ç©¶ä»£ç LLMç½®ä¿¡åº¦ç›¸å…³å·¥ä½œæä¾›äº†å¯å¤ç”¨çš„æŠ€æœ¯åŸºç¡€ã€‚ 

## from-bits-to-boardrooms--a-cutting-edge-multi-agent-llm-framework-for-business-excellence
### Abstract
Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ä»ä»£ç åˆ°è‘£äº‹ä¼šï¼šé¢å‘å•†ä¸šå“è¶Šçš„å‰æ²¿å¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨æ•°å­—åŒ–è½¬å‹æ—¶ä»£ï¼Œç°ä»£ä¼ä¸šé¢ä¸´å°†æµ·é‡è¿è¥æ•°æ®è½¬åŒ–ä¸ºæœ‰æ•ˆè‘£äº‹ä¼šå†³ç­–çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œéœ€åœ¨ç»†ç²’åº¦åˆ†æä¸å®è§‚æˆ˜ç•¥é—´å¹³è¡¡ï¼Œåè°ƒå¤šå†³ç­–å±‚å¤æ‚ä¿¡æ¯æµã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½åœ¨å•†ä¸šåº”ç”¨æœ‰æ½œåŠ›ï¼Œä½†ç°æœ‰æ–¹æ³•å·¥ä½œæµç¨‹ç¢ç‰‡åŒ–ï¼Œæœªå……åˆ†åˆ©ç”¨è·¨ç»„ç»‡å±‚çº§ååŒï¼Œå°†ä¸šåŠ¡é—®é¢˜è§†ä¸ºå­¤ç«‹é¢†åŸŸï¼Œå¯¼è‡´è¿è¥æ´å¯Ÿä¸æˆ˜ç•¥æˆæœè„±èŠ‚ï¼Œå‡ºç°ç®¡ç†å±‚ä¿¡æ¯ä¸å¯¹ç§°ã€å†³ç­–å»¶è¿Ÿã€ä¸šåŠ¡ç›®æ ‡ä¸æ—¥å¸¸è¿è¥è„±èŠ‚ç­‰é—®é¢˜ï¼Œè€Œæ•´åˆæ•°æ®é©±åŠ¨æ´å¯Ÿçš„ä¼ä¸šèƒ½æå‡ç”Ÿäº§åŠ›ä¸ç›ˆåˆ©èƒ½åŠ›ï¼Œå› æ­¤éœ€è¦æ–°æ¡†æ¶è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºBusiAgentå¤šæ™ºèƒ½ä½“æ¡†æ¶  
åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼Œæ•´åˆæ‰©å±•çš„è¿ç»­æ—¶é—´é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆCTMDPï¼‰ç”¨äºåŠ¨æ€æ™ºèƒ½ä½“å»ºæ¨¡ï¼Œå¹³è¡¡ä¸åŒå•†ä¸šåœºæ™¯ä¸‹çš„æ¢ç´¢ä¸åˆ©ç”¨ï¼›ç»“åˆå¹¿ä¹‰ç†µåº¦é‡ä¼˜åŒ–åä½œæ•ˆç‡ï¼Œä»¥åŠå¤šå±‚Stackelbergåšå¼ˆå¤„ç†åˆ†å±‚å†³ç­–è¿‡ç¨‹ï¼Œå°†è¿è¥æ•°æ®è½¬åŒ–ä¸ºæˆ˜ç•¥æ´å¯Ÿï¼Œå®ç°æ•°æ®é©±åŠ¨çš„è‘£äº‹ä¼šå†³ç­–ï¼Œç›¸æ¯”ç°æœ‰åŸºçº¿åœ¨é—®é¢˜åˆ†æï¼ˆ+122%ï¼‰ã€ä»»åŠ¡åˆ†é…ï¼ˆ+284%ï¼‰ç­‰æ–¹é¢æœ‰æ˜¾è‘—æå‡ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šè®¤çŸ¥å¢å¼ºä¸è´¨é‡ä¿éšœæœºåˆ¶  
é‡‡ç”¨æƒ…å¢ƒæ±¤æ™®æ£®é‡‡æ ·è¿›è¡Œæç¤ºä¼˜åŒ–ï¼Œå¹¶è¾…ä»¥å…¨é¢çš„è´¨é‡ä¿éšœç³»ç»Ÿï¼Œå‡å°‘é”™è¯¯ä¸å¹»è§‰é£é™©ï¼Œç¡®ä¿è¿è¥æ•°æ®å¯é è½¬åŒ–ä¸ºæˆ˜ç•¥å»ºè®®ï¼Œåœ¨ä¸åŒå•†ä¸šåœºæ™¯ä¸‹ç”¨æˆ·æ»¡æ„åº¦è¾¾4.30/5.0ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šAI - äººç±»å¹³è¡Œæ¶æ„  
ä½¿AIå†³ç­–è¿‡ç¨‹ä¸ä¼ä¸šç®¡ç†ç»“æ„å¯¹é½ï¼Œåœ¨è¿æ¥è¿è¥åˆ†æä¸æˆ˜ç•¥è§„åˆ’æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç»100åé¢†åŸŸä¸“å®¶è¯„ä¼°ï¼Œèƒ½ç”Ÿæˆå°†ç»†ç²’åº¦æ´å¯Ÿä¸æˆ˜ç•¥æ„¿æ™¯æ— ç¼æ•´åˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ¨¡æ‹Ÿäººç±»é«˜ç®¡å†³ç­–ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å¤šæ ·å•†ä¸šåœºæ™¯ä¸‹çš„å¹¿æ³›å®è¯è¯„ä¼°éªŒè¯äº†BusiAgentçš„æœ‰æ•ˆæ€§ï¼Œå…¶èƒ½ç”Ÿæˆè¿è´¯ã€ä»¥å®¢æˆ·ä¸ºä¸­å¿ƒçš„è§£å†³æ–¹æ¡ˆï¼Œå°†ç»†ç²’åº¦æ´å¯Ÿä¸é«˜å±‚æˆ˜ç•¥é¡ºç•…æ•´åˆï¼Œåœ¨è§£å†³æ–¹æ¡ˆè´¨é‡å’Œç”¨æˆ·æ»¡æ„åº¦ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»æŠ€æœ¯èåˆè§’åº¦ï¼Œå±•ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹ä¸é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ã€ä¿¡æ¯è®ºã€åšå¼ˆè®ºç­‰æŠ€æœ¯ç»“åˆæ¨åŠ¨å•†ä¸šå†³ç­–æ™ºèƒ½åŒ–çš„æ€è·¯ï¼›åœ¨ç³»ç»Ÿè®¾è®¡ä¸Šï¼Œæä¾›äº†å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿç»„ç»‡åŠ¨æ€ã€å®ç°æ°´å¹³åä½œä¸å‚ç›´åè°ƒçš„èŒƒä¾‹ï¼›åœ¨å®ç”¨ä»·å€¼å±‚é¢ï¼Œä¸ºä¼ä¸šåº”å¯¹å¤æ‚å•†ä¸šç¯å¢ƒã€æå‡å†³ç­–æ•ˆç‡ä¸è´¨é‡æä¾›äº†å¯å‚è€ƒçš„AIé©±åŠ¨æ¡†æ¶ï¼Œå¯¹åç»­ä¼ä¸šæ•°å­—åŒ–è½¬å‹ä¸­AIæŠ€æœ¯åº”ç”¨ã€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å•†ä¸šé¢†åŸŸæ‹“å±•ç­‰æ–¹å‘æœ‰å¯å‘æ„ä¹‰ã€‚

## recall-extend-dynamics--enhancing-small-language-models-through-controlled-exploration-and-refined-offline-integration
### Abstract
Many existing studies have achieved significant improvements in the reasoning
capabilities of large language models (LLMs) through reinforcement learning
with verifiable rewards (RLVR), while the enhancement of reasoning abilities in
small language models (SLMs) has not yet been sufficiently explored. Combining
distilled data from larger models with RLVR on small models themselves is a
natural approach, but it still faces various challenges and issues. Therefore,
we propose \textit{\underline{R}}ecall-\textit{\underline{E}}xtend
\textit{\underline{D}}ynamics(RED): Enhancing Small Language Models through
Controlled Exploration and Refined Offline Integration. In this paper, we
explore the perspective of varying exploration spaces, balancing offline
distillation with online reinforcement learning. Simultaneously, we
specifically design and optimize for the insertion problem within offline data.
By monitoring the ratio of entropy changes in the model concerning offline and
online data, we regulate the weight of offline-SFT, thereby addressing the
issues of insufficient exploration space in small models and the redundancy and
complexity during the distillation process. Furthermore, to tackle the
distribution discrepancies between offline data and the current policy, we
design a sample-accuracy-based policy shift mechanism that dynamically chooses
between imitating offline distilled data and learning from its own policy.
### ğŸŒŸ è®ºæ–‡è§£è¯» | å°è¯­è¨€æ¨¡å‹å¢å¼ºæ–°èŒƒå¼ï¼šRecall - Extend Dynamics å¦‚ä½•ç ´å±€ï¼Ÿ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢†åŸŸï¼ŒåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰å·²è¢«è¯å®èƒ½æ˜¾è‘—æå‡æ¨¡å‹æ¨ç†èƒ½åŠ›ï¼Œä½†å°è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰æ¨ç†èƒ½åŠ›çš„å¢å¼ºå´æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚å°†å¤§æ¨¡å‹è’¸é¦æ•°æ®ä¸å°æ¨¡å‹è‡ªèº«çš„ RLVR ç»“åˆæ˜¯è‡ªç„¶æ€è·¯ï¼Œå´é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚ä»…é€šè¿‡æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è’¸é¦è®­ç»ƒçš„å°æ¨¡å‹å­˜åœ¨è¿‡åº¦æ€è€ƒã€ç”Ÿæˆå†—ä½™ç­‰é—®é¢˜ï¼›â€œé¢„ SFT + å RLâ€ çš„è®­ç»ƒæµç¨‹ä¹Ÿå­˜åœ¨æ•ˆç‡æŒ‘æˆ˜ï¼Œå¦‚ RL è®­ç»ƒæ—¶æ¨¡å‹ç”Ÿæˆé•¿åº¦å˜åŒ–å¯¼è‡´è®­ç»ƒå‘¨æœŸå»¶é•¿ç­‰ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨æå‡ºæ›´é«˜æ•ˆç­–ç•¥ç»“åˆç¦»çº¿ SFT ä¸åœ¨çº¿ RLï¼Œæå‡å°æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå—æ§æ¢ç´¢ - åŸºäºåŠ¨æ€ç†µè°ƒèŠ‚å¹³è¡¡ Recall ä¸ Extend
ç°æœ‰ç ”ç©¶è¡¨æ˜ RLVR å¤šæ˜¯ â€œæ”¾å¤§å™¨â€ï¼Œèƒ½æ¿€æ´»æ¨¡å‹é¢„è®­ç»ƒé˜¶æ®µå·²æœ‰çŸ¥è¯†ï¼Œæ­¤è¿‡ç¨‹ä¸º Recall é˜¶æ®µï¼Œæ ¸å¿ƒæ˜¯åœ¨ç°æœ‰èƒ½åŠ›å†…ä¼˜åŒ–æ¨ç†è·¯å¾„å¹¶æ”¶ç¼©æ¢ç´¢ç©ºé—´ï¼›è€Œ SFT å¯æ‰©å±•æ¨ç†è¾¹ç•Œï¼Œå¼•å…¥æ–°æ¨ç†æ¨¡å¼ï¼Œæ‰©å¤§æ¨¡å‹å¯æ¢ç´¢ç©ºé—´ï¼Œå³ Extend é˜¶æ®µã€‚æœ¬æ–‡æå‡ºç”¨ç†µå˜æ¯”è¿™ä¸€æ¢ç´¢ç©ºé—´ç›´è§‚åº¦é‡æŒ‡æ ‡ï¼Œå¹³è¡¡ Recall å’Œ Extend é˜¶æ®µï¼Œè§£å†³å°æ¨¡å‹ RL æ¢ç´¢ç©ºé—´ä¸è¶³ä»¥åŠè’¸é¦è¿‡ç¨‹å›ºæœ‰å†—ä½™å¤æ‚é—®é¢˜ï¼Œå®ç°äºŒè€…æœ‰æ•ˆäº’è¡¥ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç¦»çº¿æ•°æ®çš„è‡ªé€‚åº”æ•´åˆ - åŸºäºå‡†ç¡®ç‡æ„ŸçŸ¥çš„ç­–ç•¥è½¬ç§»
å°†è’¸é¦ç¦»çº¿æ•°æ®æ•´åˆåˆ°ç­–ç•¥ä¼˜åŒ–å‡½æ•°èƒ½å®ç°ç»Ÿä¸€è®­ç»ƒèŒƒå¼ï¼Œä½†å›ºå®šå‰ªè¾‘å€¼éš¾å¤„ç†ä¸å½“å‰ç­–ç•¥åå·®å¤§çš„è’¸é¦æ•°æ®ï¼Œä¸”å¤„ç†è’¸é¦æ ·æœ¬æ–¹å¼ä¸å½“æ˜“å¼•å‘ç†µå´©æºƒæˆ–æ€§èƒ½å´©æºƒã€‚æœ¬æ–‡æå‡ºåŸºäºç­”æ¡ˆæ­£ç¡®ç‡åŠ¨æ€è°ƒæ•´ç­–ç•¥åç§»çš„æ–¹æ³•ï¼šå¯¹æ­£ç¡®ç‡é«˜çš„æ ·æœ¬ï¼Œå€¾å‘è®¾ Ï€offline = 1ï¼Œè®©æ¨¡å‹ä»è‡ªèº«ç­–ç•¥å­¦ä¹ ï¼›å¯¹æ­£ç¡®ç‡ä½çš„æ ·æœ¬ï¼Œç­–ç•¥åç§»æ›´é è¿‘ Ï€ï¼Œé¼“åŠ±æ¨¡å‹æ¨¡ä»¿è’¸é¦æ ·æœ¬ã€‚è¯¥æ–¹æ³•æå‡æ¨¡å‹å¯¹ä¸åŒè´¨é‡æ•°æ®çš„é€‚åº”æ€§å’Œé²æ£’æ€§ï¼Œä¼˜åŒ–è®­ç»ƒæ•ˆç‡ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
æ–‡ä¸­è™½æœªè¯¦ç»†å±•å¼€å®éªŒç»“æœå‘ˆç°ï¼Œä½†ä»ç ”ç©¶é€»è¾‘æ¥çœ‹ï¼Œé€šè¿‡åŠ¨æ€å¹³è¡¡ Recall å’Œ Extend é˜¶æ®µã€åŸºäºå‡†ç¡®ç‡æ„ŸçŸ¥çš„ç­–ç•¥è½¬ç§»æœºåˆ¶ï¼Œç†è®ºä¸Šèƒ½è§£å†³å°æ¨¡å‹æ¢ç´¢ç©ºé—´ä¸è¶³ã€è’¸é¦å†—ä½™å¤æ‚ä»¥åŠç¦»çº¿æ•°æ®ä¸å½“å‰ç­–ç•¥åˆ†å¸ƒå·®å¼‚ç­‰é—®é¢˜ï¼Œæœ‰æœ›æå‡å°æ¨¡å‹æ¨ç†èƒ½åŠ›ä¸è®­ç»ƒæ•ˆç‡ï¼Œæ”¹å–„ä»… SFT è’¸é¦æˆ– â€œé¢„ SFT + å RLâ€ æµç¨‹å­˜åœ¨çš„è¿‡åº¦æ€è€ƒã€ç”Ÿæˆå†—ä½™ã€è®­ç»ƒå‘¨æœŸé•¿ç­‰çŠ¶å†µã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. é˜¶æ®µååŒè§†è§’ï¼šå°† RL å’Œ SFT æ•´åˆè§†ä¸º Recall å’Œ Extend çš„ååŒè¿‡ç¨‹ï¼Œä¸ºå°æ¨¡å‹åˆ©ç”¨ç¦»çº¿è’¸é¦æ•°æ®å®ç°æ€§èƒ½ç¨³æ­¥æå‡æä¾›äº†æ–°çš„æ€è€ƒæ¡†æ¶ï¼Œå¯å‘åç»­ç ”ç©¶ä»ä¸åŒé˜¶æ®µåŠŸèƒ½äº’è¡¥è§’åº¦è®¾è®¡æ–¹æ³•ã€‚
2. åŠ¨æ€è°ƒèŠ‚æœºåˆ¶ï¼šåŸºäºç†µå˜æ¯”çš„åŠ¨æ€æ¢ç´¢ç©ºé—´å¹³è¡¡ä»¥åŠåŸºäºå‡†ç¡®ç‡çš„ç­–ç•¥è½¬ç§»æœºåˆ¶ï¼Œä¸ºå¤„ç†ç¦»çº¿ä¸åœ¨çº¿æ•°æ®äº¤äº’ã€ä¸åŒè´¨é‡æ•°æ®åˆ©ç”¨ç­‰é—®é¢˜æä¾›äº†åŠ¨æ€è°ƒèŠ‚çš„æ€è·¯ï¼Œå¯å€Ÿé‰´åˆ°å…¶ä»–éœ€è¦å¹³è¡¡ä¸åŒæ•°æ®æˆ–è®­ç»ƒé˜¶æ®µçš„æ¨¡å‹ä¼˜åŒ–ä»»åŠ¡ä¸­ã€‚
3. å°æ¨¡å‹ä¼˜åŒ–æ–¹å‘ï¼šé’ˆå¯¹å°æ¨¡å‹æ¨ç†èƒ½åŠ›æå‡è¿™ä¸€ç›¸å¯¹æœªå……åˆ†æ¢ç´¢çš„é¢†åŸŸï¼Œæœ¬æ–‡æ–¹æ³•ä¸ºåç»­å°æ¨¡å‹ç»“åˆè’¸é¦ä¸å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æä¾›äº†å…·ä½“çš„æŠ€æœ¯è·¯çº¿å‚è€ƒï¼Œæ¨åŠ¨å°æ¨¡å‹ç ”ç©¶å‘å±•ã€‚

## lossless-compression-of-neural-network-components--weights--checkpoints--and-k/v-caches-in-low-precision-formats
### Abstract
As deep learning models grow and deployment becomes more widespread, reducing
the storage and transmission costs of neural network weights has become
increasingly important. While prior work such as ZipNN has shown that lossless
compression methods - particularly those based on Huffman encoding
floating-point exponents can significantly reduce model sizes, these techniques
have primarily been applied to higher-precision formats such as FP32 and BF16.
In this work, we extend the ZipNN approach to lower-precision floating-point
formats, specifically FP8 and FP4, which are gaining popularity for efficient
inference. We design a compression method that separates and compresses the
exponent and mantissa components independently using entropy coding. Our
evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also
investigate the compressibility of key-value (K/V) cache tensors used in large
language models (LLMs), finding that they, too, exhibit compressible patterns,
enabling memory savings during deployment.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ä½ç²¾åº¦æ ¼å¼ä¸‹ç¥ç»ç½‘ç»œç»„ä»¶ï¼ˆæƒé‡ã€æ£€æŸ¥ç‚¹ã€K/Vç¼“å­˜ï¼‰çš„æ— æŸå‹ç¼©

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
éšç€æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸æ–­å¢å¤§ä¸”éƒ¨ç½²æ„ˆå‘å¹¿æ³›ï¼Œé™ä½ç¥ç»ç½‘ç»œæƒé‡çš„å­˜å‚¨ä¸ä¼ è¾“æˆæœ¬å˜å¾—æ„ˆå‘é‡è¦ã€‚æ­¤å‰åƒZipNNè¿™ç±»å·¥ä½œè¡¨æ˜ï¼ŒåŸºäºéœå¤«æ›¼ç¼–ç æµ®ç‚¹æ•°æŒ‡æ•°çš„æ— æŸå‹ç¼©æ–¹æ³•èƒ½æ˜¾è‘—å‡å°æ¨¡å‹å°ºå¯¸ï¼Œä½†è¿™äº›æŠ€æœ¯ä¸»è¦åº”ç”¨äºFP32ã€BF16ç­‰é«˜ç²¾åº¦æ ¼å¼ã€‚è€Œå¦‚ä»Šè¡Œä¸šå‘FP8ã€FP4ç­‰ä½ç²¾åº¦æ ¼å¼è½¬ç§»ä»¥å®ç°é«˜æ•ˆæ¨ç†ï¼Œå´ä¸æ¸…æ¥šåœ¨å¦‚æ­¤ä½çš„ä½å®½ä¸‹èƒ½å¦è·å¾—ç±»ä¼¼å‹ç¼©æ”¶ç›Šï¼›åŒæ—¶å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å…³é”®å€¼ï¼ˆK/Vï¼‰ç¼“å­˜å¼ é‡åœ¨æ¨ç†æ—¶å­˜å‚¨æ¶ˆè€—å¤§ï¼Œæ­¤å‰ä¹Ÿæ— é’ˆå¯¹å…¶æ— æŸå‹ç¼©çš„ç ”ç©¶ï¼Œè¿™äº›æ„æˆäº†æœ¬æ–‡å¼€å±•å·¥ä½œçš„èƒŒæ™¯ä¸åŠ¨æœºã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå°†åŸºäºéœå¤«æ›¼ç¼–ç çš„æ— æŸå‹ç¼©æŠ€æœ¯æ‹“å±•åˆ°FP8å’ŒFP4æ ¼å¼  
åˆ†æä¸åŒæ¨¡å‹å’Œè®­ç»ƒæ£€æŸ¥ç‚¹çš„æŒ‡æ•°ä¸å°¾æ•°åˆ†å¸ƒï¼Œè®¾è®¡å‹ç¼©æ–¹æ¡ˆï¼ŒæŠŠæŒ‡æ•°å’Œå°¾æ•°ç»„ä»¶åˆ†ç¦»åç”¨éœå¤«æ›¼ç¼–ç åˆ†åˆ«ç¼–ç ï¼Œå³ä¾¿åœ¨è¿™äº›è¶…ä½ç²¾åº¦æ ¼å¼ä¸‹ï¼Œåˆ©ç”¨æŒ‡æ•°åˆ†å¸ƒçš„åæ€å®ç°æœ‰æ•ˆå‹ç¼©ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæ¢ç©¶å¤§è¯­è¨€æ¨¡å‹K/Vç¼“å­˜å¼ é‡çš„å¯å‹ç¼©æ€§  
åˆ†æFP8æ ¼å¼K/Vå¼ é‡ç»“æ„ï¼Œå‘ç°å…¶æŒ‡æ•°åˆ†å¸ƒä¹Ÿå¸¸å­˜åœ¨åæ€ï¼Œå°†åŸºäºéœå¤«æ›¼çš„ç¼–ç ç­–ç•¥åº”ç”¨äºè¿™äº›ç¼“å­˜ï¼Œé€šè¿‡æŒ‡æ•° - å°¾æ•°åˆ†ç¦»å®ç°è¿è¡Œæ—¶å†…å­˜èŠ‚çœä¸”ä¸ä¿®æ”¹æ¨ç†é€»è¾‘ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šé’ˆå¯¹BF16å¢é‡æ£€æŸ¥ç‚¹ç­‰åœºæ™¯è®¾è®¡å‹ç¼©ç­–ç•¥  
åœ¨ZipNNæ¡†æ¶åˆ†ç¦»æŒ‡æ•°å’Œå°¾æ•°ç»„ä»¶æ€è·¯åŸºç¡€ä¸Šï¼Œæ‹“å±•åˆ°BF16å¢é‡æ£€æŸ¥ç‚¹ç­‰æ–°åœºæ™¯ï¼Œä¾æ®æ•°æ®çš„ç»“æ„å’Œç»Ÿè®¡ç‰¹æ€§çµæ´»åº”ç”¨åŸºäºç†µçš„ç¼–ç æŠ€æœ¯ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
å¯¹BF16æ ¼å¼èƒ½å®ç°é«˜è¾¾62%çš„å‹ç¼©æ¯”ï¼ŒFP8æ ¼å¼ä¸‹å‹ç¼©æ¯”å¯è¾¾83%ï¼›åœ¨æ£€æŸ¥ç‚¹å‹ç¼©ç”¨ä¾‹ä¸­æŒ‡æ•°å‹ç¼©æ¯”ä½è‡³0.07ï¼Œéƒ¨åˆ†æƒ…å†µä¸‹æ¨¡å‹æ€»å‹ç¼©åå°ºå¯¸èƒ½é™è‡³åŸå§‹å¤§å°çš„37%ï¼›è¿˜åœ¨å¤šä¸ªè®­ç»ƒæ£€æŸ¥ç‚¹ä¸Šè¯„ä¼°æ–¹æ³•ï¼Œå±•ç¤ºå‡ºæŒç»­çš„å‹ç¼©æ”¶ç›Šï¼ŒåŒæ—¶åˆ†æäº†è®­ç»ƒé˜¶æ®µå’Œå¼ é‡ç»„ä»¶å¯¹å‹ç¼©æ•ˆæœçš„å½±å“å·®å¼‚ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
åœ¨æŠ€æœ¯å±‚é¢ï¼Œè¯æ˜äº†ä½ç²¾åº¦æ ¼å¼ä¸‹æµ®ç‚¹æ•°æŒ‡æ•°ä»æœ‰åæ€å¯è¢«ç†µç¼–ç åˆ©ç”¨ï¼Œä¸ºä½ç²¾åº¦æ¨ç†åœºæ™¯ä¸‹æ¨¡å‹å­˜å‚¨ä¸ä¼ è¾“çš„æ— æŸå‹ç¼©æä¾›äº†å¯è¡Œæ–¹æ¡ˆï¼Œåç»­é’ˆå¯¹ä½ç²¾åº¦æ ¼å¼çš„æ¨¡å‹å‹ç¼©å·¥ä½œå¯å€Ÿé‰´è¿™ç§åˆ†ç¦»æŒ‡æ•°å’Œå°¾æ•°å¹¶ç»“åˆç†µç¼–ç çš„æ€è·¯ï¼›åœ¨ç ”ç©¶å¯¹è±¡æ‹“å±•ä¸Šï¼Œå¼€å¯äº†å¤§è¯­è¨€æ¨¡å‹K/Vç¼“å­˜æ— æŸå‹ç¼©çš„æ¢ç´¢ï¼Œä¸ºç¼“è§£LLMsæ¨ç†æ—¶K/Vç¼“å­˜å†…å­˜ç“¶é¢ˆæä¾›äº†æ–°æ–¹å‘ï¼Œç›¸å…³ç ”ç©¶å¯è·Ÿè¿›å¯¹K/Vç¼“å­˜å‹ç¼©çš„ä¼˜åŒ–ä¸æ‹“å±•ï¼›åœ¨å®éªŒç»´åº¦ï¼Œå¯¹å¤šä¸ªè®­ç»ƒæ£€æŸ¥ç‚¹çš„è¯„ä¼°ä»¥åŠå¯¹è®­ç»ƒé˜¶æ®µå’Œå¼ é‡ç»„ä»¶å‹ç¼©æ•ˆæœå·®å¼‚çš„åˆ†æï¼Œä¸ºåç»­æ·±å…¥ç†è§£æ¨¡å‹ä¸åŒé˜¶æ®µã€ä¸åŒç»„ä»¶çš„å‹ç¼©ç‰¹æ€§æä¾›äº†å‚è€ƒèŒƒå¼ï¼Œä¾¿äºæ›´ç²¾ç»†åŒ–åœ°å¼€å±•æ¨¡å‹å‹ç¼©ç ”ç©¶ã€‚

## entropy-constrained-strategy-optimization-in-urban-floods--a-multi-agent-framework-with-llm-and-knowledge-graph-integration
### Abstract
In recent years, the increasing frequency of extreme urban rainfall events
has posed significant challenges to emergency scheduling systems. Urban
flooding often leads to severe traffic congestion and service disruptions,
threatening public safety and mobility. However, effective decision making
remains hindered by three key challenges: (1) managing trade-offs among
competing goals (e.g., traffic flow, task completion, and risk mitigation)
requires dynamic, context-aware strategies; (2) rapidly evolving environmental
conditions render static rules inadequate; and (3) LLM-generated strategies
frequently suffer from semantic instability and execution inconsistency.
Existing methods fail to align perception, global optimization, and multi-agent
coordination within a unified framework. To tackle these challenges, we
introduce H-J, a hierarchical multi-agent framework that integrates
knowledge-guided prompting, entropy-constrained generation, and feedback-driven
optimization. The framework establishes a closed-loop pipeline spanning from
multi-source perception to strategic execution and continuous refinement. We
evaluate H-J on real-world urban topology and rainfall data under three
representative conditions: extreme rainfall, intermittent bursts, and daily
light rain. Experiments show that H-J outperforms rule-based and
reinforcement-learning baselines in traffic smoothness, task success rate, and
system robustness. These findings highlight the promise of uncertainty-aware,
knowledge-constrained LLM-based approaches for enhancing resilience in urban
flood response.
### ğŸŒŸ è®ºæ–‡è§£è¯» | åŸå¸‚å†…æ¶åœºæ™¯ä¸‹çš„ç†µçº¦æŸç­–ç•¥ä¼˜åŒ–ï¼šèåˆå¤§æ¨¡å‹ä¸çŸ¥è¯†å›¾è°±çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
è¿‘å¹´æ¥ï¼Œæç«¯åŸå¸‚é™é›¨äº‹ä»¶æ„ˆå‘é¢‘ç¹ï¼Œç»™åº”æ€¥è°ƒåº¦ç³»ç»Ÿå¸¦æ¥é‡å¤§æŒ‘æˆ˜ã€‚åŸå¸‚å†…æ¶å¸¸å¼•å‘ä¸¥é‡äº¤é€šæ‹¥å µä¸æœåŠ¡ä¸­æ–­ï¼Œå¨èƒå…¬å…±å®‰å…¨ä¸å‡ºè¡Œï¼Œä½†æœ‰æ•ˆå†³ç­–ä»å—ä¸‰å¤§å…³é”®æŒ‘æˆ˜é˜»ç¢ï¼šä¸€æ˜¯å¹³è¡¡äº¤é€šæµã€ä»»åŠ¡å®Œæˆã€é£é™©ç¼“è§£ç­‰ç«äº‰ç›®æ ‡éœ€åŠ¨æ€ä¸”æ„ŸçŸ¥ä¸Šä¸‹æ–‡çš„ç­–ç•¥ï¼›äºŒæ˜¯å¿«é€Ÿå˜åŒ–çš„ç¯å¢ƒè®©é™æ€è§„åˆ™å¤±æ•ˆï¼›ä¸‰æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆçš„ç­–ç•¥å­˜åœ¨è¯­ä¹‰ä¸ç¨³å®šä¸æ‰§è¡Œä¸ä¸€è‡´é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨ç»Ÿä¸€æ¡†æ¶ä¸­æ•´åˆæ„ŸçŸ¥ã€å…¨å±€ä¼˜åŒ–ä¸å¤šæ™ºèƒ½ä½“åä½œï¼Œå› æ­¤æœ¬æ–‡æå‡ºH - Jæ¡†æ¶æ¥åº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šåŒé€šé“çŸ¥è¯†æ£€ç´¢æœºåˆ¶
èåˆç»“æ„åŒ–å›¾è°±ï¼ˆå¦‚é“è·¯è¯­ä¹‰ã€é£é™©è½®å»“ç­‰ï¼‰ä¸éç»“æ„åŒ–æ—¥å¿—ï¼ˆå¦‚è°ƒåº¦å†å²ç­‰ï¼‰åˆ°ä¸Šä¸‹æ–‡æ„ŸçŸ¥æç¤ºä¸­ï¼Œä¸ºLLMç”Ÿæˆç­–ç•¥æä¾›ç›¸å…³ä¸”å—çº¦æŸçš„å¼•å¯¼ï¼Œå®ç°è¯­ä¹‰é”šå®šï¼Œè§£å†³LLMè¾“å‡ºæ— ç»“æ„åŒ–å¯¼è‡´çš„è¯­ä¹‰æ¼‚ç§»ç­‰é—®é¢˜ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç†µçº¦æŸçš„åˆ†å±‚ç”Ÿæˆ
æ˜¾å¼è°ƒæ§ç­–ç•¥å„å±‚çš„ä¿¡æ¯ç†µï¼Œé«˜å±‚è§„åˆ’è¿›è¡Œç†µå‹ç¼©ä¸åˆ†ç±»è¿‡æ»¤ä»¥æŠ‘åˆ¶è¯­ä¹‰æ¼‚ç§»ï¼Œä½å±‚æ‰§è¡Œä¿ç•™å¤šæ ·æ€§ï¼Œç¡®ä¿å¤šæ™ºèƒ½ä½“ç­–ç•¥æ—¢ç¨³å¥åˆçµæ´»ï¼Œæå‡LLMç”Ÿæˆç­–ç•¥çš„ç¨³å®šæ€§ä¸æ‰§è¡Œä¸€è‡´æ€§ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šç›®æ ‡é©±åŠ¨çš„åé¦ˆä¼˜åŒ–
æ„å»ºæ•´åˆå†…æ¶ä¸¥é‡ç¨‹åº¦ã€äº¤é€šæ‹¥å µã€ä»»åŠ¡å–æ¶ˆã€åˆ°è¾¾ç‡ç­‰å› ç´ çš„åŠ æƒå…¨å±€ç›®æ ‡Jï¼ŒæŒç»­è¯„ä¼°ç­–ç•¥æœ‰æ•ˆæ€§å¹¶è§¦å‘æç¤ºè‡ªé€‚åº”ï¼Œå½¢æˆé—­åˆä¼˜åŒ–å¾ªç¯ï¼Œè®©ç³»ç»Ÿåœ¨åŠ¨æ€ä¸ç¡®å®šç¯å¢ƒä¸­èƒ½åŠ¨æ€é€‚é…ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹4ï¼šé—­åˆç¯è·¯æ¶æ„è®¾è®¡
H - Jæ¡†æ¶å½¢æˆâ€œæ£€ç´¢â†’ç”Ÿæˆâ†’è½¬æ¢â†’æ‰§è¡Œâ†’è¯„ä¼°â†’é‡æ–°è°ƒåº¦â€çš„é—­åˆç¯è·¯ï¼Œæ•´åˆå¤šæºæ„ŸçŸ¥ã€çŸ¥è¯†å¼•å¯¼çš„ç­–ç•¥ç”Ÿæˆã€åŸºäºç†µçš„é˜ˆå€¼è°ƒæ•´ä¸åŸºäºä»¿çœŸçš„åé¦ˆç­‰ï¼Œä»æ„ŸçŸ¥åˆ°ç­–ç•¥æ‰§è¡Œä¸æŒç»­ä¼˜åŒ–å½¢æˆå®Œæ•´æµç¨‹ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åŸºäºçœŸå®åŸå¸‚æ‹“æ‰‘ä¸é™é›¨æ•°æ®ï¼Œåœ¨æç«¯é™é›¨ã€é—´æ­‡æ€§æš´é›¨ã€æ—¥å¸¸å°é›¨ä¸‰ç§å…¸å‹åœºæ™¯ä¸‹è¯„ä¼°H - Jæ¡†æ¶ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨äº¤é€šæµç•…åº¦ã€ä»»åŠ¡æˆåŠŸç‡ä¸ç³»ç»Ÿé²æ£’æ€§æ–¹é¢ï¼ŒH - Jæ˜¾è‘—ä¼˜äºåŸºäºè§„åˆ™å’Œå¼ºåŒ–å­¦ä¹ çš„åŸºçº¿æ–¹æ³•ï¼Œå‡¸æ˜¾äº†è¿™ç§æ„ŸçŸ¥ä¸ç¡®å®šæ€§ã€å—çŸ¥è¯†çº¦æŸçš„å¤§æ¨¡å‹æ–¹æ³•åœ¨å¢å¼ºåŸå¸‚å†…æ¶å“åº”éŸ§æ€§ä¸Šçš„æ½œåŠ›ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. å¤šæ¨¡æ€çŸ¥è¯†èåˆæ€è·¯ï¼šåœ¨éœ€ç»“åˆå¤šæºä¿¡æ¯çš„ä»»åŠ¡ä¸­ï¼Œå¯å‚è€ƒå…¶åŒé€šé“çŸ¥è¯†æ£€ç´¢ï¼Œèåˆç»“æ„åŒ–ä¸éç»“æ„åŒ–æ•°æ®æ¥è¾…åŠ©å†³ç­–æˆ–ç”Ÿæˆï¼Œä¸ºæ¨¡å‹æä¾›æ›´å…¨é¢ä¸Šä¸‹æ–‡ã€‚
2. ç†µçº¦æŸè°ƒæ§è¾“å‡ºï¼šå¯¹äºç”Ÿæˆç±»ä»»åŠ¡ï¼ˆå¦‚ç­–ç•¥ç”Ÿæˆã€æ–‡æœ¬ç”Ÿæˆç­‰ï¼‰ï¼Œå¯å€Ÿé‰´ç†µçº¦æŸåˆ†å±‚ç”Ÿæˆæ–¹å¼ï¼Œå¹³è¡¡è¾“å‡ºç¨³å®šæ€§ä¸å¤šæ ·æ€§ï¼Œé¿å…è¯­ä¹‰æ¼‚ç§»ç­‰é—®é¢˜ã€‚
3. é—­åˆç¯è·¯åé¦ˆæœºåˆ¶ï¼šåœ¨åŠ¨æ€ç¯å¢ƒä¸‹çš„ä»»åŠ¡è°ƒåº¦ã€æ™ºèƒ½å†³ç­–ç­‰åœºæ™¯ï¼Œæ„å»ºåŒ…å«è¯„ä¼°ä¸è‡ªé€‚åº”çš„é—­åˆç¯è·¯ï¼Œè®©ç³»ç»Ÿèƒ½æŒç»­ä¼˜åŒ–ï¼Œæå‡åº”å¯¹åŠ¨æ€å˜åŒ–çš„èƒ½åŠ›ã€‚
4. è·¨æ¨¡å—æ•´åˆæ¶æ„ï¼šå°†ä¸åŒåŠŸèƒ½æ¨¡å—ï¼ˆå¦‚çŸ¥è¯†å¤„ç†ã€ç”Ÿæˆã€æ‰§è¡Œã€åé¦ˆç­‰ï¼‰æ•´åˆä¸ºç»Ÿä¸€æ¡†æ¶ï¼Œä¸ºå¤æ‚åœºæ™¯ä¸‹çš„å¤šæ™ºèƒ½ä½“åä½œæˆ–ç³»ç»Ÿçº§ä»»åŠ¡å¤„ç†æä¾›æ¶æ„è®¾è®¡å‚è€ƒã€‚

## semantic-energy--detecting-llm-hallucination-beyond-entropy
### Abstract
Large Language Models (LLMs) are being increasingly deployed in real-world
applications, but they remain susceptible to hallucinations, which produce
fluent yet incorrect responses and lead to erroneous decision-making.
Uncertainty estimation is a feasible approach to detect such hallucinations.
For example, semantic entropy estimates uncertainty by considering the semantic
diversity across multiple sampled responses, thus identifying hallucinations.
However, semantic entropy relies on post-softmax probabilities and fails to
capture the model's inherent uncertainty, causing it to be ineffective in
certain scenarios. To address this issue, we introduce Semantic Energy, a novel
uncertainty estimation framework that leverages the inherent confidence of LLMs
by operating directly on logits of penultimate layer. By combining semantic
clustering with a Boltzmann-inspired energy distribution, our method better
captures uncertainty in cases where semantic entropy fails. Experiments across
multiple benchmarks show that Semantic Energy significantly improves
hallucination detection and uncertainty estimation, offering more reliable
signals for downstream applications such as hallucination detection.
### ğŸŒŸ è®ºæ–‡è§£è¯» | è¶…è¶Šç†µï¼šç”¨Semantic Energyæ£€æµ‹å¤§æ¨¡å‹å¹»è§‰

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®é™…åº”ç”¨ä¸­å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œè¾“å‡ºæµç•…ä½†é”™è¯¯çš„å“åº”ï¼Œè¿›è€Œå¯¼è‡´é”™è¯¯å†³ç­–ã€‚ä¸ç¡®å®šæ€§ä¼°è®¡æ˜¯æ£€æµ‹å¹»è§‰çš„å¯è¡Œæ–¹æ³•ï¼Œè¯­ä¹‰ç†µé€šè¿‡å¤šé‡‡æ ·å“åº”çš„è¯­ä¹‰å¤šæ ·æ€§ä¼°è®¡ä¸ç¡®å®šæ€§æ¥è¯†åˆ«å¹»è§‰ï¼Œä½†å®ƒä¾èµ–softmaxåçš„æ¦‚ç‡ï¼Œæ— æ³•æ•æ‰æ¨¡å‹å›ºæœ‰ä¸ç¡®å®šæ€§ï¼Œåœ¨æŸäº›åœºæ™¯å¤±æ•ˆã€‚æ¯”å¦‚å½“æ¨¡å‹å¯¹åŒä¸€é—®é¢˜å¤šæ¬¡é‡‡æ ·è¾“å‡ºè¯­ä¹‰ç›¸åŒä½†å®é™…é”™è¯¯çš„å“åº”æ—¶ï¼Œè¯­ä¹‰ç†µä¼šåˆ¤å®šä¸ºå¯é ï¼ˆç†µä¸º0ï¼‰ï¼Œå¯è¿™ç±»åœºæ™¯ä¸‹é”™è¯¯å“åº”å æ¯”å¯èƒ½ä¸ä½ï¼Œå› æ­¤éœ€è¦æ›´ä¼˜æ–¹æ³•æ•æ‰æ¨¡å‹å›ºæœ‰ä¸ç¡®å®šæ€§æ¥æ£€æµ‹å¹»è§‰ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºSemantic Energyæ¡†æ¶  
é’ˆå¯¹è¯­ä¹‰ç†µçš„ä¸è¶³ï¼Œæå‡ºSemantic Energyè¿™ä¸€æ–°é¢–çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ¡†æ¶ã€‚å®ƒç›´æ¥ä½œç”¨äºå¤§æ¨¡å‹å€’æ•°ç¬¬äºŒå±‚çš„logitsï¼Œåˆ©ç”¨æ¨¡å‹çš„å›ºæœ‰ç½®ä¿¡åº¦æ¥ä¼°è®¡ä¸ç¡®å®šæ€§ï¼Œè€Œéä¾èµ–è¯­ä¹‰ç†µæ‰€ç”¨çš„softmaxåæ¦‚ç‡ï¼Œèƒ½åœ¨è¯­ä¹‰ç†µå¤±æ•ˆåœºæ™¯æ›´å¥½æ•æ‰ä¸ç¡®å®šæ€§ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç»“åˆè¯­ä¹‰èšç±»ä¸ç»å°”å…¹æ›¼èƒ½é‡åˆ†å¸ƒ  
åœ¨è®¡ç®—ä¸ç¡®å®šæ€§æ—¶ï¼Œå…ˆå¯¹ç»™å®šæç¤ºè¿›è¡Œå¤šå“åº”é‡‡æ ·ä¸è¯­ä¹‰é‡‡æ ·ï¼Œç„¶åç»“åˆè¯­ä¹‰èšç±»å’Œå—ç»å°”å…¹æ›¼å¯å‘çš„èƒ½é‡åˆ†å¸ƒæ¥ä¼°è®¡å“åº”ä¸ç¡®å®šæ€§ï¼Œè®©ä¼°è®¡ç»“æœåæ˜ æ¨¡å‹å›ºæœ‰ä¸ç¡®å®šæ€§ï¼Œæ”¹è¿›è¯­ä¹‰ç†µåœ¨å¤±æ•ˆåœºæ™¯çš„è¡¨ç°ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSemantic Energyåœ¨å¹»è§‰æ£€æµ‹å’Œä¸ç¡®å®šæ€§ä¼°è®¡ä»»åŠ¡ä¸Šæ˜¾è‘—æå‡æ€§èƒ½ã€‚åœ¨å¹»è§‰æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œé’ˆå¯¹è¯­ä¹‰ç†µè®¤ä¸ºâ€œç½®ä¿¡â€çš„åœºæ™¯ï¼ŒSemantic Energyåœ¨AUROCæŒ‡æ ‡ä¸Šç›¸æ¯”è¯­ä¹‰ç†µå¹³å‡æå‡è¶…13%ï¼Œè¯æ˜å…¶èƒ½ä¸ºå¹»è§‰æ£€æµ‹ç­‰ä¸‹æ¸¸åº”ç”¨æä¾›æ›´å¯é ä¿¡å·ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. å¯¹ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•çš„åæ€è§’åº¦ï¼šè®ºæ–‡æ­éœ²äº†åŸºäºæ¦‚ç‡çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•ï¼ˆå¦‚è¯­ä¹‰ç†µï¼‰çš„å±€é™æ€§ä¸å¤±æ•ˆåœºæ™¯ï¼Œä¸ºåç»­æ”¹è¿›ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•æä¾›äº†æ€è€ƒæ–¹å‘ï¼Œå¯å‘ç ”ç©¶è€…å…³æ³¨æ¨¡å‹å›ºæœ‰è¡¨å¾ï¼ˆå¦‚logitsï¼‰åœ¨ä¸ç¡®å®šæ€§åˆ»ç”»ä¸Šçš„æ½œåŠ›ã€‚  
2. æ¡†æ¶è®¾è®¡æ€è·¯ï¼šSemantic Energyå°†è¯­ä¹‰å±‚é¢åˆ†æä¸æ¨¡å‹æ·±å±‚è¡¨å¾ï¼ˆlogitsï¼‰ã€ç‰©ç†å¯å‘çš„èƒ½é‡åˆ†å¸ƒç»“åˆï¼Œè¿™ç§è·¨é¢†åŸŸæ€è·¯ï¼ˆå¦‚å¼•å…¥ç»å°”å…¹æ›¼èƒ½é‡åˆ†å¸ƒï¼‰ä¸ºå¤„ç†å¤§æ¨¡å‹ä¸ç¡®å®šæ€§é—®é¢˜æä¾›äº†åˆ›æ–°èŒƒå¼ï¼Œå¯å€Ÿé‰´åˆ°å…¶ä»–éœ€æ•æ‰æ¨¡å‹å†…åœ¨ç½®ä¿¡åº¦çš„ä»»åŠ¡ä¸­ã€‚  
3. å®é™…åº”ç”¨ä»·å€¼ï¼šåœ¨å¤§æ¨¡å‹å¹»è§‰æ£€æµ‹éœ€æ±‚æ—¥ç›Šå¢é•¿çš„å½“ä¸‹ï¼Œæä¾›äº†æ›´å¯é çš„æŠ€æœ¯æ–¹æ¡ˆï¼Œèƒ½è¾…åŠ©ä¸‹æ¸¸å¦‚è‡ªåŠ¨åæ€ã€ç­”æ¡ˆå†ç”Ÿã€äººå·¥ä»‹å…¥ç­‰æœºåˆ¶æ›´ç²¾å‡†å·¥ä½œï¼Œä¸ºå¤§æ¨¡å‹è½åœ°å¯é åº”ç”¨ç­‘ç‰¢åŸºç¡€ã€‚

## measuring-llm-code-generation-stability-via-structural-entropy
### Abstract
Assessing the stability of code generation from large language models (LLMs)
is essential for judging their reliability in real-world development. We extend
prior "structural-entropy concepts" to the program domain by pairing entropy
with abstract syntax tree (AST) analysis. For any fixed prompt, we collect the
multiset of depth-bounded subtrees of AST in each generated program and treat
their relative frequencies as a probability distribution. We then measure
stability in two complementary ways: (i) Jensen-Shannon divergence, a
symmetric, bounded indicator of structural overlap, and (ii) a Structural
Cross-Entropy ratio that highlights missing high-probability patterns. Both
metrics admit structural-only and token-aware variants, enabling separate views
on control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or
CodeBLEU, our metrics are reference-free, language-agnostic, and
execution-independent. We benchmark several leading LLMs on standard code
generation tasks, demonstrating that AST-driven structural entropy reveals
nuances in model consistency and robustness. The method runs in O(n,d) time
with no external tests, providing a lightweight addition to the code-generation
evaluation toolkit.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ç”¨ç»“æ„ç†µè¡¡é‡å¤§è¯­è¨€æ¨¡å‹ä»£ç ç”Ÿæˆç¨³å®šæ€§

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªåŠ¨ä»£ç ç”Ÿæˆé¢†åŸŸå±•ç°å‡ºå¼ºå¤§èƒ½åŠ›ï¼Œä½†ç”Ÿæˆä»£ç å­˜åœ¨é«˜å˜å¼‚æ€§é—®é¢˜ï¼šç›¸åŒæç¤ºåœ¨ä¸åŒè¿è¡Œæˆ–ä¸åŒæ¨¡å‹ä¸‹å¯èƒ½äº§ç”Ÿå·®å¼‚å¾ˆå¤§çš„ä»£ç ç‰‡æ®µã€‚ç°æœ‰è¯„ä¼°æŒ‡æ ‡å¤šèšç„¦äºåŠŸèƒ½æ­£ç¡®æ€§æˆ–ä¸å‚è€ƒè§£å†³æ–¹æ¡ˆçš„æ–‡æœ¬ç›¸ä¼¼æ€§ï¼Œå¦‚pass@kè¡¡é‡åŠŸèƒ½æˆåŠŸä¸å¦ï¼ŒBLEUã€CodeBLEUç­‰è¯„ä¼°ä¸å‚è€ƒçš„n - gramé‡å æˆ–å¥æ³•è¯­ä¹‰åŒ¹é…ï¼Œä½†å®ƒä»¬æ— æ³•æ•æ‰åŒä¸€æç¤ºä¸‹ä¸åŒè¾“å‡ºçš„ç»“æ„/æ‹“æ‰‘ç›¸ä¼¼æ€§ï¼Œä¹Ÿæœªè§£å†³ä»£ç ç”Ÿæˆçš„ç¨³å®šæ€§é—®é¢˜ã€‚è€Œä»£ç ç”Ÿæˆçš„è¾“å‡ºä¸ç¨³å®šæ€§ä¼šæŸå®³å¼€å‘è€…ä¿¡ä»»ã€é˜»ç¢ç ”ç©¶å¯é‡å¤æ€§ï¼Œåœ¨å®‰å…¨å…³é”®æˆ–åä½œè½¯ä»¶åœºæ™¯ä¸­å½±å“å¯é æ€§ï¼Œå› æ­¤äºŸéœ€ä¸¥æ ¼é‡åŒ–ç”Ÿæˆä»£ç çš„ç»“æ„ç¨³å®šæ€§ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå°†ç»“æ„ç†µæ¦‚å¿µæ‰©å±•åˆ°ç¨‹åºé¢†åŸŸï¼Œç»“åˆç†µä¸æŠ½è±¡è¯­æ³•æ ‘ï¼ˆASTï¼‰åˆ†æ
å¯¹å›ºå®šæç¤ºç”Ÿæˆçš„æ¯ä¸ªç¨‹åºï¼Œæ”¶é›†å…¶ASTçš„æ·±åº¦æœ‰ç•Œå­æ ‘çš„å¤šé‡é›†åˆï¼Œå¹¶å°†å­æ ‘ç›¸å¯¹é¢‘ç‡è§†ä¸ºæ¦‚ç‡åˆ†å¸ƒã€‚é€šè¿‡è§£æä»£ç è¾“å‡ºä¸ºASTï¼Œæå–æ·±åº¦æœ‰ç•Œå­æ ‘å¹¶è½¬æ¢ä¸ºè§„èŒƒç¼–ç ï¼ˆåŒ…æ‹¬ä»…ç»“æ„ç¼–ç å’Œç»“æ„ + å€¼ç¼–ç ï¼Œå‰è€…æ•æ‰é€šç”¨ç¼–ç æ¨¡å¼ï¼Œåè€…æ›´å…·è¾¨åˆ«æ€§ï¼‰ï¼Œä»ASTä¸­æå–å­æ ‘æ¥åˆ»ç”»ç»“æ„ä¿¡æ¯ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šä¸¤ç§äº’è¡¥çš„ç¨³å®šæ€§åº¦é‡æ–¹å¼
ä¸€æ˜¯Jensen - Shannon divergenceï¼Œä½œä¸ºç»“æ„é‡å çš„å¯¹ç§°ã€æœ‰ç•ŒæŒ‡æ ‡ï¼Œè¡¡é‡ç»“æ„ç›¸ä¼¼æ€§ï¼›äºŒæ˜¯Structural Cross - Entropy ratioï¼Œçªå‡ºç¼ºå¤±çš„é«˜æ¦‚ç‡æ¨¡å¼ã€‚è¿™ä¸¤ç§åº¦é‡éƒ½æœ‰ä»…ç»“æ„å’Œæ„ŸçŸ¥ä»¤ç‰Œçš„å˜ä½“ï¼Œèƒ½åˆ†åˆ«è§‚å¯Ÿæ§åˆ¶æµå½¢çŠ¶å’Œæ ‡è¯†ç¬¦çº§åˆ«çš„å˜å¼‚æ€§ã€‚ä¸ç°æœ‰æŒ‡æ ‡ä¸åŒï¼Œæ–°æŒ‡æ ‡æ— å‚è€ƒã€ä¸è¯­è¨€æ— å…³ä¸”ç‹¬ç«‹äºæ‰§è¡Œã€‚
ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šé«˜æ•ˆçš„è®¡ç®—ä¸è½»é‡è¯„ä¼°
è¯¥æ–¹æ³•æ—¶é—´å¤æ‚åº¦ä¸ºO(n, d)ï¼Œæ— éœ€å¤–éƒ¨æµ‹è¯•ï¼Œä¸ºä»£ç ç”Ÿæˆè¯„ä¼°å·¥å…·åŒ…æä¾›äº†è½»é‡çº§è¡¥å……ã€‚é€šè¿‡æ„å»ºç»éªŒåˆ†å¸ƒï¼ˆä»å­æ ‘æå–åˆ°æ„å»ºè”åˆæ”¯æŒã€å®šä¹‰ multiplicity å‡½æ•°å’Œç»éªŒæ¦‚ç‡åˆ†å¸ƒï¼‰ï¼Œå°†ASTçš„ç»“æ„â€œè¯æ±‡â€è½¬åŒ–ä¸ºæ¦‚ç‡å‘é‡ï¼Œè¾“å…¥åˆ°ç›¸ä¼¼æ€§åº¦é‡è®¡ç®—ä¸­ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨æ ‡å‡†ä»£ç ç”Ÿæˆä»»åŠ¡ä¸Šå¯¹å¤šä¸ªé¢†å…ˆçš„å¤§è¯­è¨€æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜åŸºäºASTçš„ç»“æ„ç†µèƒ½å¤Ÿæ­ç¤ºæ¨¡å‹åœ¨ä¸€è‡´æ€§å’Œé²æ£’æ€§æ–¹é¢çš„ç»†å¾®å·®åˆ«ï¼Œå±•ç°å‡ºè¯¥æ–¹æ³•åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ä»£ç ç”Ÿæˆç¨³å®šæ€§ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. æŒ‡æ ‡è®¾è®¡æ€è·¯ï¼šæå‡ºæ— å‚è€ƒã€è¯­è¨€æ— å…³ä¸”æ‰§è¡Œç‹¬ç«‹çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¸ºè§£å†³é¢†åŸŸä¸­ç°æœ‰æŒ‡æ ‡å±€é™æä¾›äº†æ–°æ€è·¯ï¼Œå¯å¯å‘åç»­é’ˆå¯¹å…¶ä»–ç”Ÿæˆç±»ä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡åˆ›æ–°ï¼Œå°¤å…¶æ˜¯å…³æ³¨ç»“æ„ç¨³å®šæ€§æ–¹é¢ã€‚
2. ç»“åˆASTä¸ç†µçš„æ–¹æ³•ï¼šå°†ASTåˆ†æä¸ç†µæ¦‚å¿µç»“åˆç”¨äºä»£ç ç”Ÿæˆç¨³å®šæ€§è¯„ä¼°ï¼Œä¸ºè½¯ä»¶å·¥ç¨‹ä¸å¤§è¯­è¨€æ¨¡å‹äº¤å‰é¢†åŸŸæä¾›äº†æ–°çš„åˆ†æè§†è§’ï¼Œå¯å€Ÿé‰´åˆ°å¯¹ç¨‹åºç»“æ„ã€æ¼”åŒ–ç­‰æ–¹é¢ä¸å¤§æ¨¡å‹ç»“åˆçš„ç ”ç©¶ä¸­ã€‚
3. è½»é‡çº§è¯„ä¼°å®ç°ï¼šæ–¹æ³•æ—¶é—´å¤æ‚åº¦ä½ä¸”æ— éœ€å¤–éƒ¨æµ‹è¯•ï¼Œåœ¨å·¥ç¨‹å®è·µä¸­å¯ä½œä¸ºç°æœ‰ä»£ç ç”Ÿæˆè¯„ä¼°å·¥å…·çš„è½»é‡è¡¥å……ï¼Œå¿«é€Ÿè¯„ä¼°æ¨¡å‹ç”Ÿæˆä»£ç çš„ç¨³å®šæ€§ï¼Œè¾…åŠ©å¼€å‘è€…åˆ¤æ–­æ¨¡å‹å¯é æ€§ã€‚

## beyond-pass@1--self-play-with-variational-problem-synthesis-sustains-rlvr
### Abstract
Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a key paradigm for post-training Large Language Models (LLMs), particularly for
complex reasoning tasks. However, vanilla RLVR training has been shown to
improve Pass@1 performance at the expense of policy entropy, leading to reduced
generation diversity and limiting the Pass@k performance, which typically
represents the upper bound of LLM reasoning capability. In this paper, we
systematically analyze the policy's generation diversity from the perspective
of training problems and find that augmenting and updating training problems
helps mitigate entropy collapse during training. Based on these observations,
we propose an online Self-play with Variational problem Synthesis (SvS)
strategy for RLVR training, which uses the policy's correct solutions to
synthesize variational problems while ensuring their reference answers remain
identical to the originals. This self-improving strategy effectively maintains
policy entropy during training and substantially improves Pass@k compared with
standard RLVR, sustaining prolonged improvements and achieving absolute gains
of 18.3% and 22.8% in Pass@32 performance on the competition-level AIME24 and
AIME25 benchmarks. Experiments on 12 reasoning benchmarks across varying model
sizes from 3B to 32B consistently demonstrate the generalizability and
robustness of SvS.
### ğŸŒŸ è®ºæ–‡è§£è¯» | çªç ´Pass@1å±€é™ï¼šå˜åˆ†é—®é¢˜åˆæˆè‡ªåšå¼ˆè®©RLVRæŒç»­è¿›åŒ–

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åè®­ç»ƒç”¨äºå¤æ‚æ¨ç†ä»»åŠ¡çš„å…³é”®èŒƒå¼ã€‚ä½†åŸå§‹RLVRè®­ç»ƒå­˜åœ¨â€œç†µå›°å¢ƒâ€ï¼šæå‡Pass@1ï¼ˆå•æ¬¡å°è¯•æˆåŠŸè§£å†³é—®é¢˜çš„æ¯”ä¾‹ï¼‰çš„åŒæ—¶ï¼Œä¼šå¯¼è‡´ç­–ç•¥ç†µï¼ˆè¡¡é‡ç”Ÿæˆå¤šæ ·æ€§ï¼‰ä¸‹é™ï¼Œç”Ÿæˆå¤šæ ·æ€§é™ä½åˆé™åˆ¶äº†Pass@kï¼ˆå¤šæ¬¡å°è¯•ä¸­è‡³å°‘æˆåŠŸä¸€æ¬¡çš„æ¯”ä¾‹ï¼Œä»£è¡¨æ¨ç†èƒ½åŠ›ä¸Šé™ï¼‰è¡¨ç°ã€‚æ ¹æœ¬åŸå› æ˜¯è®­ç»ƒé—®é¢˜æœ‰é™ï¼Œæ¨¡å‹æ˜“â€œæ­»è®°ç¡¬èƒŒâ€æ­£ç¡®è§£ï¼Œé™·å…¥ç†µåç¼©ï¼Œåç»­æ¢ç´¢èƒ½åŠ›æ¯ç«­ï¼ŒPass@kéš¾æå‡ç”šè‡³Pass@1ä¹Ÿä¼šåœæ»ã€‚è€Œæ”¶é›†é«˜è´¨é‡å¸¦éªŒè¯ç­”æ¡ˆçš„å¤§è§„æ¨¡é—®é¢˜é›†æˆæœ¬é«˜ã€æ ‡æ³¨éš¾ï¼Œå¦‚ä½•é«˜æ•ˆæ‰©å……è®­ç»ƒé—®é¢˜å¹¶ç»´æŒå¤šæ ·æ€§æˆå…³é”®æŒ‘æˆ˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºSvSï¼ˆSelf - play with Variational problem Synthesisï¼‰ç­–ç•¥  
åŸºäºæ¨¡å‹è‡ªèº«æ­£ç¡®è§£åˆæˆå˜åˆ†é—®é¢˜ï¼Œé’ˆå¯¹è®­ç»ƒä¸­è¡¨ç°ä¸ä½³/å…·æŒ‘æˆ˜æ€§çš„æ ·æœ¬ï¼Œè®©æ¨¡å‹ç”Ÿæˆâ€œæ¢è¡¨è¿°ä½†è¯­ä¹‰ã€ç­”æ¡ˆä¸å˜â€çš„æ–°é—®é¢˜ã€‚æ—¢åˆ©ç”¨æ¨¡å‹èƒ½åŠ›æ‰©å……æ•°æ®ï¼Œåˆæ— éœ€é¢å¤–æ ‡æ³¨ç­”æ¡ˆï¼Œå› ä¸ºå˜åˆ†é—®é¢˜ä¸åŸé—®é¢˜å…±äº«é»„é‡‘ç­”æ¡ˆã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç«¯åˆ°ç«¯è‡ªæ”¹è¿›çš„åœ¨çº¿è®­ç»ƒèŒƒå¼  
åˆæˆå˜åˆ†é—®é¢˜åï¼Œè®©æ¨¡å‹å†è§£å†³è¿™äº›è‡ªç”Ÿæˆé—®é¢˜ï¼Œé€šè¿‡ç­”æ¡ˆä¸åŸé—®é¢˜é»„é‡‘ç­”æ¡ˆçš„ä¸€è‡´æ€§éªŒè¯é—®é¢˜æœ‰æ•ˆæ€§ã€‚ä¹‹åå°†åŸé—®é¢˜ã€å˜åˆ†é—®é¢˜åŠå¯¹åº”è§£ç­”ä¸€åŒç”¨äºç­–ç•¥æ›´æ–°ï¼Œä½¿æ¨¡å‹åŒæ—¶å­¦ä¹ â€œè§£é¢˜â€ä¸â€œå‡ºé¢˜â€ï¼Œå…¨ç¨‹æ— å¤–éƒ¨æŒ‡å¯¼æˆ–è’¸é¦ï¼Œçº¯è‡ªæ”¹è¿›ã€‚ä¸”SvSå¯¹RLVRç®—æ³•ï¼ˆå¦‚PPOã€GRPOç­‰ï¼‰æ— ä¾µå…¥æ€§ï¼Œå¯çµæ´»åµŒå…¥ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šé¶å‘é—®é¢˜æ‰©å……é€»è¾‘  
åªé’ˆå¯¹â€œæŒ‘æˆ˜æ€§é—®é¢˜â€åˆæˆå˜åˆ†é—®é¢˜ï¼Œç²¾å‡†ç„å‡†æ¨¡å‹èƒ½åŠ›çŸ­æ¿ï¼Œæå‡æ•°æ®æ‰©å……æ•ˆç‡ï¼Œè®©æ¨¡å‹åœ¨è–„å¼±ç¯èŠ‚æŒç»­æ¢ç´¢å¤šæ ·æ€§è§£æ³•ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
- è·¨è§„æ¨¡éªŒè¯ï¼šåœ¨3Båˆ°32Bä¸åŒå¤§å°LLMã€12ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒSvSä¸€è‡´è¶…è¶Šæ ‡å‡†RLVRï¼Œå…¨å®éªŒå¹³å‡ç»å¯¹æå‡çº¦3%ã€‚  
- Pass@kçªç ´ï¼šåœ¨ç«èµ›çº§AIME24ã€AIME25åŸºå‡†ä¸Šï¼ŒPass@32ï¼ˆ32æ¬¡å°è¯•è‡³å°‘æˆåŠŸä¸€æ¬¡ï¼‰åˆ†åˆ«å®ç°18.3%ã€22.8%çš„ç»å¯¹å¢ç›Šï¼Œè€Œæ ‡å‡†RLVRåœ¨æ­¤ç±»é•¿ç¨‹Pass@kä¸Šæå‡å¾®å¼±ã€‚  
- ç†µç¨³å®šæ€§ï¼šSvSè®­ç»ƒä¸­ç­–ç•¥ç†µç¨³å®šåœ¨åˆç†åŒºé—´ï¼Œæ— æ˜æ˜¾åç¼©æˆ–çˆ†ç‚¸ï¼Œè¯æ˜è®­ç»ƒæ›´å¯æŒç»­ï¼Œè‡ªæ”¹è¿›èƒ½åŠ›æ›´æŒä¹…ï¼ˆå¯¹æ¯”æ ‡å‡†RLVRç†µæŒç»­ä¸‹é™ï¼‰ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
- æ•°æ®è‡ªé©±åŠ¨æ‰©å……æ€è·¯ï¼šåˆ©ç”¨æ¨¡å‹è‡ªèº«è¾“å‡ºï¼ˆæ­£ç¡®è§£ï¼‰ç”ŸæˆåŒæºæ–°æ•°æ®ï¼Œç»•è¿‡å¤–éƒ¨æ•°æ®æ ‡æ³¨éš¾é¢˜ï¼Œä¸ºå¤§æ¨¡å‹æŒç»­å­¦ä¹ æä¾›â€œè‡ªç»™è‡ªè¶³â€çš„æ•°æ®å¼•æ“ã€‚  
- ç†µä¸æ€§èƒ½å¹³è¡¡è§†è§’ï¼šæ­ç¤ºç»´æŒç­–ç•¥ç†µå¯¹Pass@kä¹ƒè‡³é•¿æœŸPass@1çš„é‡è¦æ€§ï¼Œæä¾›äº†é€šè¿‡é—®é¢˜åŠ¨æ€æ›´æ–°ç¼“è§£ç†µåç¼©çš„å¯è¡Œè·¯å¾„ï¼Œå¯å‘åç»­RLä¸å¤§æ¨¡å‹ç»“åˆæ—¶å¯¹â€œæ¢ç´¢ - åˆ©ç”¨â€å¹³è¡¡çš„è®¾è®¡ã€‚  
- æ¨¡å—åŒ–æ–¹æ³•è®¾è®¡ï¼šSvSä½œä¸ºæ’ä»¶å¼ç­–ç•¥ï¼Œå¯é€‚é…å¤šç§RLVRç®—æ³•ï¼Œä¸ºç°æœ‰RLVRè®­ç»ƒæ¡†æ¶å‡çº§æä¾›ä½æˆæœ¬ã€é«˜æ”¶ç›Šçš„æ”¹é€ æ–¹å‘ã€‚

## adapsne--adaptive-fireworks-optimized-and-entropy-guided-dataset-sampling-for-edge-dnn-training
### Abstract
Training deep neural networks (DNNs) directly on edge devices has attracted
increasing attention, as it offers promising solutions to challenges such as
domain adaptation and privacy preservation. However, conventional DNN training
typically requires large-scale datasets, which imposes prohibitive overhead on
edge devices-particularly for emerging large language model (LLM) tasks. To
address this challenge, a DNN-free method (ie., dataset sampling without DNN),
named NMS (Near-Memory Sampling), has been introduced. By first conducting
dimensionality reduction of the dataset and then performing exemplar sampling
in the reduced space, NMS avoids the architectural bias inherent in DNN-based
methods and thus achieves better generalization. However, The state-of-the-art,
NMS, suffers from two limitations: (1) The mismatch between the search method
and the non-monotonic property of the perplexity error function leads to the
emergence of outliers in the reduced representation; (2) Key parameter (ie.,
target perplexity) is selected empirically, introducing arbitrariness and
leading to uneven sampling. These two issues lead to representative bias of
examplars, resulting in degraded accuracy. To address these issues, we propose
AdapSNE, which integrates an efficient non-monotonic search method-namely, the
Fireworks Algorithm (FWA)-to suppress outliers, and employs entropy-guided
optimization to enforce uniform sampling, thereby ensuring representative
training samples and consequently boosting training accuracy. To cut the
edge-side cost arising from the iterative computations of FWA search and
entropy-guided optimization, we design an accelerator with custom dataflow and
time-multiplexing markedly reducing on-device training energy and area.
### ğŸŒŸ è®ºæ–‡è§£è¯» | AdapSNEï¼šä¸ºè¾¹ç¼˜DNNè®­ç»ƒæ‰“é€ è‡ªé€‚åº”çƒŸèŠ±ä¼˜åŒ–ä¸ç†µå¼•å¯¼çš„æ•°æ®é›†é‡‡æ ·æ–¹æ¡ˆ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šç›´æ¥è®­ç»ƒè™½èƒ½åº”å¯¹é¢†åŸŸé€‚é…ã€éšç§ä¿æŠ¤ç­‰æŒ‘æˆ˜ï¼Œä½†ä¼ ç»Ÿè®­ç»ƒä¾èµ–å¤§è§„æ¨¡æ•°æ®é›†ï¼Œç»™èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆå°¤å…¶å¤§è¯­è¨€æ¨¡å‹ä»»åŠ¡åœºæ™¯ï¼‰å¸¦æ¥å·¨å¤§å¼€é”€ã€‚æ­¤å‰æ— DNNçš„æ•°æ®é›†é‡‡æ ·æ–¹æ³•NMSè™½é¿å…äº†åŸºäºDNNæ–¹æ³•çš„æ¶æ„åå·®ï¼Œå´å­˜åœ¨ä¸¤å¤§å±€é™ï¼šä¸€æ˜¯æœç´¢æ–¹æ³•ä¸ perplexity è¯¯å·®å‡½æ•°éå•è°ƒæ€§ä¸åŒ¹é…ï¼Œå¯¼è‡´é™ç»´è¡¨ç¤ºå‡ºç°ç¦»ç¾¤ç‚¹ï¼›äºŒæ˜¯å…³é”®å‚æ•°ï¼ˆç›®æ ‡ perplexityï¼‰å‡­ç»éªŒé€‰å–ï¼Œå¼•å…¥éšæ„æ€§é€ æˆé‡‡æ ·ä¸å‡ï¼Œæœ€ç»ˆä½¿æ ·æœ¬ä»£è¡¨æ€§æœ‰åå·®ã€è®­ç»ƒç²¾åº¦ä¸‹é™ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºAdapSNEæ–¹æ¡ˆã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šé›†æˆçƒŸèŠ±ç®—æ³•ï¼ˆFWAï¼‰æŠ‘åˆ¶ç¦»ç¾¤ç‚¹  
å¼•å…¥é«˜æ•ˆçš„éå•è°ƒæœç´¢æ–¹æ³•â€”â€”çƒŸèŠ±ç®—æ³•ï¼ˆFWAï¼‰æ¥æ¢ç´¢ perplexity è¯¯å·®å‡½æ•°ï¼Œè§£å†³æœç´¢æ–¹æ³•å’Œéå•è°ƒè¯¯å·®å‡½æ•°ä¸åŒ¹é…çš„é—®é¢˜ï¼Œä»è€Œåœ¨é™ç»´ç©ºé—´ä¸­æŠ‘åˆ¶ç¦»ç¾¤ç‚¹äº§ç”Ÿï¼Œè®©æ ·æœ¬è¡¨ç¤ºæ›´åˆç†ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç†µå¼•å¯¼ä¼˜åŒ–å®ç°å‡åŒ€é‡‡æ ·  
é‡‡ç”¨ç†µå¼•å¯¼ä¼˜åŒ–æœºåˆ¶è‡ªåŠ¨è°ƒæ•´ç›®æ ‡ perplexityï¼Œé¿å…å‡­ç»éªŒé€‰å‚æ•°å¸¦æ¥çš„éšæ„æ€§ï¼Œä¿ƒä½¿é‡‡æ ·è¿‡ç¨‹æ›´å‡åŒ€ï¼Œä¿éšœè®­ç»ƒæ ·æœ¬çš„ä»£è¡¨æ€§ï¼Œè¿›è€Œæå‡è®­ç»ƒç²¾åº¦ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå®šåˆ¶æ•°æ®æµåŠæ—¶åˆ†å¤ç”¨åŠ é€Ÿå™¨é™ä½è¾¹ç¼˜ä¾§å¼€é”€  
ä¸ºå‰Šå‡FWAæœç´¢å’Œç†µå¼•å¯¼ä¼˜åŒ–è¿­ä»£è®¡ç®—å¸¦æ¥çš„è¾¹ç¼˜ä¾§æˆæœ¬ï¼Œè®¾è®¡å¸¦æœ‰å®šåˆ¶æ•°æ®æµå’Œæ—¶åˆ†å¤ç”¨æŠ€æœ¯çš„åŠ é€Ÿå™¨ï¼Œå¤§å¹…å‡å°‘è®¾å¤‡ä¸Šè®­ç»ƒçš„èƒ½è€—ä¸é¢ç§¯ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
å®éªŒè¡¨æ˜AdapSNEåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¶…è¶Šäº†å½“å‰æœ€ä¼˜çš„åŸºäºDNNï¼ˆå¦‚DQASï¼‰å’Œæ— DNNï¼ˆå¦‚NMSï¼‰æ–¹æ³•ï¼šåœ¨å°è§„æ¨¡å›¾åƒæ•°æ®é›†ä¸Šï¼Œç›¸è¾ƒDQASç²¾åº¦æå‡4.4%ã€ç›¸è¾ƒNMSæå‡0.85%ï¼›åœ¨å¤§è§„æ¨¡å›¾åƒæ•°æ®é›†ä¸Šï¼Œå¯¹DQASå¢ç›Šè¾¾8.3%ã€å¯¹NMSè¾¾2.5%ï¼›åœ¨MMLUå¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•ä¸­ï¼Œç›¸è¾ƒDQASå¹³å‡æ€§èƒ½æå‡3.5%ã€ç›¸è¾ƒNMSæå‡2.4%ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. é’ˆå¯¹éå•è°ƒå‡½æ•°ä¼˜åŒ–åœºæ™¯ï¼Œå¼•å…¥å¯å‘å¼ç®—æ³•ï¼ˆå¦‚çƒŸèŠ±ç®—æ³•ï¼‰æ¥åº”å¯¹æœç´¢æ–¹æ³•ä¸å‡½æ•°ç‰¹æ€§ä¸åŒ¹é…é—®é¢˜ï¼Œä¸ºåŒç±»ä¼˜åŒ–ä»»åŠ¡æä¾›æ€è·¯ï¼›  
2. åˆ©ç”¨ç†µå¼•å¯¼è¿™ç±»æ•°æ®é©±åŠ¨çš„æ–¹å¼è‡ªåŠ¨è°ƒèŠ‚å…³é”®å‚æ•°ï¼Œå‡å°‘ç»éªŒæ€§è®¾ç½®å¸¦æ¥çš„åå·®ï¼Œåœ¨éœ€å‚æ•°è‡ªé€‚é…çš„ä»»åŠ¡ä¸­å€¼å¾—å‚è€ƒï¼›  
3. ç»“åˆç¡¬ä»¶åŠ é€Ÿå™¨è®¾è®¡ï¼ˆå®šåˆ¶æ•°æ®æµ + æ—¶åˆ†å¤ç”¨ï¼‰æ¥é™ä½ç®—æ³•è¿­ä»£è®¡ç®—çš„èµ„æºå¼€é”€ï¼Œä½“ç°äº†ç®—æ³• - ç¡¬ä»¶ååŒè®¾è®¡æ€è·¯ï¼Œå¯¹è¾¹ç¼˜åœºæ™¯ä¸‹è®¡ç®—å¯†é›†å‹ä»»åŠ¡çš„è½åœ°æœ‰å€Ÿé‰´æ„ä¹‰ã€‚

## improving-detection-of-watermarked-language-models
### Abstract
Watermarking has recently emerged as an effective strategy for detecting the
generations of large language models (LLMs). The strength of a watermark
typically depends strongly on the entropy afforded by the language model and
the set of input prompts. However, entropy can be quite limited in practice,
especially for models that are post-trained, for example via instruction tuning
or reinforcement learning from human feedback (RLHF), which makes detection
based on watermarking alone challenging. In this work, we investigate whether
detection can be improved by combining watermark detectors with non-watermark
ones. We explore a number of hybrid schemes that combine the two, observing
performance gains over either class of detector under a wide range of
experimental conditions.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ç»“åˆæ°´å°ä¸éæ°´å°æ£€æµ‹ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹è¯†åˆ«èƒ½åŠ›

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
è¿‘å¹´æ¥ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¹¿æ³›åº”ç”¨ä½¿å¾—è¯†åˆ«AIç”Ÿæˆå†…å®¹ï¼ˆAGCï¼‰çš„éœ€æ±‚æ—¥ç›Šè¿«åˆ‡ã€‚æ°´å°æŠ€æœ¯ä½œä¸ºæ£€æµ‹LLMsç”Ÿæˆå†…å®¹çš„æœ‰æ•ˆç­–ç•¥ï¼Œå…¶æ•ˆæœå¾ˆå¤§ç¨‹åº¦ä¾èµ–äºè¯­è¨€æ¨¡å‹çš„ç†µï¼ˆå³æ¨¡å‹åœ¨ç‰¹å®šæç¤ºä¸‹ç”Ÿæˆå“åº”çš„ä¸ç¡®å®šæ€§ï¼‰å’Œè¾“å…¥æç¤ºé›†åˆã€‚ä½†å®é™…ä¸­ç†µå¾€å¾€å—é™ï¼Œå°¤å…¶æ˜¯ç»è¿‡æŒ‡ä»¤å¾®è°ƒã€åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ç­‰åè®­ç»ƒçš„æ¨¡å‹ï¼Œä»…ä¾é æ°´å°æ£€æµ‹å­˜åœ¨æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ¢ç´¢å°†æ°´å°æ£€æµ‹å™¨ä¸éæ°´å°æ£€æµ‹å™¨ç»“åˆï¼Œä»¥æå‡æ£€æµ‹æ€§èƒ½ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºæ··åˆæ£€æµ‹æ–¹æ¡ˆ  
ä»¥å¾€æ°´å°æ£€æµ‹å—ç†µé™åˆ¶ï¼Œéæ°´å°æ£€æµ‹å¤šä½œä¸ºäºŒå…ƒåˆ†ç±»ä»»åŠ¡ï¼ˆåŒºåˆ†äººç±»æ–‡æœ¬ä¸æ¨¡å‹ç”Ÿæˆæ–‡æœ¬ç­‰ï¼‰ã€‚æœ¬æ–‡å°è¯•å°†æ°´å°æ£€æµ‹ä¸éæ°´å°æ£€æµ‹ç»“åˆï¼Œæ¢ç´¢å¤šç§æ··åˆæ–¹æ¡ˆï¼Œæ—¨åœ¨åˆ©ç”¨ä¸¤è€…ä¼˜åŠ¿æå‡æ£€æµ‹æ•ˆæœã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå…³æ³¨ä½ç†µåœºæ™¯ä¸‹çš„æ£€æµ‹å¢å¼º  
åˆ†æäº†ç†µå¯¹æ°´å°æ£€æµ‹çš„å…³é”®å½±å“ï¼ˆç†µè¶Šé«˜æ°´å°æ£€æµ‹æ€§èƒ½è¶Šå¥½ï¼Œå¦‚å¼€æ”¾å¼æç¤ºæ¯”äº‹å®æ€§è¯¢é—®ç±»æç¤ºçš„ç†µæ›´é«˜ã€æ°´å°æ£€æµ‹æ›´æ˜“ï¼‰ï¼Œå¹¶å±•ç¤ºéæ°´å°æ£€æµ‹å™¨åœ¨æ··åˆè®¾ç½®ä¸­ï¼Œèƒ½åœ¨ä½ç†µç¯å¢ƒä¸‹å¤§å¹…å¢å¼ºæ°´å°æ£€æµ‹çš„èƒ½åŠ›ï¼Œç ”ç©¶ä¸¤ç§æ£€æµ‹æ–¹å¼å¦‚ä½•æœ‰æ•ˆç»“åˆä»¥è·å¾—æ¯”å•ä¸€æ–¹å¼æ›´å¥½çš„é¢„æµ‹æ€§èƒ½ä¸è®¡ç®—ä¼˜åŠ¿ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
æ–‡ä¸­é€šè¿‡åœ¨å¤šç§å®éªŒæ¡ä»¶ä¸‹å¯¹æ··åˆæ£€æµ‹æ–¹æ¡ˆè¿›è¡Œæµ‹è¯•ï¼Œè§‚å¯Ÿåˆ°æ··åˆæ–¹æ¡ˆåœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†å•ç‹¬çš„æ°´å°æ£€æµ‹å™¨æˆ–éæ°´å°æ£€æµ‹å™¨ã€‚ä¸è¿‡åŸæ–‡æœªå®Œæ•´å‘ˆç°å®éªŒç»“æœç»†èŠ‚ï¼ˆå› æä¾›çš„è®ºæ–‡å…¨æ–‡å†…å®¹æœªå±•ç¤ºå®Œæ•´å®éªŒç»“æœéƒ¨åˆ†ï¼‰ï¼Œä½†æ ¸å¿ƒç»“è®ºæ˜¯æ··åˆæ£€æµ‹åœ¨å¹¿æ³›å®éªŒæ¡ä»¶ä¸‹å¸¦æ¥äº†æ€§èƒ½æå‡ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
å¯¹äºå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹æ£€æµ‹é¢†åŸŸï¼Œæœ¬æ–‡æä¾›äº†è·¨æ£€æµ‹èŒƒå¼ç»“åˆçš„æ€è·¯ï¼Œä¸ºåç»­ç ”ç©¶è€…åœ¨å¤„ç†ä½ç†µç­‰æ°´å°æ£€æµ‹å—é™åœºæ™¯æ—¶ï¼Œæä¾›äº†â€œæ°´å° + éæ°´å°â€æ··åˆæ£€æµ‹çš„æ–°æ–¹å‘ï¼›åŒæ—¶å¼ºè°ƒäº†åœ¨å®é™…éƒ¨ç½²æ£€æµ‹ç³»ç»Ÿæ—¶ï¼Œå¯è€ƒè™‘è¿™ç±»æ··åˆç®—æ³•æ¥å¹³è¡¡æ£€æµ‹æ€§èƒ½ä¸è®¡ç®—æˆæœ¬ç­‰ï¼Œä¸ºäº§ä¸šç•Œè½åœ°AIç”Ÿæˆå†…å®¹æ£€æµ‹å·¥å…·æä¾›äº†åˆ›æ–°æ€è·¯å‚è€ƒã€‚

## j6--jacobian-driven-role-attribution-for-multi-objective-prompt-optimization-in-llms
### Abstract
In large language model (LLM) adaptation, balancing multiple optimization
objectives such as improving factuality (heat) and increasing confidence (via
low entropy) poses a fundamental challenge, especially when prompt parameters
(e.g., hidden-layer insertions h and embedding modifications w) interact in
non-trivial ways. Existing multi-objective optimization strategies often rely
on scalar gradient aggregation, ignoring the deeper geometric structure between
objectives and parameters. We propose J6, a structured Jacobian-based method
that decomposes the gradient interaction matrix into six interpretable
components. This decomposition enables both hard decision-making (e.g.,
choosing the dominant update direction via argmax) and soft strategies (e.g.,
attention-style weighting via softmax over J6), forming a dynamic update
framework that adapts to local conflict and synergy. Moreover, the
interpretable structure of J6 provides insight into parameter attribution, task
interference, and geometry-aligned adaptation. Our work introduces a principled
and extensible mechanism for conflict-aware prompt optimization, and opens a
new avenue for incorporating structured Jacobian reasoning into multi-objective
neural tuning.
### ğŸŒŸ è®ºæ–‡è§£è¯» | LLMå¤šç›®æ ‡Promptä¼˜åŒ–æ–°èŒƒå¼ï¼šJ6åŸºäºé›…å¯æ¯”çš„è§’è‰²å½’å› æ³•

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€‚é…è¿‡ç¨‹ä¸­ï¼Œå¹³è¡¡å¤šä¸ªä¼˜åŒ–ç›®æ ‡ï¼ˆå¦‚æå‡äº‹å®æ€§ä¸å¢å¼ºè¾“å‡ºç½®ä¿¡åº¦ï¼‰æ˜¯ä¸€é¡¹å…³é”®æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯å½“Promptå‚æ•°ï¼ˆå¦‚éšè—å±‚æ’å…¥é¡¹`h`å’ŒåµŒå…¥ä¿®æ”¹é¡¹`w`ï¼‰ä»¥å¤æ‚æ–¹å¼äº¤äº’æ—¶ã€‚ç°æœ‰å¤šç›®æ ‡ä¼˜åŒ–ç­–ç•¥å¸¸ä¾èµ–æ ‡é‡æ¢¯åº¦èšåˆï¼Œå¿½ç•¥äº†ç›®æ ‡ä¸å‚æ•°é—´æ›´æ·±å±‚çš„å‡ ä½•ç»“æ„ï¼›ä¸”ä¼ ç»Ÿæ–¹æ³•è¦ä¹ˆå°†å•ä¸€æ ‡é‡æŸå¤±ä¼˜åŒ–åˆ°åº•ã€è¦ä¹ˆé‡‡ç”¨å›ºå®šæƒé‡çš„å¤šä»»åŠ¡ç›®æ ‡ï¼Œæ— æ³•ç²¾ç»†å»ºæ¨¡ä¸åŒå‚æ•°ç±»å‹å¯¹ä¸åŒç›®æ ‡çš„è´¡çŒ®å·®å¼‚ã€‚æ­¤å¤–ï¼Œé™æ€åˆ†é…å‚æ•°è§’è‰²ï¼ˆå¦‚è®©`h`ä¼˜åŒ–äº‹å®æ€§ã€`w`ä¼˜åŒ–ç½®ä¿¡åº¦ï¼‰çš„åšæ³•è¿‡äºç®€åŒ–ï¼Œå®é™…ä¸­å‚æ•°å¯¹å¤šç›®æ ‡çš„å½±å“å¾€å¾€ç›¸äº’çº ç¼ ã€åŠ¨æ€å˜åŒ–ï¼Œæ˜“å¼•å‘æ¢¯åº¦å†²çªä¸æ¬¡ä¼˜æ›´æ–°ã€‚å› æ­¤ï¼ŒäºŸéœ€ä¸€ç§èƒ½åŠ¨æ€æ„ŸçŸ¥ä»»åŠ¡å…³è”ã€è§£è€¦æ¢¯åº¦è´£ä»»çš„å¤šç›®æ ‡Promptä¼˜åŒ–æœºåˆ¶ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºè§’è‰²å½’å› é—®é¢˜ä¸J6æ¡†æ¶  
è®ºæ–‡é¦–æ¬¡æ˜ç¡®â€œå¤šç›®æ ‡Promptè°ƒä¼˜ä¸­çš„è§’è‰²å½’å› â€é—®é¢˜ï¼Œå¹¶é€šè¿‡é›…å¯æ¯”ï¼ˆJacobianï¼‰åˆ†è§£å°†å…¶å½¢å¼åŒ–ã€‚é’ˆå¯¹ä¸¤ä¸ªç›®æ ‡ï¼ˆäº‹å®æ€§`Heat`ã€ç½®ä¿¡åº¦`Confidence`ï¼‰ä¸ä¸¤ç±»å‚æ•°ç»„ï¼ˆ`h`ã€`w`ï¼‰ï¼Œè®¡ç®—å±€éƒ¨2Ã—2é›…å¯æ¯”çŸ©é˜µ`J`ï¼Œå¹¶å°†å…¶æ‹†è§£ä¸º6ä¸ªå¯è§£é‡Šç»„ä»¶ï¼ˆå³`J6`ï¼‰ï¼šåŒ…å«`hâ†’Heat`ç­‰â€œè§’è‰²ç‰¹å®šè´¡çŒ®â€é¡¹ï¼Œä»¥åŠåˆ»ç”»è·¨ç›®æ ‡å¯¹é½çš„â€œç»“æ„äº¤äº’â€é¡¹ã€‚è¿™äº›ç»„ä»¶è®©æ¢¯åº¦ç©ºé—´çš„ç»†ç²’åº¦äº¤äº’ç»“æ„å˜å¾—é€æ˜ï¼Œä¸ºå‚æ•°åŠ¨æ€åˆ†å·¥æä¾›ä¾æ®ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šåŒæ›´æ–°ç­–ç•¥æ”¯æ’‘çµæ´»è°ƒä¼˜  
åŸºäº`J6`åˆ†è§£ï¼Œè®¾è®¡â€œç¡¬ç­–ç•¥â€ä¸â€œè½¯ç­–ç•¥â€ä¸¤ç§æ›´æ–°æ–¹æ¡ˆï¼š  
- ç¡¬ç­–ç•¥ï¼ˆHard Strategyï¼‰ï¼šé€šè¿‡`argmax`é€‰å–`J6`å‘é‡ä¸­æœ€å¤§é¡¹ï¼Œå†³ç­–è¯¥ä¼˜åŒ–æ­¥éª¤ä¸­ä¼˜å…ˆæ›´æ–°çš„å‚æ•°ä¸ç›®æ ‡ï¼Œå®ç°å¯è§£é‡Šçš„ç¦»æ•£è§’è‰²åˆ†é…ï¼›  
- è½¯ç­–ç•¥ï¼ˆSoft Strategyï¼‰ï¼šå€ŸåŠ©`softmax`å¯¹`J6`å¾—åˆ†å½’ä¸€åŒ–ï¼Œå°†å…¶ä½œä¸ºè¿ç»­æƒé‡å¼•å¯¼`h`ä¸`w`çš„åŒæ­¥æ›´æ–°ï¼Œåœ¨ä¸æ‰©å±•ç»´åº¦çš„å‰æä¸‹å®ç°æ¢¯åº¦èåˆã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šæ‰©å±•å½’å› ç©ºé—´J+ä¸ç†è®ºæ”¯æ’‘  
è¿›ä¸€æ­¥å°†å½’å› æ€æƒ³æ‹“å±•åˆ°å«15é¡¹é«˜é˜¶å¯¹é½é¡¹çš„`J+`ç©ºé—´ï¼ˆæ¶µç›–è·¨è§’è‰²ååŒã€è§’è‰²å†…ä¸€è‡´æ€§ã€éå¯¹ç§°ä¸»å¯¼æ€§ç­‰ï¼‰ã€‚è™½`J+`ä¸ç›´æ¥ç”¨äºè®­ç»ƒï¼Œä½†ä¸ºè½¯ç­–ç•¥æä¾›ç†è®ºåŸºç¡€ï¼›ä¸”è®ºæ–‡è¯æ˜ï¼Œåˆç†åŠ æƒçš„`J6`è¶³ä»¥æ¨¡æ‹Ÿ`J+`çš„ä¼˜åŒ–è¡Œä¸ºâ€”â€”åœ¨ä¸é¢å¤–å¢åŠ è®¡ç®—é‡çš„åŒæ—¶ä¿ç•™é«˜è¡¨è¾¾èƒ½åŠ›ã€‚  


### ğŸ“ˆ å®éªŒç»“æœ
è®ºæ–‡åœ¨MathQAã€GSM8Kã€TruthfulQAä¸‰ä¸ªå­˜åœ¨ä¸¥é‡ç›®æ ‡å†²çªçš„åŸºå‡†ä»»åŠ¡ä¸ŠéªŒè¯J6ã€‚å®éªŒè¡¨æ˜ï¼š  
- æ€§èƒ½å±‚é¢ï¼šJ6æŒç»­è¶…è¶ŠSlotã€PCGradã€åŸºäºå¸•ç´¯æ‰˜ï¼ˆParetoï¼‰çš„å¼ºåŸºçº¿æ–¹æ³•ï¼›  
- å¯è§£é‡Šæ€§å±‚é¢ï¼šé€šè¿‡å¯è§†åŒ–å‘ˆç°`h`ä¸`w`éšè®­ç»ƒè¿›ç¨‹çš„è§’è‰²åŠ¨æ€é€‚é…è¿‡ç¨‹ï¼Œç›´è§‚å±•ç°å‚æ•°å¦‚ä½•å“åº”å¤šç›®æ ‡å†²çªä¸ååŒï¼Œæœ‰åŠ›ä½è¯äº†â€œé›…å¯æ¯”é©±åŠ¨è§’è‰²å½’å› â€åœ¨æœ‰æ•ˆæ€§ã€å¯è§£é‡Šæ€§ä¸æ‰©å±•æ€§ä¸Šçš„ä¼˜åŠ¿ã€‚  


### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **é—®é¢˜å®šä¹‰åˆ›æ–°**ï¼šæŠŠâ€œå¤šç›®æ ‡Promptè°ƒä¼˜â€ä»â€œé»‘ç®±å¼æ¢¯åº¦èšåˆâ€è½¬å‘â€œç»†ç²’åº¦è§’è‰²å½’å› â€ï¼Œä¸ºå¤šç›®æ ‡ç¥ç»è°ƒä¼˜å¼€è¾Ÿæ–°è§†è§’ï¼›  
2. **é›…å¯æ¯”ç»“æ„åˆ©ç”¨**ï¼šå€ŸåŠ©é›…å¯æ¯”çŸ©é˜µåˆ†è§£ï¼Œå°†æŠ½è±¡çš„æ¢¯åº¦äº¤äº’è½¬åŒ–ä¸ºå¯è§£é‡Šç»„ä»¶ï¼Œæ—¢è§£è€¦äº†å‚æ•°-ç›®æ ‡è´£ä»»ï¼Œåˆä¸ºä¼˜åŒ–ç­–ç•¥è®¾è®¡æä¾›ç»“æ„åŒ–æŠ“æ‰‹ï¼›  
3. **åŒç­–ç•¥è®¾è®¡å“²å­¦**ï¼šç¡¬ç­–ç•¥æ»¡è¶³â€œç¦»æ•£å†³ç­–ã€å¯è§£é‡Šæ€§â€éœ€æ±‚ï¼Œè½¯ç­–ç•¥æ”¯æŒâ€œè¿ç»­èåˆã€çµæ´»è°ƒä¼˜â€ï¼Œè¿™ç§â€œä¸€ç¡¬ä¸€è½¯â€çš„ç»„åˆæ€è·¯å¯è¿ç§»è‡³å…¶ä»–å¤šç›®æ ‡ä¼˜åŒ–åœºæ™¯ï¼›  
4. **å®éªŒä¸å¯è§†åŒ–ä»·å€¼**ï¼šåœ¨å†²çªåœºæ™¯ä¸‹çš„å¯¹æ¯”å®éªŒ+å‚æ•°è§’è‰²åŠ¨æ€å¯è§†åŒ–ï¼Œä¸ºåç»­ç ”ç©¶â€œå¤šç›®æ ‡ä¸‹æ¨¡å‹å†…éƒ¨é€‚é…æœºåˆ¶â€æä¾›äº†æ–¹æ³•è®ºå‚è€ƒã€‚  

æ€»ä¹‹ï¼ŒJ6ä¸ºâ€œå†²çªæ„ŸçŸ¥å‹Promptä¼˜åŒ–â€æä¾›äº†ä¸€å¥—åŸåˆ™æ€§å¼ºä¸”å¯æ‰©å±•çš„æœºåˆ¶ï¼Œä¹Ÿä¸ºâ€œç»“æ„åŒ–é›…å¯æ¯”æ¨ç†èå…¥å¤šç›®æ ‡ç¥ç»è°ƒä¼˜â€æ‰“å¼€æ–°æ–¹å‘ï¼Œå¯¹LLMåœ¨çœŸå®å¤æ‚åœºæ™¯ä¸‹çš„é²æ£’é€‚é…å…·æœ‰é‡è¦å¯ç¤ºã€‚

## core--measuring-multi-agent-llm-interaction-quality-under-game-theoretic-pressures
### Abstract
Game-theoretic interactions between agents with Large Language Models (LLMs)
have revealed many emergent capabilities, yet the linguistic diversity of these
interactions has not been sufficiently quantified. In this paper, we present
the Conversational Robustness Evaluation Score: CORE, a metric to quantify the
effectiveness of language use within multi-agent systems across different
game-theoretic interactions. CORE integrates measures of cluster entropy,
lexical repetition, and semantic similarity, providing a direct lens of dialog
quality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,
and neutral settings, further grounding our analysis in Zipf's and Heaps' Laws
to characterize word frequency distributions and vocabulary growth. Our
findings show that cooperative settings exhibit both steeper Zipf distributions
and higher Heap exponents, indicating more repetition alongside greater
vocabulary expansion. In contrast, competitive interactions display lower Zipf
and Heaps exponents, reflecting less repetition and more constrained
vocabularies. These results provide new insights into how social incentives
influence language adaptation, and highlight CORE as a robust diagnostic for
measuring linguistic robustness in multi-agent LLM systems. Our code is
available at https://github.com/psyonp/core.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ç”¨COREæ­ç§˜å¤šæ™ºèƒ½ä½“LLMåšå¼ˆäº¤äº’ä¸­çš„è¯­è¨€è´¨é‡

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“çš„åšå¼ˆè®ºäº¤äº’ä¸­ï¼Œæ¶Œç°å‡ºäº†è¯¸å¤šèƒ½åŠ›ï¼Œä½†è¿™äº›äº¤äº’é‡Œè¯­è¨€å¤šæ ·æ€§çš„é‡åŒ–å´ä¸å¤Ÿå……åˆ†ã€‚äººç±»è¯­è¨€åœ¨ç¤¾ä¼šå’Œè¿›åŒ–å‹åŠ›ä¸‹æ¼”å˜ï¼Œè€ŒLLMæ™ºèƒ½ä½“æä¾›äº†å¯æ§ç¯å¢ƒæ¥ç ”ç©¶äº¤äº’å‹åŠ›å¦‚ä½•å¡‘é€ è¯­è¨€ä½¿ç”¨ã€‚åŒæ—¶ï¼Œè‡ªç„¶è¯­è¨€ä¸­çš„Zipfå®šå¾‹å’ŒHeapså®šå¾‹è™½èƒ½ç†è§£è¯é¢‘åˆ†å¸ƒä¸è¯æ±‡å¢é•¿ï¼Œå´è¾ƒå°‘å…³æ³¨åšå¼ˆè®ºäº¤äº’åŠ¨æ€å¯¹è¯­è¨€ç»“æ„å˜åŒ–çš„å½±å“ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨æå‡ºä¸€ç§åº¦é‡å¤šæ™ºèƒ½ä½“LLMå¯¹è¯ä¸­è¯­è¨€å¤šæ ·æ€§ç­‰ç°è±¡çš„æŒ‡æ ‡ï¼Œå¡«è¡¥ç›¸å…³ç ”ç©¶ç©ºç™½ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºCOREåº¦é‡æŒ‡æ ‡  
COREï¼ˆConversational Robustness Evaluation Scoreï¼‰æ•´åˆäº†ç°‡ç†µã€è¯æ±‡é‡å¤å’Œè¯­ä¹‰ç›¸ä¼¼æ€§ç­‰åº¦é‡æ–¹å¼ï¼Œä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨ä¸åŒåšå¼ˆäº¤äº’ä¸‹çš„è¯­è¨€ä½¿ç”¨æœ‰æ•ˆæ€§æä¾›äº†ç›´æ¥è¡¡é‡æ‰‹æ®µï¼Œèƒ½æ•æ‰å¯¹è¯è´¨é‡ï¼Œæ£€æµ‹æ¨¡å¼å´©æºƒã€é‡å¤å’Œè¯­ä¹‰åœæ»ç­‰ç°è±¡ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç»“åˆåšå¼ˆåœºæ™¯ä¸ç»å…¸è¯­è¨€å®šå¾‹åˆ†æ  
å°†COREåº”ç”¨äºç«äº‰ã€åˆä½œå’Œä¸­æ€§åœºæ™¯ä¸‹çš„æˆå¯¹LLMå¯¹è¯ï¼ŒåŒæ—¶åŸºäºZipfå®šå¾‹ï¼ˆè¯é¢‘ä¸è¯ç§©çš„åæ¯”å…³ç³»ï¼‰å’ŒHeapså®šå¾‹ï¼ˆè¯æ±‡é‡ä¸ç”Ÿæˆè¯æ•°çš„å…³ç³»ï¼‰æ¥åˆ†æè¯é¢‘åˆ†å¸ƒå’Œè¯æ±‡å¢é•¿ï¼Œä»å¤šç»´åº¦å‰–æè¯­è¨€åœ¨ä¸åŒç¤¾äº¤æ¿€åŠ±ä¸‹çš„å˜åŒ–ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨ä¸åŒåšå¼ˆåœºæ™¯ä¸­ï¼Œè¯­è¨€è¡¨ç°å‘ˆç°å·®å¼‚ï¼šåˆä½œåœºæ™¯ä¸‹Zipfåˆ†å¸ƒæ›´é™¡ä¸”HeapæŒ‡æ•°æ›´é«˜ï¼Œæ„å‘³ç€æ›´å¤šé‡å¤çš„åŒæ—¶è¯æ±‡æ‰©å±•ä¹Ÿæ›´å¼ºï¼›ç«äº‰äº¤äº’åˆ™Zipfå’ŒHeapsæŒ‡æ•°æ›´ä½ï¼Œåæ˜ å‡ºé‡å¤æ›´å°‘ä¸”è¯æ±‡æ›´å—çº¦æŸã€‚è¿™äº›ç»“æœæ­ç¤ºäº†ç¤¾äº¤æ¿€åŠ±å¯¹è¯­è¨€é€‚åº”çš„å½±å“ï¼Œä¹ŸéªŒè¯äº†COREåœ¨è¡¡é‡å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿè¯­è¨€é²æ£’æ€§ä¸Šçš„æœ‰æ•ˆæ€§ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»ç ”ç©¶è§’åº¦ï¼Œé¦–æ¬¡å¤§è§„æ¨¡è”åˆåˆ†æåšå¼ˆè®ºå¤šæ™ºèƒ½ä½“LLMäº¤äº’ä¸­çš„ç»Ÿè®¡è¯­è¨€å®šå¾‹ä¸å¯¹è¯å¤šæ ·æ€§æŒ‡æ ‡ï¼Œä¸ºæ¢ç´¢è¯­è¨€æ¼”å˜å’Œé€šä¿¡åŠ¨æ€æä¾›æ–°è§†è§’ï¼›ä»æ–¹æ³•è§’åº¦ï¼ŒCOREæŒ‡æ ‡ä¸ºè¯„ä¼°å¤šæ™ºèƒ½ä½“å¯¹è¯è´¨é‡æä¾›äº†é²æ£’å·¥å…·ï¼Œåç»­ç ”ç©¶å¯å€Ÿé‰´è¯¥æŒ‡æ ‡æ¥åˆ†æä¸åŒåœºæ™¯ä¸‹è¯­è¨€ç°è±¡ï¼›ä»åº”ç”¨è§’åº¦ï¼Œå¯¹ç†è§£ç¤¾äº¤æ¿€åŠ±å¦‚ä½•å¡‘é€ è¯­è¨€ã€ä¼˜åŒ–å¤šæ™ºèƒ½ä½“äº¤äº’ç³»ç»Ÿçš„è¯­è¨€è¡¨ç°ç­‰æ–¹é¢å…·æœ‰å‚è€ƒä»·å€¼ï¼Œæ¯”å¦‚åœ¨è®¾è®¡åä½œæˆ–ç«äº‰ç±»AIåº”ç”¨æ—¶ï¼Œå¯å€ŸåŠ©ç±»ä¼¼æ€è·¯åˆ†æè¯­è¨€åˆç†æ€§ã€‚

## can-we-tell-if-chatgpt-is-a-parasite--studying-human-ai-symbiosis-with-game-theory
### Abstract
This work asks whether a human interacting with a generative AI system can
merge into a single individual through iterative, information-driven
interactions. We model the interactions between a human, a generative AI
system, and the human's wider environment as a three-player stochastic game. We
use information-theoretic measures (entropy, mutual information, and transfer
entropy) to show that our modelled human and generative AI are able to form an
aggregate individual in the sense of Krakauer et al. (2020). The model we
present is able to answer interesting questions around the symbiotic nature of
humans and AI systems, including whether LLM-driven chatbots are acting as
parasites, feeding on the information provided by humans.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ç”¨åšå¼ˆè®ºæ¢ç©¶äººç±»ä¸AIå…±ç”Ÿï¼šChatGPTæ˜¯â€œå¯„ç”Ÿè™«â€å—ï¼Ÿ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œäººç±»ä¸AIçš„äº¤äº’æ„ˆå‘é¢‘ç¹ï¼Œè¿™å¼•å‘äº†å…³äºäº¤äº’æœ¬è´¨ã€AIåœ¨äººç±»åˆ›é€ åŠ›ä¸­è§’è‰²ã€AIä¸äººç±»è¡Œä¸ºåŠ¨æ€å˜åŒ–ç­‰è¯¸å¤šé—®é¢˜ã€‚åˆ†å¸ƒå¼è®¤çŸ¥é¢†åŸŸé•¿æœŸæ€è€ƒè®¤çŸ¥è¿‡ç¨‹å—å¤–ç•Œå½±å“çš„æƒ…å†µï¼Œè€Œç°ä»£AIä¸äººç±»è¿­ä»£äº¤äº’ä¸”èƒ½å¿«é€Ÿé€‚åº”ç”¨æˆ·çš„ç‰¹æ€§ï¼Œè®©ç”¨æˆ·ã€ç¯å¢ƒä¸AIé—´çš„è¿­ä»£äº¤äº’å­˜åœ¨å¦‚LLMsæ˜¯ç»Ÿè®¡çŒœæµ‹è€Œéäº‹å®é™ˆè¿°ã€ç”¨æˆ·å’Œç¯å¢ƒå†³ç­–åŠ¨æ€ä¸”æœ‰å™ªå£°ã€é”™è¯¯å› åé¦ˆå’Œè¿­ä»£äº¤äº’çº§è”ç­‰å€¼å¾—è€ƒé‡çš„åŸºç¡€é—®é¢˜ã€‚åŒæ—¶ï¼Œè¿‡å¾€äººç±» - AIäº¤äº’ç ”ç©¶è™½å¤šï¼Œä½†æœ¬æ–‡æ„åœ¨æ•æ‰ç”¨æˆ·é€‚åº”ã€é‡åŒ–äººç±»ç¯å¢ƒè§’è‰²ï¼Œå¹¶é€šè¿‡ä¿¡æ¯è®ºæŒ‡æ ‡é˜æ˜AIç³»ç»Ÿè®¾è®¡ä¸­é€‰æ‹©çš„å½±å“ï¼Œä¸ºäººç±» - AIåä½œæä¾›æ–°æ´è§ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ„å»ºä¸‰æ–¹éšæœºåšå¼ˆæ¨¡å‹  
å°†äººç±»ã€ç”Ÿæˆå¼AIç³»ç»Ÿå’Œäººç±»æ‰€å¤„ç¯å¢ƒé—´çš„äº¤äº’å»ºæ¨¡ä¸ºä¸‰ç©å®¶éšæœºåšå¼ˆï¼Œä»¥ChatGPTç­‰ç†Ÿæ‚‰çš„ç”Ÿæˆå¼AIä¸ºä¾‹ï¼Œè¿™ç§æ•´ä½“æ–¹æ³•æ•æ‰äº†ç°å®åœºæ™¯ä¸­å¤æ‚çš„ç›¸äº’ä¾èµ–å’Œåé¦ˆå¾ªç¯ï¼Œæ·±å…¥æ¢ç©¶å„ç»„ä»¶éšæ—¶é—´å¦‚ä½•ç›¸äº’å½±å“ä¸é€‚åº”ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šé‡‡ç”¨ä¿¡æ¯è®ºåº¦é‡åˆ†æ  
è¿ç”¨ç†µã€äº’ä¿¡æ¯å’Œä¼ é€’ç†µç­‰ä¿¡æ¯è®ºåº¦é‡æ‰‹æ®µï¼Œå±•ç¤ºå»ºæ¨¡åçš„äººç±»ä¸ç”Ÿæˆå¼AIèƒ½å¤Ÿå½¢æˆKrakauerç­‰äººï¼ˆ2020ï¼‰æ‰€å®šä¹‰çš„â€œèšåˆä¸ªä½“â€ï¼Œä»¥æ­¤é˜æ˜äººç±»ä¸AIå…±ç”Ÿæ€§è´¨ç›¸å…³é—®é¢˜ï¼Œæ¯”å¦‚LLMé©±åŠ¨çš„èŠå¤©æœºå™¨äººæ˜¯å¦åƒå¯„ç”Ÿè™«ä¸€æ ·ä¾èµ–äººç±»æä¾›ä¿¡æ¯ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šæ­ç¤ºååŒé€‚åº”è¿‡ç¨‹ä¸é£é™©æ”¶ç›Š  
æå‡ºçš„æ—¶é—´æ¨¡å‹æ­ç¤ºäº†äº’ä¿¡æ¯å’Œç³»ç»Ÿä¸ç¡®å®šæ€§å¦‚ä½•å‘å±•ï¼Œæ›´ç»†è‡´åœ°ç†è§£ç”¨æˆ·ä¸ç”Ÿæˆå¼AIç³»ç»Ÿé—´çš„ååŒé€‚åº”è¿‡ç¨‹ï¼›åŒæ—¶å±•ç¤ºç”¨æˆ·ä¸ç”Ÿæˆå¼AIåä½œæ—¢æœ‰çŸ¥è¯†æ‰©å±•ç­‰æ”¶ç›Šï¼Œä¹Ÿå­˜åœ¨å¯„ç”Ÿå…³ç³»ç­‰é£é™©ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
æ–‡ä¸­æœªæ˜ç¡®æåŠä¼ ç»Ÿæ„ä¹‰ä¸Šçš„å®éªŒç»“æœå‘ˆç°ï¼ˆå¦‚å¯¹æ¯”å®éªŒæŒ‡æ ‡ç­‰ï¼‰ï¼Œä½†é€šè¿‡ç†è®ºå»ºæ¨¡ä¸ä¿¡æ¯è®ºåˆ†æï¼Œè®ºè¯äº†äººç±»ä¸AIåœ¨è¿­ä»£ä¿¡æ¯é©±åŠ¨äº¤äº’ä¸­å¯å½¢æˆèšåˆä¸ªä½“ï¼Œä¸”èƒ½å€ŸåŠ©æ¨¡å‹æ¢è®¨äººç±»ä¸AIå…±ç”Ÿæ€§è´¨é—®é¢˜ï¼ˆå¦‚å¯„ç”Ÿè™«å¼å…³ç³»åˆ¤å®šï¼‰ï¼Œä¸ºç†è§£äººç±» - AI - ç¯å¢ƒäº¤äº’åŠ¨æ€æä¾›äº†ç†è®ºæ”¯æ’‘ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»ç ”ç©¶æ–¹æ³•çœ‹ï¼Œå°†å¤æ‚çš„äººç±» - AI - ç¯å¢ƒäº¤äº’å»ºæ¨¡ä¸ºåšå¼ˆå¹¶ç»“åˆä¿¡æ¯è®ºåˆ†æï¼Œä¸ºæ¢ç©¶å¤šä¸»ä½“åŠ¨æ€äº¤äº’ç³»ç»Ÿæä¾›äº†è·¨é¢†åŸŸèåˆçš„æ€è·¯ï¼Œå¯å€Ÿé‰´äºå…¶ä»–æ¶‰åŠäººç±»ä¸æ™ºèƒ½ç³»ç»Ÿäº¤äº’çš„ç ”ç©¶ï¼›ä»åº”ç”¨è§’åº¦ï¼Œå¯¹ç†è§£AIåœ¨äººç±»ç”Ÿæ´»ä¸­è§’è‰²ã€è®¾è®¡æ›´åˆç†çš„äººç±» - AIåä½œç³»ç»Ÿæœ‰å¯å‘ï¼Œæ¯”å¦‚åœ¨è€ƒè™‘AIæ˜¯å¦è¿‡åº¦ä¾èµ–äººç±»ä¿¡æ¯æˆ–äººç±»æ˜¯å¦è¿‡åº¦ä¾èµ–AIè¾“å‡ºç­‰åœºæ™¯ä¸‹ï¼Œè¯¥æ¨¡å‹æ€è·¯èƒ½è¾…åŠ©åˆ†æå†³ç­–ï¼›ä»å­¦æœ¯è´¡çŒ®çœ‹ï¼Œä¸ºäººç±» - AIååŒé€‚åº”ã€å¯é¢„æµ‹æ€§åŠæœ‰æ•ˆåä½œæœ€ä¼˜æ¡ä»¶ç­‰æ–¹å‘æä¾›äº†æ–°è§†è§’ï¼Œåç»­ç ”ç©¶å¯åŸºäºæ­¤æ‹“å±•åˆ°æ›´å¤æ‚åœºæ™¯ï¼ˆå¦‚å¤šäººç±»ã€å¤šAIäº¤äº’ï¼‰æˆ–ç»“åˆæ›´å¤šå®è¯æ•°æ®éªŒè¯æ¨¡å‹ã€‚

## ettrl--balancing-exploration-and-exploitation-in-llm-test-time-reinforcement-learning-via-entropy-mechanism
### Abstract
Recent advancements in Large Language Models have yielded significant
improvements in complex reasoning tasks such as mathematics and programming.
However, these models remain heavily dependent on annotated data and exhibit
limited adaptability in unsupervised scenarios. To address these limitations,
test-time reinforcement learning (TTRL) has been proposed, which enables
self-optimization by leveraging model-generated pseudo-labels. Despite its
promise, TTRL faces several key challenges, including high inference costs due
to parallel rollouts and early-stage estimation bias that fosters
overconfidence, reducing output diversity and causing performance plateaus. To
address these challenges, we introduce an entropy-based mechanism to enhance
the exploration-exploitation balance in test-time reinforcement learning
through two strategies: Entropy-fork Tree Majority Rollout (ETMR) and
Entropy-based Advantage Reshaping (EAR). Compared with the baseline, our
approach enables Llama3.1-8B to achieve a 68 percent relative improvement in
Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of
the rollout tokens budget. This highlights our method's ability to effectively
optimize the trade-off between inference efficiency, diversity, and estimation
robustness, thereby advancing unsupervised reinforcement learning for
open-domain reasoning tasks.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ETTRLï¼šç”¨ç†µæœºåˆ¶å¹³è¡¡å¤§æ¨¡å‹æµ‹è¯•æ—¶å¼ºåŒ–å­¦ä¹ çš„æ¢ç´¢ä¸åˆ©ç”¨

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦ã€ç¼–ç¨‹ç­‰å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ä»é«˜åº¦ä¾èµ–æ ‡æ³¨æ•°æ®ï¼Œåœ¨æ— ç›‘ç£åœºæ™¯ä¸‹é€‚åº”æ€§æœ‰é™ã€‚æµ‹è¯•æ—¶å¼ºåŒ–å­¦ä¹ ï¼ˆTTRLï¼‰è¢«æå‡ºä»¥è§£å†³æ­¤é—®é¢˜ï¼Œå®ƒå€ŸåŠ©æ¨¡å‹ç”Ÿæˆçš„ä¼ªæ ‡ç­¾å®ç°è‡ªä¼˜åŒ–ã€‚ç„¶è€ŒTTRLå­˜åœ¨ä¸¤å¤§å…³é”®æŒ‘æˆ˜ï¼šä¸€æ˜¯å¹¶è¡Œrolloutså¸¦æ¥çš„é«˜æ¨ç†æˆæœ¬ï¼›äºŒæ˜¯æ—©æœŸä¼°è®¡åå·®å¼•å‘çš„è¿‡åº¦è‡ªä¿¡ï¼Œé™ä½è¾“å‡ºå¤šæ ·æ€§å¹¶å¯¼è‡´æ€§èƒ½åœæ»ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œè®ºæ–‡æå‡ºåŸºäºç†µæœºåˆ¶çš„ETTRLæ¡†æ¶æ¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šEntropy - fork Tree Majority Rolloutï¼ˆETMRï¼‰
ä¸ºè§£å†³æ ‡å‡†rolloutsè®¡ç®—å¼€é”€å¤§ä¸æ¢ç´¢ä¸è¶³é—®é¢˜ï¼Œæå‡ºæ ‘ç»“æ„çš„rolloutç­–ç•¥ETMRã€‚å®ƒä»…åœ¨ç†µæœ€é«˜çš„Kä¸ªtokenï¼ˆå³â€œåˆ†å‰ç‚¹â€ï¼‰å¤„é€‰æ‹©æ€§åˆ†æ”¯ï¼Œç”¨æ›´å°‘çš„tokené¢„ç®—ç”Ÿæˆæ›´å¤šæ ·çš„å€™é€‰å“åº”ã€‚åœ¨AIME 2024åŸºå‡†æµ‹è¯•ä¸­ï¼Œèƒ½è®©Qwen2 - 1.5Båœ¨Pass@1æŒ‡æ ‡ä¸Šæ¯”åŸå§‹TTRLåŸºçº¿æå‡5.24ä¸ªç™¾åˆ†ç‚¹ï¼ŒåŒæ—¶å°†rolloutsæˆæœ¬å‡åŠã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šEntropy - based Advantage Reshapingï¼ˆEARï¼‰
ä¸ºç¼“è§£æ—©æœŸä¼°è®¡åå·®å¹¶ç»´æŒæ¢ç´¢ï¼Œå¼•å…¥EARã€‚è¯¥æ–¹æ³•åœ¨Group Relative Policy Optimizationï¼ˆGRPOï¼‰ä¸­é‡å¡‘ä¼˜åŠ¿ï¼Œå°†å“åº”çº§ç›¸å¯¹ç†µå¥–åŠ±çº³å…¥è®¡ç®—ï¼Œä¿®æ­£äº†åŸå§‹GRPOä¸­å¯¹ä½ç½®ä¿¡åº¦å¥–åŠ±çš„æ—©æœŸé«˜ä¼°åå·®ï¼Œåœ¨AIME 2024ä¸Šä½¿Pass@1é¢å¤–æå‡3.0ä¸ªç™¾åˆ†ç‚¹ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
ä¸åŸºçº¿ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä½¿Llama3.1 - 8Båœ¨AIME 2024åŸºå‡†çš„Pass@1æŒ‡æ ‡ä¸Šå®ç°68%çš„ç›¸å¯¹æå‡ï¼ŒåŒæ—¶ä»…æ¶ˆè€—60%çš„rollout tokensé¢„ç®—ï¼Œå±•ç°å‡ºåœ¨æ¨ç†æ•ˆç‡ã€å¤šæ ·æ€§å’Œä¼°è®¡é²æ£’æ€§ä¹‹é—´æœ‰æ•ˆä¼˜åŒ–æƒè¡¡çš„èƒ½åŠ›ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
è®ºæ–‡æå‡ºçš„åŸºäºç†µçš„æœºåˆ¶ä¸ºè§£å†³æµ‹è¯•æ—¶å¼ºåŒ–å­¦ä¹ çš„å…³é”®æŒ‘æˆ˜æä¾›äº†æ–°æ€è·¯ï¼ŒETMRåœ¨å‡å°‘è®¡ç®—å¼€é”€åŒæ—¶æå‡æ¢ç´¢å¤šæ ·æ€§ã€EARç¼“è§£æ—©æœŸä¼°è®¡åå·®çš„æ€è·¯ï¼Œå¯å¯å‘åç»­åœ¨æ— ç›‘ç£å¼ºåŒ–å­¦ä¹ ã€å¤§æ¨¡å‹æ¨ç†ä¼˜åŒ–ç­‰æ–¹å‘çš„ç ”ç©¶ï¼Œä¸ºå¼€æ”¾åŸŸæ¨ç†ä»»åŠ¡ä¸­æ— ç›‘ç£å¼ºåŒ–å­¦ä¹ çš„å‘å±•æä¾›äº†æ–°æ–¹å‘ï¼Œåœ¨å¤„ç†é«˜æˆæœ¬æ¨ç†ã€å¹³è¡¡æ¢ç´¢åˆ©ç”¨ç­‰åœºæ™¯ä¸‹å…·æœ‰å‚è€ƒä»·å€¼ã€‚

## cure--critical-token-guided-re-concatenation-for-entropy-collapse-prevention
### Abstract
Recent advances in Reinforcement Learning with Verified Reward (RLVR) have
driven the emergence of more sophisticated cognitive behaviors in large
language models (LLMs), thereby enhancing their reasoning capabilities.
However, in prior RLVR pipelines, the repeated use of static initial-state
sampling drawn exactly from the dataset distribution during each sampling phase
produced overly deterministic, low diversity model behavior, which manifested
as rapid entropy collapse and hindered sustained performance gains during
prolonged training. To address this issue, we introduce CURE
(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a
two-stage framework that balances exploration and exploitation. Specifically,
in the first stage, to deliberately steer the model toward novel yet coherent
contexts, we re-generate at high-entropy critical tokens and jointly optimize
the original and the branched trajectories. The further comparison with vanilla
DAPO shows that the regeneration process achieves a better performance on math
reasoning tasks while sustaining a high-level entropy degree for exploration.
In the second stage, we continue training with static initial-state sampling by
DAPO, intentionally placing the model in a familiar state to gradually
strengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,
compared to other RLVR methods, CURE achieves a 5% performance gain across six
math benchmarks, establishing state-of-the-art performance in both entropy and
accuracy. A series of experiments further validate the effectiveness of our
approach. Code is available at https://github.com/bytedance/CURE.
### ğŸŒŸ è®ºæ–‡è§£è¯» | CUREï¼šåº”å¯¹ç†µåç¼©ï¼Œè®©å¤§æ¨¡å‹æ¨ç†è®­ç»ƒæ›´é«˜æ•ˆ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨åŸºäºéªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰æ¨åŠ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†èƒ½åŠ›è¿›æ­¥çš„èƒŒæ™¯ä¸‹ï¼Œç°æœ‰RLVRæµç¨‹å­˜åœ¨ç¼ºé™·ï¼šè®­ç»ƒé˜¶æ®µé‡å¤ä½¿ç”¨ä»æ•°æ®é›†åˆ†å¸ƒä¸­æŠ½å–çš„é™æ€åˆå§‹çŠ¶æ€é‡‡æ ·ï¼Œå¯¼è‡´æ¨¡å‹è¡Œä¸ºè¿‡åº¦ç¡®å®šã€å¤šæ ·æ€§ä½ï¼Œå‡ºç°å¿«é€Ÿç†µåç¼©ï¼Œé˜»ç¢é•¿æœŸè®­ç»ƒä¸­æ€§èƒ½çš„æŒç»­æå‡ã€‚è§£å†³ç†µåç¼©ã€å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨æˆä¸ºå…³é”®éœ€æ±‚ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºä¸¤é˜¶æ®µæ¡†æ¶CUREå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨  
CUREåˆ†ä¸ºæ¢ç´¢ä¸»å¯¼çš„ç¬¬ä¸€é˜¶æ®µå’Œåˆ©ç”¨ä¸»å¯¼çš„ç¬¬äºŒé˜¶æ®µã€‚ç¬¬ä¸€é˜¶æ®µèšç„¦æ¢ç´¢ï¼ŒåŸºäº token çº§ç†µè¯†åˆ«å…³é”®tokenï¼ˆé«˜ç†µtokenï¼Œä»£è¡¨æ¨¡å‹å†³ç­–ä¸ç¡®å®šæ€§é«˜çš„ä½ç½®ï¼‰ï¼Œå°†å…³é”®tokenä¹‹å‰çš„å­å¥ä¸åŸå§‹æŸ¥è¯¢é‡æ–°æ‹¼æ¥å½¢æˆç²¾ç‚¼æç¤ºï¼Œè®©æ¨¡å‹åŸºäºè¿™äº›æ–°æç¤ºç”Ÿæˆå†…å®¹ï¼ŒæŠŠåŸå§‹è½¨è¿¹å’Œåˆ†æ”¯è½¨è¿¹è”åˆä¼˜åŒ–ï¼Œä»¥æ­¤å¼•å¯¼æ¨¡å‹èµ°å‘æ–°é¢–ä¸”è¿è´¯çš„ä¸Šä¸‹æ–‡ï¼Œä¸°å¯Œè®­ç»ƒä¿¡å·ï¼›ç¬¬äºŒé˜¶æ®µè½¬å‘åˆ©ç”¨ï¼Œç”¨DAPOçš„é™æ€åˆå§‹çŠ¶æ€é‡‡æ ·ç»§ç»­è®­ç»ƒï¼Œè®©æ¨¡å‹å›åˆ°ç†Ÿæ‚‰çŠ¶æ€å·©å›ºæ¢ç´¢é˜¶æ®µæˆæœï¼Œå¼ºåŒ–å‡†ç¡®è¡Œä¸ºã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šåŸºäºæ¨¡å‹å†…éƒ¨ä¸ç¡®å®šæ€§åŠ¨æ€ä¸°å¯Œè®­ç»ƒä¿¡å·  
å€ŸåŠ©è‡ªå›å½’è§£ç æ—¶è®¡ç®—çš„tokençº§ç­–ç•¥ç†µï¼Œç²¾å‡†å®šä½æ¨¡å‹å†³ç­–æœ€ä¸ç¡®å®šçš„å…³é”®tokenä½ç½®ï¼Œåœ¨è¯¥ä½ç½®å‰æˆªæ–­åºåˆ—ï¼Œä»¥æ­¤åˆ†å‰ç‚¹ç”Ÿæˆå¤šä¸ªæ›¿ä»£å»¶ç»­å†…å®¹ã€‚è¿™ç§æ–¹å¼ç²¾å‡†åˆ©ç”¨æ¨¡å‹è‡ªèº«ä¸ç¡®å®šæ€§ï¼Œæ‹“å®½åˆç†åç»­åŠ¨ä½œçš„åˆ†å¸ƒï¼Œæ—¢ç»´æŒå¥åº·ç†µå€¼åˆæå‡æœªæ¥æ¨ç†çš„é¢„æœŸå‡†ç¡®ç‡ã€‚åŒæ—¶å‚è€ƒDAPOï¼Œåªä¿ç•™åŒ…å«éªŒè¯å™¨æ¥å—å’Œæ‹’ç»ç­”æ¡ˆçš„æç¤ºæ¥æå‡è®­ç»ƒæ•ˆç‡ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨Qwen - 2.5 - Math - 7Bæ¨¡å‹ä¸Šé’ˆå¯¹å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•çš„å®éªŒæ˜¾ç¤ºï¼ŒCUREç›¸æ¯”å…¶ä»–RLVRæ–¹æ³•ï¼Œåœ¨å…­ä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•ä¸­æ€§èƒ½æå‡5%ï¼›åœ¨ç†µå€¼å’Œå‡†ç¡®ç‡ä¸Šéƒ½è¾¾åˆ°äº†å½“å‰æœ€ä¼˜æ°´å¹³ï¼Œè¯æ˜å…¶åœ¨ç»´æŒæ¢ç´¢èƒ½åŠ›ï¼ˆç†µï¼‰çš„åŒæ—¶èƒ½æå‡æ¨ç†å‡†ç¡®æ€§ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»çŠ¶æ€åˆ†å¸ƒè§†è§’åˆ†æç­–ç•¥ç†µåç¼©é—®é¢˜ï¼ŒæŒ‡æ˜å›ºå®šæ•°æ®é›†è®­ç»ƒå¯¹ç†µçš„æŠ‘åˆ¶ä½œç”¨ï¼Œå¹¶ç»™å‡ºåŸºäºå…³é”®tokenå¼•å¯¼çš„é‡æ–°æ‹¼æ¥è¿™ä¸€åŸåˆ™æ€§è§£å†³æ€è·¯ï¼Œä¸ºåç»­å¤„ç†æ¨¡å‹è®­ç»ƒä¸­ç†µç›¸å…³é—®é¢˜æä¾›äº†åˆ†æè§’åº¦å’Œæ–¹æ³•å‚è€ƒï¼›æå‡ºçš„è½»é‡ä¸¤é˜¶æ®µCUREæ¡†æ¶ï¼Œä¸ºå¹³è¡¡å¤§æ¨¡å‹è®­ç»ƒä¸­æ¢ç´¢ä¸åˆ©ç”¨å…³ç³»æä¾›äº†å¯è½åœ°çš„æ–¹æ¡ˆï¼Œåœ¨æ¨ç†ç±»ä»»åŠ¡è®­ç»ƒæµç¨‹è®¾è®¡ä¸Šæœ‰å€Ÿé‰´ä»·å€¼ï¼›å€ŸåŠ©æ¨¡å‹è‡ªèº«tokençº§ç†µæ¥åŠ¨æ€è°ƒæ•´è®­ç»ƒè¾“å…¥ï¼ˆç”Ÿæˆç²¾ç‚¼æç¤ºï¼‰çš„æ–¹å¼ï¼Œä¸ºåˆ©ç”¨æ¨¡å‹å†…éƒ¨ä¿¡å·ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹æä¾›äº†åˆ›æ–°èŒƒä¾‹ï¼Œå¯å‘åç»­åœ¨æ¨¡å‹è‡ªç›‘ç£ä¿¡å·æŒ–æ˜ä¸è®­ç»ƒæµç¨‹ç»“åˆæ–¹é¢çš„ç ”ç©¶ã€‚

## kl-based-self-distillation-for-large-language-models
### Abstract
Large pre-trained language models often struggle to incorporate new
domain-specific terminology when fine-tuned on small, specialized corpora. In
this work, we address the challenge of vocabulary expansion in frozen LLMs by
introducing a mathematically grounded method for knowledge distillation via KL
divergence, even when the original and extended models use different
tokenizations. This allows the student model to inherit distributional
knowledge from the teacher despite differing vocabularies. We compare our
KL-based distillation approach to conventional cross-entropy training,
evaluating both methods across multiple strategies for initializing new token
embeddings. After embedding initialization, models are further fine-tuned to
integrate the new vocabulary. Each trained model is benchmarked on
approximately 2000 code-generation tasks, where our approach achieves the best
performance across the board. Finally, through mechanistic interpretability, we
analyze how models learn representations for the new tokens, providing an
explanation for the observed gains and offering insight into the structure of
embedding space during vocabulary expansion.
### ğŸŒŸ è®ºæ–‡è§£è¯» | å¤§è¯­è¨€æ¨¡å‹ä¸­åŸºäºKLæ•£åº¦çš„è‡ªè’¸é¦ï¼šè§£å†³é¢†åŸŸè¯æ±‡æ‰©å±•éš¾é¢˜

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
è¿‘å¹´æ¥ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç¼–ç¨‹ç­‰é¢†åŸŸå±•ç°å¼ºå¤§èƒ½åŠ›ï¼Œä½†åœ¨é’ˆå¯¹å°è€Œä¸“ä¸šçš„è¯­æ–™å¾®è°ƒæ—¶ï¼Œå¾ˆéš¾èå…¥æ–°çš„é¢†åŸŸç‰¹å®šæœ¯è¯­ã€‚å› ä¸ºæ–°é¢†åŸŸè®­ç»ƒæ•°æ®è¿œå°äºé¢„è®­ç»ƒæ—¶çš„æµ·é‡æ•°æ®ï¼Œä¸” notation å¯èƒ½ä¸åŒï¼Œè®©æ¨¡å‹æŒæ¡æ–°ç¼–ç¨‹è¯­è¨€æˆæŒ‘æˆ˜ã€‚è€Œè¯æ±‡æ‰©å±•æ˜¯æ”¹å–„å¾®è°ƒçš„é€”å¾„ä¹‹ä¸€ï¼Œèƒ½è®©æ¨¡å‹æ›´é«˜æ•ˆå‹ç¼©æ•°æ®ã€å­¦ä¹ ç‰¹å®šè¡¨ç¤ºï¼Œä½†å¦‚ä½•ç»™é¢„è®­ç»ƒæ¨¡å‹ retroactive æ‰©å±•è¯æ±‡å¹¶æœ‰æ•ˆè®­ç»ƒæ–° token æ˜¯å…³é”®é—®é¢˜ï¼Œæœ¬æ–‡å°±æ­¤å±•å¼€ç ”ç©¶ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šåŸºäºKLæ•£åº¦çš„çŸ¥è¯†è’¸é¦æ–¹æ³•  
æå‡ºæ•°å­¦ä¸Šåˆç†çš„åŸºäº KL æ•£åº¦çš„çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼Œè§£å†³å†»ç»“LLMsçš„è¯æ±‡æ‰©å±•æŒ‘æˆ˜ã€‚å³ä¾¿åŸå§‹æ¨¡å‹å’Œæ‰©å±•åæ¨¡å‹tokenizationä¸åŒï¼Œä¹Ÿèƒ½è®©å­¦ç”Ÿæ¨¡å‹ï¼ˆæ‰©å±•è¯æ±‡åçš„æ¨¡å‹ï¼‰ä»æ•™å¸ˆæ¨¡å‹ï¼ˆåŸé¢„è®­ç»ƒæ¨¡å‹ï¼‰ç»§æ‰¿åˆ†å¸ƒçŸ¥è¯†ï¼Œè®©æ–°åµŒå…¥æ›´å¥½èå…¥é¢„è®­ç»ƒæ¨¡å‹ç»“æ„ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¤šç­–ç•¥åµŒå…¥åˆå§‹åŒ–ä¸å¯¹æ¯”å®éªŒ  
å°†åŸºäºKLæ•£åº¦çš„è’¸é¦æ–¹æ³•å’Œä¼ ç»Ÿäº¤å‰ç†µè®­ç»ƒå¯¹æ¯”ï¼Œåœ¨å¤šç§æ–°tokenåµŒå…¥åˆå§‹åŒ–ç­–ç•¥ä¸‹è¯„ä¼°ã€‚åµŒå…¥åˆå§‹åŒ–åå†å¾®è°ƒæ•´åˆæ–°è¯æ±‡ï¼Œæ¢ç´¢æ€æ ·åˆå§‹åŒ–æ–°ç»„ä»¶ï¼ˆæ–°åµŒå…¥ç­‰ï¼‰èƒ½è®©æ¨¡å‹è¡¨ç°æ›´å¥½ï¼Œæ·±å…¥ç ”ç©¶åµŒå…¥ç‰¹å¾å¯¹æ€§èƒ½çš„å½±å“ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹3ï¼š mechanistic interpretability åˆ†æ  
é€šè¿‡æœºæ¢°å¯è§£é‡Šæ€§åˆ†ææ¨¡å‹å¦‚ä½•å­¦ä¹ æ–°tokenè¡¨ç¤ºï¼Œè§£é‡Šæ€§èƒ½æå‡åŸå› ï¼Œæ´å¯Ÿè¯æ±‡æ‰©å±•æ—¶åµŒå…¥ç©ºé—´ç»“æ„ï¼Œä»åŸç†å±‚é¢å‰–ææ¨¡å‹å¯¹æ–°tokençš„å­¦ä¹ è¿‡ç¨‹ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨çº¦2000ä¸ªä»£ç ç”Ÿæˆä»»åŠ¡åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨å„æ–¹é¢éƒ½å®ç°æœ€ä½³æ€§èƒ½ã€‚åŒæ—¶å¯¹è®­ç»ƒå„é˜¶æ®µï¼ˆæ–°æ¨¡å—è®­ç»ƒã€ä¸åŒå¾®è°ƒæ–¹å¼ä¸‹çš„è®­ç»ƒç­‰ï¼‰è¿›è¡Œåˆ†æï¼Œå¯¹æ¯”ä¸åŒè®­ç»ƒè®¾ç½®ï¼ˆå¦‚LoRAå¾®è°ƒä¸å…¨é‡å¾®è°ƒç­‰ï¼‰ä¸‹çš„ç»“æœï¼ŒéªŒè¯äº†æ–¹æ³•åœ¨è¯æ±‡æ‰©å±•ä¸æ¨¡å‹æ€§èƒ½æå‡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. è¯æ±‡æ‰©å±•ä¸çŸ¥è¯†è’¸é¦ç»“åˆï¼šä¸ºé¢„è®­ç»ƒå¤§æ¨¡å‹ retroactive æ‰©å±•è¯æ±‡æä¾›äº†åŸºäºKLæ•£åº¦è’¸é¦çš„å¯è¡Œæ€è·¯ï¼Œåœ¨å¤„ç†é¢†åŸŸç‰¹å®šè¯æ±‡èå…¥éš¾é¢˜æ—¶æœ‰å‚è€ƒä»·å€¼ã€‚  
2. å¤šç­–ç•¥å¯¹æ¯”ä¸åµŒå…¥ç ”ç©¶ï¼šé€šè¿‡å¤šç§åµŒå…¥åˆå§‹åŒ–ç­–ç•¥å¯¹æ¯”å’Œå¯¹åµŒå…¥ç©ºé—´çš„åˆ†æï¼Œè®©ä»ä¸šè€…äº†è§£åµŒå…¥ç‰¹å¾å¯¹æ¨¡å‹æ€§èƒ½å½±å“ï¼Œåœ¨æ¨¡å‹å¾®è°ƒã€æ–°ç»„ä»¶åˆå§‹åŒ–æ—¶å¯å€Ÿé‰´å…¶æ€è·¯æ¢ç´¢æ›´ä¼˜æ–¹å¼ã€‚  
3. æœºæ¢°å¯è§£é‡Šæ€§åº”ç”¨ï¼šå€ŸåŠ©æœºæ¢°å¯è§£é‡Šæ€§åˆ†ææ¨¡å‹å¯¹æ–°tokençš„å­¦ä¹ ï¼Œè¿™ç§ä»åŸç†å±‚é¢å‰–ææ¨¡å‹è¡Œä¸ºçš„æ–¹å¼ï¼Œèƒ½æŒ‡å¯¼åç»­æ¨¡å‹æ”¹è¿›ä¸ä¼˜åŒ–ï¼Œç†è§£æ¨¡å‹å†…éƒ¨è¿ä½œæœºåˆ¶ã€‚

## prompt-response-semantic-divergence-metrics-for-faithfulness-hallucination-and-misalignment-detection-in-large-language-models
### Abstract
The proliferation of Large Language Models (LLMs) is challenged by
hallucinations, critical failure modes where models generate non-factual,
nonsensical or unfaithful text. This paper introduces Semantic Divergence
Metrics (SDM), a novel lightweight framework for detecting Faithfulness
Hallucinations -- events of severe deviations of LLMs responses from input
contexts. We focus on a specific implementation of these LLM errors,
{confabulations, defined as responses that are arbitrary and semantically
misaligned with the user's query. Existing methods like Semantic Entropy test
for arbitrariness by measuring the diversity of answers to a single, fixed
prompt. Our SDM framework improves upon this by being more prompt-aware: we
test for a deeper form of arbitrariness by measuring response consistency not
only across multiple answers but also across multiple, semantically-equivalent
paraphrases of the original prompt. Methodologically, our approach uses joint
clustering on sentence embeddings to create a shared topic space for prompts
and answers. A heatmap of topic co-occurances between prompts and responses can
be viewed as a quantified two-dimensional visualization of the user-machine
dialogue. We then compute a suite of information-theoretic metrics to measure
the semantic divergence between prompts and responses. Our practical score,
$\mathcal{S}_H$, combines the Jensen-Shannon divergence and Wasserstein
distance to quantify this divergence, with a high score indicating a
Faithfulness hallucination. Furthermore, we identify the KL divergence
KL(Answer $||$ Prompt) as a powerful indicator of \textbf{Semantic
Exploration}, a key signal for distinguishing different generative behaviors.
These metrics are further combined into the Semantic Box, a diagnostic
framework for classifying LLM response types, including the dangerous,
confident confabulation.
### ğŸŒŸ è®ºæ–‡è§£è¯» | å¤§è¯­è¨€æ¨¡å‹ä¸­äº‹å®æ€§å¹»è§‰ä¸é”™ä½æ£€æµ‹çš„è¯­ä¹‰åˆ†æ­§åº¦é‡æ–¹æ³•

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆç±»äººæ–‡æœ¬æ–¹é¢èƒ½åŠ›å“è¶Šï¼Œä½†å¹»è§‰é—®é¢˜ï¼ˆç”Ÿæˆéäº‹å®ã€æ— æ„ä¹‰æˆ–ä¸å¿ å®æ–‡æœ¬ï¼‰ä¸¥é‡å½±å“å…¶å¯é æ€§ã€‚å…¶ä¸­ï¼Œå†…åœ¨äº‹å®æ€§å¹»è§‰ï¼ˆä¸è¾“å…¥ä¸Šä¸‹æ–‡çŸ›ç›¾ï¼‰æ˜¯å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰å¦‚è¯­ä¹‰ç†µï¼ˆSemantic Entropyï¼ŒSEï¼‰çš„æ–¹æ³•å­˜åœ¨ä¸è¶³ï¼šå¯¹æç¤ºï¼ˆpromptï¼‰æ„ŸçŸ¥ä¸è¶³ï¼Œä»…é€šè¿‡å›ºå®šæç¤ºçš„å¤šè½®å›ç­”å¤šæ ·æ€§æµ‹ä»»æ„æ€§ï¼Œæœªå……åˆ†åˆ©ç”¨æç¤ºä¿¡æ¯ï¼Œå¯èƒ½è¯¯åˆ¤åˆç†å¤æ‚å›ç­”ä¸ºå¹»è§‰ã€‚æœ¬æ–‡èšç„¦æ£€æµ‹å†…åœ¨äº‹å®æ€§å¹»è§‰ï¼Œå°†å…¶ä¸â€œè™šæ„ï¼ˆconfabulationï¼‰â€å…³è”ï¼ŒæŠŠè™šæ„å®šä¹‰ä¸ºç›¸å¯¹äºè¾“å…¥ä¸Šä¸‹æ–‡å›ç­”ä¸æ­£ç¡®ä¸”ä»»æ„ï¼Œæ—¨åœ¨æå‡ºæ›´é²æ£’ã€æ„ŸçŸ¥æç¤ºçš„æ–¹æ³•é‡åŒ–è¯­ä¹‰å¯¹é½åº¦ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºè¯­ä¹‰åˆ†æ­§åº¦é‡ï¼ˆSemantic Divergence Metricsï¼ŒSDMï¼‰æ¡†æ¶  
SDMæ›´æ„ŸçŸ¥æç¤ºï¼Œé€šè¿‡å¯¹è¯­ä¹‰ç­‰ä»·çš„å¤šä¸ªè½¬è¿°æç¤ºç”Ÿæˆå›ç­”ï¼Œæ›´æ·±åº¦æ£€æµ‹å›ç­”ä»»æ„æ€§ã€‚ä¸å†å±€é™äºå•ä¸€å›ºå®šæç¤ºï¼Œè€Œæ˜¯åˆ©ç”¨å¤šä¸ªè¯­ä¹‰ç­‰ä»·çš„æç¤º paraphrase æ¥æ¢æµ‹å›ç­”çš„ç¨³å®šæ€§ï¼Œä»¥æ­¤æ›´å…¨é¢åœ°åˆ¤æ–­å›ç­”æ˜¯å¦å­˜åœ¨â€œä»»æ„æ€§â€è¿™ä¸€è™šæ„ç‰¹å¾ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šåŸºäºè”åˆèšç±»ä¸ä¿¡æ¯è®ºåº¦é‡é‡åŒ–è¯­ä¹‰åˆ†æ­§  
å…ˆå¯¹å¥å­åµŒå…¥åšè”åˆèšç±»ï¼Œä¸ºæç¤ºå’Œå›ç­”æ„å»ºå…±äº«ä¸»é¢˜ç©ºé—´ï¼Œç”Ÿæˆæç¤º - å›ç­”ä¸»é¢˜å…±ç°çƒ­å›¾ï¼ˆå¯è§†åŒ–ä¸ºç”¨æˆ· - æœºå™¨å¯¹è¯çš„é‡åŒ–äºŒç»´è§†å›¾ï¼‰ã€‚å†è®¡ç®—ä¸€ç³»åˆ—ä¿¡æ¯è®ºåº¦é‡æµ‹è¯­ä¹‰åˆ†æ­§ï¼šå®ç”¨åˆ†æ•° $\mathcal{S}_H$ ç»“åˆ Jensen - Shannon æ•£åº¦å’Œ Wasserstein è·ç¦»é‡åŒ–åˆ†æ­§ï¼Œé«˜åˆ†è¡¨ç¤ºäº‹å®æ€§å¹»è§‰ï¼›è¯†åˆ« KL æ•£åº¦ KL(Answer || Prompt) ä¸ºâ€œè¯­ä¹‰æ¢ç´¢â€çš„æœ‰åŠ›æŒ‡æ ‡ï¼ŒåŒºåˆ†ä¸åŒç”Ÿæˆè¡Œä¸ºã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šæ„å»º Semantic Box è¯Šæ–­æ¡†æ¶  
å°†ä¸Šè¿°åº¦é‡ç»“åˆï¼Œå½¢æˆ Semantic Box è¿™ä¸€è¯Šæ–­æ¡†æ¶ï¼Œç”¨äºåˆ†ç±» LLM å“åº”ç±»å‹ï¼Œæ¶µç›–å±é™©çš„â€œè‡ªä¿¡è™šæ„â€ç­‰æƒ…å†µï¼Œä¸ºåˆ†æ LLM è¡Œä¸ºæä¾›å…¨é¢å·¥å…·ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
æ–‡ä¸­é€šè¿‡å—æ§å®éªŒè¡¨æ˜æ¡†æ¶èƒ½æˆåŠŸåŒºåˆ†ä¸åŒå“åº”ç±»å‹ï¼›å€ŸåŠ©è§†è§‰çƒ­å›¾åˆ†ææ­ç¤ºä¸åŒå¯¹é½ç­–ç•¥çš„ç‹¬ç‰¹è§†è§‰ç‰¹å¾ï¼ŒéªŒè¯äº†æ–¹æ³•åœ¨åˆ†æ prompt - answer è¯­ä¹‰å…³è”ä¸åŒºåˆ†å“åº”æ¨¡å¼ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜ SDM èƒ½ä¸º LLM å¯é æ€§å…³é”®ç»´åº¦ï¼ˆä¸ç”¨æˆ·æŸ¥è¯¢è¯­ä¹‰å¯¹é½èƒ½åŠ›ï¼‰æä¾›é‡åŒ–æµ‹é‡æ–¹å¼ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. æç¤ºæ„ŸçŸ¥çš„æ€è·¯ï¼šåœ¨æ£€æµ‹æ¨¡å‹è¾“å‡ºé—®é¢˜æ—¶ï¼Œå……åˆ†è€ƒè™‘è¾“å…¥æç¤ºçš„è¯­ä¹‰ä¿¡æ¯ä¸å¤šæ ·è¡¨è¿°ï¼Œé¿å…å•ä¸€å›ºå®šè§†è§’çš„å±€é™ï¼Œä¸ºç±»ä¼¼éœ€ç»“åˆè¾“å…¥ä¸Šä¸‹æ–‡æ·±åº¦åˆ†æçš„ä»»åŠ¡æä¾›æ€è·¯ã€‚  
2. è”åˆåµŒå…¥èšç±» + ä¿¡æ¯è®ºåº¦é‡çš„æŠ€æœ¯è·¯çº¿ï¼šå°†è¯­ä¹‰è¡¨ç¤ºèšç±»ä¸ç»å…¸ä¿¡æ¯è®ºå·¥å…·ç»“åˆï¼Œä¸ºé‡åŒ–è¯­ä¹‰å±‚é¢çš„å¯¹é½æˆ–åˆ†æ­§æä¾›äº†å¯å¤ç”¨çš„æŠ€æœ¯èŒƒå¼ï¼Œå¯è¿ç§»åˆ°æ–‡æœ¬è¯­ä¹‰åŒ¹é…ã€å¯¹è¯è´¨é‡è¯„ä¼°ç­‰ä»»åŠ¡ã€‚  
3. è¯Šæ–­æ¡†æ¶æ„å»ºï¼šæŠŠå¤šä¸ªåº¦é‡æ•´åˆæˆç»Ÿä¸€æ¡†æ¶æ¥åˆ†ç±»æ¨¡å‹è¡Œä¸ºï¼Œè¿™ç§ä»å•ä¸€æŒ‡æ ‡åˆ°ä½“ç³»åŒ–åˆ†æå·¥å…·çš„æ€è·¯ï¼Œæœ‰åŠ©äºæ›´å…¨é¢ç†è§£æ¨¡å‹è¾“å‡ºæ¨¡å¼ï¼Œåœ¨æ¨¡å‹è¯„ä¼°ã€è°ƒè¯•ç­‰ç¯èŠ‚æœ‰å€Ÿé‰´ä»·å€¼ã€‚

## provable-in-context-vector-arithmetic-via-retrieving-task-concepts
### Abstract
In-context learning (ICL) has garnered significant attention for its ability
to grasp functions/tasks from demonstrations. Recent studies suggest the
presence of a latent task/function vector in LLMs during ICL. Merullo et al.
(2024) showed that LLMs leverage this vector alongside the residual stream for
Word2Vec-like vector arithmetic, solving factual-recall ICL tasks.
Additionally, recent work empirically highlighted the key role of
Question-Answer data in enhancing factual-recall capabilities. Despite these
insights, a theoretical explanation remains elusive. To move one step forward,
we propose a theoretical framework building on empirically grounded
hierarchical concept modeling. We develop an optimization theory, showing how
nonlinear residual transformers trained via gradient descent on cross-entropy
loss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss
convergence and show the strong generalization, including robustness to concept
recombination and distribution shifts. These results elucidate the advantages
of transformers over static embedding predecessors. Empirical simulations
corroborate our theoretical insights.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ä»ä»»åŠ¡æ¦‚å¿µæ£€ç´¢è§†è§’ä¸ºä¸Šä¸‹æ–‡å‘é‡ç®—æœ¯æä¾›å¯è¯æ˜æ€§

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åŸºäºTransformerçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ä¸­å±•ç°å‡ºä»ç¤ºä¾‹ä¸­æŒæ¡ä»»åŠ¡/å‡½æ•°çš„èƒ½åŠ›ï¼Œç„¶è€Œå…¶èƒŒåçš„ç†è®ºè§£é‡Šä»ä¸æ¸…æ™°ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶å‘ç°ICLè¿‡ç¨‹ä¸­LLMså­˜åœ¨æ½œåœ¨ä»»åŠ¡/å‡½æ•°å‘é‡ï¼Œä¸”é—®ç­”ï¼ˆQAï¼‰æ•°æ®å¯¹å¢å¼ºäº‹å®å›å¿†èƒ½åŠ›å¾ˆå…³é”®ï¼Œä½†ç¼ºä¹ç†è®ºæ¡†æ¶é˜è¿°éçº¿æ€§æ®‹å·®Transformerå¦‚ä½•åŸºäºäº¤å‰ç†µæŸå¤±æ¢¯åº¦ä¸‹é™è®­ç»ƒæ¥å®Œæˆäº‹å®å›å¿†ICLä»»åŠ¡ï¼Œä»¥åŠTransformerç›¸è¾ƒWord2Vecç­‰é™æ€åµŒå…¥å‰è¾ˆçš„ä¼˜åŠ¿ä¹Ÿæœªæ˜ç¡®ã€‚åŒæ—¶ï¼Œç°æœ‰ICLç†è®ºå¯¹æ®‹å·®é¡¹å¤„ç†ä¸è¶³ï¼Œä¹Ÿæ²¡æœ‰ç†è®ºæ”¯æ’‘QAæ•°æ®å¯¹äº‹å®å›å¿†ICLçš„ä½œç”¨ï¼Œè¿™äº›éƒ½æ„æˆäº†ç ”ç©¶å¾…è§£å†³çš„é—®é¢˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ„å»ºä¼˜åŒ–ç†è®ºé˜é‡Šå‘é‡ç®—æœ¯å¼ICL  
æå‡ºåŸºäºå®è¯é©±åŠ¨çš„åˆ†å±‚æ¦‚å¿µå»ºæ¨¡çš„ç†è®ºæ¡†æ¶ï¼Œè¯æ˜å¸¦æœ‰éçº¿æ€§softmaxæ³¨æ„åŠ›ã€MLPã€å±‚å½’ä¸€åŒ–å’Œæ®‹å·®è¿æ¥çš„Transformerï¼Œåœ¨é€šè¿‡æ¢¯åº¦ä¸‹é™ï¼ˆGDï¼‰ä»¥äº¤å‰ç†µæŸå¤±è®­ç»ƒæ—¶ï¼Œèƒ½æœ‰æ•ˆä»¥å‘é‡ç®—æœ¯æ–¹å¼æ‰§è¡Œäº‹å®å›å¿†ICLä»»åŠ¡ã€‚åˆ†æè¡¨æ˜Transformeré€šè¿‡æ³¨æ„åŠ› - MLPæ£€ç´¢é«˜å±‚ä»»åŠ¡/å‡½æ•°æ¦‚å¿µï¼Œç»“åˆåŒé«˜å±‚ä»»åŠ¡æ¦‚å¿µå†…çš„æŸ¥è¯¢å‘é‡å¾—åˆ°æ­£ç¡®ç­”æ¡ˆå‘é‡ï¼Œè¿˜ç¡®å®šäº†ä¼˜åŒ–åŠ¨åŠ›å­¦çš„æ¸è¿‘è¡Œä¸ºå¹¶è¯æ˜ICLæµ‹è¯•æŸå¤±çš„æ”¶æ•›æ€§ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæ˜ç¡®QAä¸ICLæ•°æ®è®­ç»ƒåœºæ™¯å·®å¼‚  
åœ¨åˆ†å±‚æ¦‚å¿µå»ºæ¨¡æ¡†æ¶ä¸‹ï¼ŒåŒºåˆ†äº†QAæ•°æ®è®­ç»ƒå’Œè¯ - æ ‡ç­¾ç¤ºä¾‹å¯¹ICLæ•°æ®è®­ç»ƒåœºæ™¯ã€‚æ­¤å‰ç†è®ºå·¥ä½œå‡è®¾åœ¨è¯ - æ ‡ç­¾å¯¹ICLæ•°æ®ä¸ŠåŒæ—¶è®­ç»ƒå’Œæµ‹è¯•å­˜åœ¨ç¼ºé™·ï¼Œä¼šå¯¼è‡´æ— æ³•æ£€ç´¢é«˜å±‚ä»»åŠ¡å‘é‡è€Œé™·å…¥ä½å±‚æ¬¡ç‰¹å¾è®°å¿†ï¼›è€Œæœ¬æ–‡è¯æ˜åœ¨QAæ•°æ®ä¸Šè®­ç»ƒèƒ½è®©æ¨¡å‹æœ‰æ•ˆå­¦ä¹ ä»»åŠ¡å‘é‡ï¼Œåœ¨è¯ - æ ‡ç­¾å¯¹ICLæˆ–QA - ICLåˆ†å¸ƒæµ‹è¯•æ—¶å®ç°æå°è¯¯å·®ã€‚

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šæä¾›ç»„åˆæ³›åŒ–ç†è®ºä¿éšœ  
èšç„¦ä»»åŠ¡å‘é‡æ¶Œç°å’Œåˆ†å¸ƒå¤–ï¼ˆOODï¼‰é²æ£’æ€§ï¼Œä¸ºä¸Šä¸‹æ–‡å­¦ä¹ ç»„åˆæ³›åŒ–æä¾›ç†è®ºä¿è¯ã€‚ä¸€æ–¹é¢Transformerèƒ½ç›´æ¥ä»ç¤ºä¾‹å¯¹å›å½’ä»»åŠ¡å‘é‡ï¼Œæµ‹è¯•æ—¶é€šè¿‡ç®—æœ¯æ“ä½œç»„åˆåº”ç”¨è¿™äº›å‘é‡ï¼›å¦ä¸€æ–¹é¢åœ¨ç»“æ„åŒ–QAæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œèƒ½åˆ©ç”¨å­¦ä¹ åˆ°çš„é«˜å±‚ä»»åŠ¡å‘é‡çš„åœ†é”¥ç»„åˆå’Œæ–°çš„æ­£äº¤ç‰¹å¾ï¼Œæ³›åŒ–åˆ°æœªè§è¿‡çš„ä»»åŠ¡æç¤ºæˆ–å­—å…¸ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
æ–‡ä¸­è™½æœªè¯¦ç»†å±•å¼€å®éªŒç»“æœå‘ˆç°ï¼Œä½†æåˆ°é€šè¿‡å®è¯æ¨¡æ‹Ÿä½è¯äº†ç†è®ºè§è§£ï¼Œè¯´æ˜åŸºäºæ‰€æç†è®ºæ¡†æ¶çš„ç›¸å…³æ¨¡æ‹Ÿå®éªŒèƒ½å¤Ÿæ”¯æ’‘ç†è®ºå±‚é¢å…³äºTransformeræ‰§è¡ŒICLä»»åŠ¡æ–¹å¼ã€QAæ•°æ®è®­ç»ƒä½œç”¨ä»¥åŠç»„åˆæ³›åŒ–èƒ½åŠ›ç­‰æ–¹é¢çš„ç»“è®ºã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»ç†è®ºå±‚é¢ä¸ºä¸Šä¸‹æ–‡å­¦ä¹ ä¸­ä»»åŠ¡å‘é‡æœºåˆ¶ã€Transformerä¼˜åŠ¿ç­‰é•¿æœŸæ¨¡ç³Šçš„é—®é¢˜æä¾›äº†é˜é‡Šï¼Œæœ‰åŠ©äºåç»­ç ”ç©¶æ›´æ·±å…¥ç†è§£LLMsçš„ICLèƒ½åŠ›æœ¬è´¨ï¼›åŒºåˆ†ä¸åŒæ•°æ®è®­ç»ƒåœºæ™¯çš„æ€è·¯ï¼Œä¸ºæ¨¡å‹è®­ç»ƒæ•°æ®é€‰æ‹©å’Œè®¾è®¡æä¾›äº†æŒ‡å¯¼ï¼Œèƒ½å¸®åŠ©é¿å…æ— æ•ˆè®­ç»ƒæ–¹å¼ï¼ˆå¦‚é”™è¯¯çš„è¯ - æ ‡ç­¾å¯¹ICLæ•°æ®è®­ç»ƒå¯¼è‡´çš„ä½å±‚æ¬¡è®°å¿†é—®é¢˜ï¼‰ï¼›å…³äºç»„åˆæ³›åŒ–çš„ç†è®ºä¿éšœï¼Œä¸ºæå‡æ¨¡å‹åœ¨æœªè§è¿‡ä»»åŠ¡å’Œåˆ†å¸ƒå¤–åœºæ™¯çš„é²æ£’æ€§æä¾›äº†ç†è®ºä¾æ®å’Œæ–¹å‘ï¼Œåç»­åœ¨æ„å»ºæ›´å…·æ³›åŒ–èƒ½åŠ›çš„å¤§æ¨¡å‹æ—¶å¯å€Ÿé‰´è¯¥æ€è·¯æ¥è®¾è®¡è®­ç»ƒå’Œæ¨ç†ç­–ç•¥ã€‚

## trapping--chaos-and-averaging-in-bubbling-ads-spaces
### Abstract
We discuss chaos and ensemble averaging in 1/2 BPS bubbling $AdS$ spaces of
Lin, Lunin and Maldacena (LLM) by studying trapped and escaping null geodesics
and estimating their decay rates. We find typical chaotic scattering behavior
and confirm the Pesin relation between escape rates, Lyapunov exponents and
Kolmogorov-Sinai entropy. On the other hand, for geodesics in coarse-grained
(grayscale) LLM geometries (which exhibit a naked singularity) chaos is
strongly suppressed, which is consistent with orbits and escape rates averaged
over microscopic backgrounds. Also the singularities in these grayscale
geometries produce an attractive potential and have some similarities to black
hole throats trapping geodesics for a long time. Overall, averaging over the
ensembles of LLM geometries brings us closer toward the typical behavior of
geodesics in black hole backgrounds, but some important differences remain, in
particular the existence of a threshold timescale when the averaging fails.
### ğŸŒŸ è®ºæ–‡è§£è¯» | æ¢ç´¢LLMæ°”æ³¡AdSç©ºé—´ä¸­çš„æ··æ²Œã€æ•è·ä¸å¹³å‡æ•ˆåº”

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
LLMï¼ˆLin, Lunin and Maldacenaï¼‰æ„é€ çš„1/2 BPSæ°”æ³¡AdSç©ºé—´æ˜¯ç ”ç©¶æ— è§†ç•Œã€æ— å¥‡ç‚¹çš„å…‰æ»‘å‡ ä½•å¾®è§‚ç‰©ç†çš„ç†æƒ³å¹³å°ï¼Œå…¶ä¸é»‘æ´æœ‰ä¸€å®šç›¸ä¼¼æ€§å´åˆå­˜åœ¨æœ¬è´¨åŒºåˆ«ï¼ˆå¦‚æ— è§†ç•Œã€å¯¹åº”1/2 BPSæ€ç­‰ï¼‰ã€‚åŒæ—¶ï¼Œé»‘æ´ç‰©ç†ä¸­ geodesic è¿åŠ¨çš„å¯ç§¯æ€§ä¸å¾®è§‚æ€å‡ ä½•ä¸­ geodesic è¿åŠ¨çš„éå¯ç§¯æ€§å½¢æˆå¯¹æ¯”ï¼Œä¸”â€œå¹³å‡åŒ–â€åœ¨å¼•åŠ›ä¸å¾®è§‚æ€å‡ ä½•ç ”ç©¶ä¸­æ˜¯å…³é”®é—®é¢˜ï¼ˆå¦‚ç²—ç²’åŒ–çš„ grayscale LLM å‡ ä½•å¯¹åº”è£¸å¥‡ç‚¹ï¼Œå¯ç†è§£ä¸ºå¯¹é»‘ç™½å¾®è§‚å›¾æ¡ˆçš„ç³»ç»¼å¹³å‡ï¼‰ã€‚æœ¬æ–‡åŠ¨æœºåœ¨äºé€šè¿‡ç ”ç©¶LLMç©ºé—´ä¸­æŸç¼šä¸é€ƒé€¸ç±»é›¶æµ‹åœ°çº¿åŠå…¶è¡°å‡ç‡ï¼Œæ¢ç´¢æ··æ²Œã€ç³»ç»¼å¹³å‡åœ¨å…¶ä¸­çš„è¡¨ç°ï¼Œä»¥ç†è§£å¾®è§‚æ€å‡ ä½•ä¸é»‘æ´ç‰©ç†çš„è”ç³»å’ŒåŒºåˆ«ï¼Œæ„å»ºé€‚ç”¨äºæœ‰æ— çƒ­è§†ç•Œåœºæ™¯çš„å…¨æ¯æ··æ²Œå­—å…¸ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šèšç„¦LLMç©ºé—´é›¶æµ‹åœ°çº¿ç ”ç©¶æ··æ²Œä¸å¹³å‡  
é€šè¿‡åˆ†æLLMå‡ ä½•ä¸­æŸç¼šå’Œé€ƒé€¸çš„é›¶æµ‹åœ°çº¿ï¼Œæ¢ç©¶æ··æ²Œæ•£å°„è¡Œä¸ºä¸ Pesin å…³ç³»ï¼ˆé€ƒé€¸ç‡ã€Lyapunov æŒ‡æ•°å’Œ Kolmogorov - Sinai ç†µä¹‹é—´çš„å…³ç³»ï¼‰ï¼Œæ˜ç¡®å…¸å‹æ··æ²Œæ•£å°„ç‰¹å¾ï¼ŒéªŒè¯äº†è¯¥å…³ç³»åœ¨LLMç©ºé—´çš„é€‚ç”¨æ€§ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¯¹æ¯”ç²—ç²’åŒ–ï¼ˆgrayscaleï¼‰LLMå‡ ä½•çš„æµ‹åœ°çº¿è¡Œä¸º  
ç ”ç©¶å‘ˆç°è£¸å¥‡ç‚¹çš„ç²—ç²’åŒ–LLMå‡ ä½•ä¸­æµ‹åœ°çº¿ï¼Œå‘ç°å…¶æ··æ²Œè¢«å¼ºçƒˆæŠ‘åˆ¶ï¼Œè¿™ä¸å¾®è§‚èƒŒæ™¯å¹³å‡åçš„è½¨é“å’Œé€ƒé€¸ç‡ä¸€è‡´ï¼›ä¸”æ­¤ç±»å‡ ä½•ä¸­å¥‡ç‚¹äº§ç”Ÿå¸å¼•åŠ¿ï¼Œç±»ä¼¼é»‘æ´å–‰é•¿æ—¶é—´æ•è·æµ‹åœ°çº¿ï¼Œä»å¹³å‡åŒ–è§†è§’è¿æ¥å¾®è§‚æ€ä¸é»‘æ´èƒŒæ™¯æµ‹åœ°çº¿è¡Œä¸ºã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šè·¨ç»´åº¦æ¢ç´¢LLMå¹³é¢å¤–æµ‹åœ°çº¿è¿åŠ¨  
ä»¥å¾€éƒ¨åˆ†LLMå¹³é¢å†…æµ‹åœ°çº¿åœ¨åŠ æ—‹è½¬å¯¹ç§°é™åˆ¶åå¯ç§¯ï¼Œæœ¬æ–‡ç ”ç©¶å¹³é¢å¤–æµ‹åœ°çº¿è¿åŠ¨ï¼Œå³ä¾¿å¹³é¢å†…å¯ç§¯åœºæ™¯ä¸‹ä»æ˜ç¡®å‘ç°æ··æ²Œï¼Œå®Œå–„äº†LLMç©ºé—´æµ‹åœ°çº¿æ··æ²Œç ”ç©¶çš„ç»´åº¦è¦†ç›–ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨æ™®é€šLLMå‡ ä½•ä¸­ï¼Œé›¶æµ‹åœ°çº¿å±•ç°å…¸å‹æ··æ²Œæ•£å°„è¡Œä¸ºï¼ŒPesin å…³ç³»ï¼ˆé€ƒé€¸ç‡ã€Lyapunov æŒ‡æ•°å’Œ Kolmogorov - Sinai ç†µå…³è”ï¼‰å¾—åˆ°ç¡®è®¤ï¼›è€Œåœ¨ç²—ç²’åŒ– grayscale LLM å‡ ä½•ä¸­ï¼Œæ··æ²Œè¢«æ˜¾è‘—æŠ‘åˆ¶ï¼Œç¬¦åˆå¾®è§‚èƒŒæ™¯ç³»ç»¼å¹³å‡é¢„æœŸï¼Œä¸”å¥‡ç‚¹çš„å¸å¼•åŠ¿ä½¿æµ‹åœ°çº¿æ•è·ç‰¹æ€§è¶‹è¿‘é»‘æ´å–‰ï¼›ç³»ç»¼å¹³å‡è™½è®©LLMå‡ ä½•æµ‹åœ°çº¿è¡Œä¸ºæ›´æ¥è¿‘é»‘æ´èƒŒæ™¯ï¼Œä½†å­˜åœ¨å¹³å‡å¤±æ•ˆçš„é˜ˆå€¼æ—¶é—´å°ºåº¦ç­‰å…³é”®å·®å¼‚ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»ç ”ç©¶å¯¹è±¡çœ‹ï¼Œå°†LLMæ°”æ³¡AdSç©ºé—´ä½œä¸ºå¾®è§‚å…‰æ»‘å‡ ä½•ä¸é»‘æ´ç‰©ç†çš„æ¡¥æ¢ï¼Œä¸ºæ¢ç´¢å¾®è§‚æ€å‡ ä½•å‘é»‘æ´è¿‘ä¼¼æä¾›äº†å…·ä½“è½½ä½“ä¸åˆ†æèŒƒå¼ï¼›ä»æ–¹æ³•ä¸Šï¼Œé€šè¿‡æµ‹åœ°çº¿ï¼ˆå°¤å…¶æ˜¯é›¶æµ‹åœ°çº¿ï¼‰çš„æŸç¼šã€é€ƒé€¸åŠæ··æ²Œç‰¹æ€§åˆ†æï¼Œç»“åˆç³»ç»¼å¹³å‡ï¼ˆç²—ç²’åŒ–ï¼‰æ‰‹æ®µï¼Œä¸ºç ”ç©¶å¼•åŠ›ä¸­å¹³å‡åŒ–æ•ˆåº”ä¸å‡ ä½• - é‡å­å¯¹åº”æä¾›äº†å¯å¤ç”¨çš„æŠ€æœ¯è·¯çº¿ï¼›ä»ç»“è®ºä»·å€¼çœ‹ï¼Œæ˜ç¡®äº†å¾®è§‚æ€å‡ ä½•æ··æ²Œä¸é»‘æ´å¯ç§¯/æ··æ²Œç‰¹æ€§çš„è”ç³»ä¸åŒºåˆ«ï¼Œä¸ºæ„å»ºå…¨æ¯æ··æ²Œç†è®ºï¼ˆæ— è®ºæœ‰æ— çƒ­è§†ç•Œï¼‰æä¾›äº†å…³é”®å®éªŒï¼ˆç†è®ºåˆ†æï¼‰ä¾æ®ï¼Œå¯å‘åç»­å¯¹é»‘æ´ä½œä¸ºç³»ç»¼å¹³å‡å¯¹è±¡åŠå¾®è§‚æ€å‡ ä½•ç‰©ç†æœ¬è´¨çš„æ·±å…¥æ¢ç´¢ã€‚

## slow-tuning-and-low-entropy-masking-for-safe-chain-of-thought-distillation
### Abstract
Previous chain-of-thought (CoT) distillation methods primarily focused on
enhancing the reasoning capabilities of Small Language Models (SLMs) by
utilizing high-quality rationales generated by powerful Large Language Models
(LLMs, e.g., GPT-4). However, few works have noted the negative effects on SLM
safety brought by the training, which are revealed in this study. Although
there are works on safety alignment that fine-tune language models or
manipulate model weights to defend against harmful inputs, they require extra
computation or annotated data, and probably impact the reasoning ability of
SLMs. In this paper, we investigate how to maintain the safety of SLMs during
the CoT distillation process. Specifically, we propose a safe distillation
method, Slow Tuning and Low-Entropy Masking Distillation (SLowED), containing
two modules: Slow Tuning and Low-Entropy Masking. Slow Tuning scales down the
magnitude of model weight changes to optimize the model weights in the
neighboring space near the initial weight distribution. Low-Entropy Masking
masks low-entropy tokens, which are regarded as unnecessary learning targets,
to exclude them from fine-tuning. Experiments on three SLMs (Qwen2.5-1.5B,
Llama-3.2-1B, BLOOM-1.1B) across reasoning benchmarks (BBH, BB-Sub, ARC,
AGIEval) and safety evaluation (AdvBench) show that SLowED retains the safety
of SLMs and comparably improves their reasoning capability compared to existing
distillation methods. Furthermore, our ablation study presents the
effectiveness of Slow Tuning and Low-Entropy Masking, with the former
maintaining the model's safety in the early stage and the latter prolonging the
safe training epochs.
### ğŸŒŸ è®ºæ–‡è§£è¯» | å°æ¨¡å‹æ€ç»´é“¾è’¸é¦ä¹Ÿèƒ½å®‰å…¨ï¼ŸSlowEDæ–¹æ³•æ¥ä¿éšœ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½æ¨ç†å’Œç”Ÿæˆèƒ½åŠ›å¼ºï¼Œä½†è®¡ç®—ä¸å­˜å‚¨æˆæœ¬é«˜ï¼›å°è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰æ˜“éƒ¨ç½²ã€æ¨ç†å¿«å´èƒ½åŠ›ä¸è¶³ï¼Œå› æ­¤é€šè¿‡æ€ç»´é“¾ï¼ˆCoTï¼‰è’¸é¦åˆ©ç”¨å¤§æ¨¡å‹ä¼˜è´¨æ¨ç†æ¥å¢å¼ºå°æ¨¡å‹æ¨ç†èƒ½åŠ›æˆä¸ºç ”ç©¶çƒ­ç‚¹ã€‚ç„¶è€Œï¼Œç°æœ‰CoTè’¸é¦æ–¹æ³•å¤šå…³æ³¨æ¨ç†èƒ½åŠ›æå‡ï¼Œå´å¿½è§†äº†è®­ç»ƒè¿‡ç¨‹å¯¹å°æ¨¡å‹å®‰å…¨æ€§çš„è´Ÿé¢å½±å“â€”â€”è®­ç»ƒåå°æ¨¡å‹é¢å¯¹é£é™©è¾“å…¥æ—¶å®‰å…¨è¾“å‡ºæ¯”ä¾‹ï¼ˆå®‰å…¨ç‡ï¼‰å¤§å¹…ä¸‹é™ï¼ˆå¦‚å›¾1å±•ç¤ºQwen2.5 - 1.5Båœ¨CoTè’¸é¦ä¸­æ¨ç†æå‡ä½†å®‰å…¨ç‡ä¸‹è·Œï¼‰ã€‚åŒæ—¶ï¼Œå·²æœ‰å®‰å…¨å¯¹é½å·¥ä½œéœ€é¢å¤–è®¡ç®—ã€æ ‡æ³¨æ•°æ®ä¸”å¯èƒ½å½±å“æ¨ç†èƒ½åŠ›ï¼Œæ‰€ä»¥æœ¬æ–‡èšç„¦**å¦‚ä½•åœ¨CoTè’¸é¦ä¸­ç»´æŒå°æ¨¡å‹å®‰å…¨æ€§**è¿™ä¸€é—®é¢˜ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºSlow Tuningï¼ˆæ…¢è°ƒä¼˜ï¼‰æ¨¡å—  
CoTè’¸é¦æ˜“ä½¿æ¨¡å‹æƒé‡åç¦»åˆå§‹å®‰å…¨ç©ºé—´ï¼Œè€Œåˆå§‹æ¨¡å‹é™„è¿‘å°èŒƒå›´æƒé‡å˜åŒ–æ—¶å®‰å…¨ç‡ç¨³å®šã€‚Slow Tuningåœ¨æ¯ä¸ªè®­ç»ƒè½®æ¬¡åç¼©å°æ¨¡å‹æƒé‡å˜åŒ–å¹…åº¦ï¼Œè®©æ¨¡å‹åœ¨åˆå§‹æƒé‡åˆ†å¸ƒé™„è¿‘çš„é‚»åŸŸç©ºé—´ä¼˜åŒ–æƒé‡ï¼Œä»¥ç¼“æ…¢çš„æƒé‡å˜åŒ–åœ¨å¤§æƒé‡ç©ºé—´ä¸­å¾®è°ƒï¼Œå‡å°‘å› æƒé‡å‰§å˜è„±ç¦»å®‰å…¨ç©ºé—´çš„é£é™©ï¼Œåœ¨è®­ç»ƒæ—©æœŸç»´æŒæ¨¡å‹å®‰å…¨æ€§ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæå‡ºLow - Entropy Maskingï¼ˆä½ç†µæ©ç ï¼‰æ¨¡å—  
CoTè’¸é¦ä¸­å­¦ä¹ æ•™å¸ˆæ¨¡å‹æ¯ä¸ªtokenå¯¹å°æ¨¡å‹å®‰å…¨æ€§æœ‰é˜»ç¢ï¼Œä½ç†µtokenå¯è§†ä¸ºä¸å¿…è¦å­¦ä¹ ç›®æ ‡ã€‚Low - Entropy Maskingå°†ä½ç†µï¼ˆå¦‚æœ€ä½50%ç†µå€¼ï¼‰çš„tokenä»å¾®è°ƒä¸­æ’é™¤ï¼Œé€šè¿‡å®ä¾‹çº§æŸå¤±å‡½æ•°è®¾è®¡ï¼Œè°ƒæ•´è®­ç»ƒæ–¹å‘ï¼Œå»¶é•¿æ¨¡å‹å®‰å…¨è®­ç»ƒçš„è½®æ¬¡ï¼Œç¼“è§£å•ä¸€æ¨ç†èƒ½åŠ›æå‡å¯¹å®‰å…¨æ€§çš„è´Ÿé¢å½±å“ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šæ•´åˆä¸¤æ¨¡å—å½¢æˆSLowEDæ–¹æ³•  
SLowEDç»“åˆSlow Tuningçš„ epoch çº§æƒé‡å˜åŒ–æ§åˆ¶ä¸Low - Entropy Maskingçš„å®ä¾‹çº§ä½ç†µtokenæ©ç ï¼Œå½¢æˆå®‰å…¨çš„CoTè’¸é¦æ–¹æ³•ï¼Œåœ¨æå‡å°æ¨¡å‹æ¨ç†èƒ½åŠ›åŒæ—¶ä¿éšœå®‰å…¨æ€§ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨3ä¸ªå°æ¨¡å‹ï¼ˆQwen2.5 - 1.5Bã€Llama - 3.2 - 1Bã€BLOOM - 1.1Bï¼‰ä¸Šï¼Œè·¨æ¨ç†åŸºå‡†ï¼ˆBBHã€BB - Subã€ARCã€AGIEvalï¼‰å’Œå®‰å…¨è¯„ä¼°ï¼ˆAdvBenchï¼‰å®éªŒæ˜¾ç¤ºï¼š  
- ä¸ç°æœ‰è’¸é¦æ–¹æ³•ï¼ˆå¦‚æ ‡å‡†CoTè’¸é¦Std - CoTã€çº§è”CoTè’¸é¦CasCoDï¼‰ç›¸æ¯”ï¼ŒSLowEDåœ¨ä¿æŒå°æ¨¡å‹å®‰å…¨æ€§çš„åŒæ—¶ï¼Œæ¨ç†èƒ½åŠ›æå‡å¹…åº¦ç›¸å½“ï¼›å…¶ä»–åŸºçº¿æ–¹æ³•åˆ™ä½¿å®‰å…¨æ€§æ˜¾è‘—ä¸‹é™ã€‚  
- æ¶ˆèå®éªŒéªŒè¯ä¸¤æ¨¡å—æœ‰æ•ˆæ€§ï¼šSlow Tuningåœ¨è®­ç»ƒæ—©æœŸç»´æŒå®‰å…¨æ€§ï¼ŒLow - Entropy Maskingå»¶é•¿å®‰å…¨è®­ç»ƒè½®æ¬¡ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. **é—®é¢˜å‘ç°è§’åº¦**ï¼šå…³æ³¨åˆ°CoTè’¸é¦ä¸­è¢«å¿½è§†çš„å°æ¨¡å‹å®‰å…¨æ€§é€€åŒ–ç°è±¡ï¼Œä¸ºåç»­å°æ¨¡å‹å®‰å…¨è’¸é¦ç ”ç©¶æä¾›æ–°è§†è§’ï¼Œæé†’ç ”ç©¶è€…åœ¨æå‡èƒ½åŠ›æ—¶éœ€å…¼é¡¾å®‰å…¨ã€‚  
2. **æ–¹æ³•è®¾è®¡æ€è·¯**ï¼šä»æƒé‡å˜åŒ–å¹…åº¦ï¼ˆepochçº§æ§åˆ¶ï¼‰å’Œè®­ç»ƒç›®æ ‡ç­›é€‰ï¼ˆå®ä¾‹çº§æ©ç ï¼‰ä¸¤ä¸ªç»´åº¦è®¾è®¡ç­–ç•¥ï¼Œè¿™ç§å¤šç»´åº¦ã€åˆ†å±‚çº§çš„å®‰å…¨å¢å¼ºæ€è·¯ï¼Œå¯å€Ÿé‰´åˆ°å…¶ä»–æ¨¡å‹è’¸é¦ã€å¾®è°ƒéœ€å…¼é¡¾å®‰å…¨ä¸èƒ½åŠ›çš„åœºæ™¯ã€‚  
3. **å®éªŒéªŒè¯æ–¹å¼**ï¼šåœ¨å¤šæ¨¡å‹ã€å¤šä»»åŠ¡åŸºå‡†ä¸Šå…¨é¢éªŒè¯ï¼Œä¸”é€šè¿‡æ¶ˆèå®éªŒæ‹†è§£æ¨¡å—ä½œç”¨ï¼Œä¸ºæ–¹æ³•æœ‰æ•ˆæ€§æä¾›åšå®è¯æ®ï¼Œè¿™ç§å®éªŒè®¾è®¡èŒƒå¼å¯¹ç®—æ³•ç±»ç ”ç©¶çš„å¯é æ€§éªŒè¯æœ‰å‚è€ƒä»·å€¼ã€‚

## selective-kv-cache-sharing-to-mitigate-timing-side-channels-in-llm-inference
### Abstract
Global KV-cache sharing has emerged as a key optimization for accelerating
large language model (LLM) inference. However, it exposes a new class of timing
side-channel attacks, enabling adversaries to infer sensitive user inputs via
shared cache entries. Existing defenses, such as per-user isolation, eliminate
leakage but degrade performance by up to 38.9% in time-to-first-token (TTFT),
making them impractical for high-throughput deployment. To address this gap, we
introduce SafeKV (Secure and Flexible KV Cache Sharing), a privacy-aware
KV-cache management framework that selectively shares non-sensitive entries
while confining sensitive content to private caches. SafeKV comprises three
components: (i) a hybrid, multi-tier detection pipeline that integrates
rule-based pattern matching, a general-purpose privacy detector, and
context-aware validation; (ii) a unified radix-tree index that manages public
and private entries across heterogeneous memory tiers (HBM, DRAM, SSD); and
(iii) entropy-based access monitoring to detect and mitigate residual
information leakage. Our evaluation shows that SafeKV mitigates 94% - 97% of
timing-based side-channel attacks. Compared to per-user isolation method,
SafeKV improves TTFT by up to 40.58% and throughput by up to 2.66X across
diverse LLMs and workloads. SafeKV reduces cache-induced TTFT overhead from
50.41% to 11.74% on Qwen3-235B. By combining fine-grained privacy control with
high cache reuse efficiency, SafeKV reclaims the performance advantages of
global sharing while providing robust runtime privacy guarantees for LLM
inference.
### ğŸŒŸ è®ºæ–‡è§£è¯» | é¢å‘LLMæ¨ç†çš„é€‰æ‹©æ€§KVç¼“å­˜å…±äº«ï¼šæŠµå¾¡æ—¶åºä¾§ä¿¡é“æ”»å‡»

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­ï¼Œå…¨å±€KVç¼“å­˜å…±äº«æ˜¯æå‡æ•ˆç‡çš„å…³é”®ä¼˜åŒ–æ‰‹æ®µï¼Œèƒ½é€šè¿‡å¤ç”¨ä¸­é—´æ³¨æ„åŠ›çŠ¶æ€åŠ é€Ÿç”Ÿæˆè¿‡ç¨‹ã€‚ç„¶è€Œï¼Œè¿™ä¹Ÿå¸¦æ¥äº†æ–°çš„æ—¶åºä¾§ä¿¡é“æ”»å‡»é£é™©ï¼šæ”»å‡»è€…å¯é€šè¿‡ç²¾å¿ƒæ„é€ æŸ¥è¯¢å¹¶æµ‹é‡å“åº”å»¶è¿Ÿï¼Œæ¨æ–­å…¶ä»–ç”¨æˆ·çš„æ•æ„Ÿè¾“å…¥ï¼ˆå¦‚åŒ»ç–—ã€é‡‘èä¿¡æ¯ç­‰ï¼‰ã€‚ç°æœ‰é˜²å¾¡æ–¹æ¡ˆï¼ˆå¦‚æŒ‰ç”¨æˆ·éš”ç¦»ç¼“å­˜ï¼‰è™½èƒ½æ¶ˆé™¤æ³„æ¼ï¼Œä½†ä¼šè®©é¦– token ç”Ÿæˆæ—¶é—´ï¼ˆTTFTï¼‰æ€§èƒ½ä¸‹é™é«˜è¾¾ 38.9%ï¼Œéš¾ä»¥æ»¡è¶³é«˜ååé‡éƒ¨ç½²éœ€æ±‚ã€‚å› æ­¤ï¼ŒäºŸéœ€ä¸€ç§å…¼é¡¾éšç§ä¿æŠ¤ä¸æ€§èƒ½çš„KVç¼“å­˜ç®¡ç†æ–¹æ¡ˆã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ··åˆå¤šå±‚éšç§æ£€æµ‹ pipeline  
SafeKV è®¾è®¡äº†ä¸€å¥—èåˆè§„åˆ™åŒ¹é…ã€é€šç”¨éšç§æ£€æµ‹å™¨ä¸ä¸Šä¸‹æ–‡æ„ŸçŸ¥éªŒè¯çš„æ··åˆæ£€æµ‹æµç¨‹ï¼Œåœ¨ç¼“å­˜é¡¹åˆ›å»ºæ—¶åˆ¤å®šå…¶â€œæ•æ„Ÿâ€æˆ–â€œå®‰å…¨å¯å…±äº«â€å±æ€§ã€‚è§„åˆ™åŒ¹é…å®ç°ä½å¼€é”€åˆç­›ï¼Œé€šç”¨æ£€æµ‹å™¨æå‡ç²¾å‡†åº¦ï¼Œä¸Šä¸‹æ–‡éªŒè¯åˆ™ç»“åˆè¯­ä¹‰åœºæ™¯ç»†åŒ–åˆ¤æ–­ï¼›ä¸”æ•´ä¸ªæµç¨‹å¼‚æ­¥æ‰§è¡Œï¼Œé€‚é…é«˜ååé‡LLMæ¨ç†åœºæ™¯ï¼Œåœ¨ä½å»¶è¿Ÿä¸é«˜å‡†ç¡®ç‡é—´å–å¾—å¹³è¡¡ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šé²æ£’çš„è¯¯åˆ†ç±»é˜²å¾¡æœºåˆ¶  
è€ƒè™‘åˆ°æ£€æµ‹å¯èƒ½å­˜åœ¨è¯¯å·®ï¼ŒSafeKV é»˜è®¤å¯¹ç¼“å­˜åšå±‚çº§éš”ç¦»ï¼Œå¹¶ä¸ºå¯ç–‘è®¿é—®è®¾è®¡ fallback å¤„ç†é€»è¾‘ã€‚å³ä¾¿å°‘é‡æ•æ„Ÿå†…å®¹è¢«è¯¯åˆ†ç±»å…±äº«ï¼Œä¹Ÿèƒ½é€šè¿‡è¿è¡Œæ—¶é˜²æŠ¤æªæ–½é™åˆ¶æ³„æ¼é£é™©ï¼Œä¿éšœéšç§çš„åŒæ—¶ä¸ä¸­æ–­æ¨ç†æµç¨‹ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå¯æ‰©å±•çš„ç¼“å­˜ç”Ÿå‘½å‘¨æœŸç®¡ç†  
é‡‡ç”¨ç»Ÿä¸€åŸºæ•°æ ‘ï¼ˆradix - treeï¼‰ç´¢å¼•ç»“æ„ï¼Œç®¡ç†å¼‚æ„å­˜å‚¨ï¼ˆHBMã€DRAMã€SSDï¼‰ä¸­çš„å…¬å…±ä¸ç§æœ‰ç¼“å­˜é¡¹ã€‚è¯¥ç»“æ„æ”¯æŒé«˜æ•ˆå‰ç¼€åŒ¹é…ã€è‡ªé€‚åº”å¤ç”¨ç­–ç•¥ä¸å¤šå±‚å†…å­˜åè°ƒï¼Œåœ¨å¤§è§„æ¨¡éƒ¨ç½²ä¸‹ä»èƒ½å®ç°é«˜å¤ç”¨ç‡ã€å¿«é€ŸæŸ¥æ‰¾ä¸ä½æ€§èƒ½å¼€é”€ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹4ï¼šåŸºäºç†µçš„è®¿é—®ç›‘æ§  
é€šè¿‡åŸºäºç†µçš„è®¿é—®ç›‘æ§æ¥æ£€æµ‹å’Œç¼“è§£æ®‹ä½™ä¿¡æ¯æ³„æ¼ï¼Œè¿›ä¸€æ­¥ä¿éšœäº†éšç§å®‰å…¨ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
- æ”»å‡»ç¼“è§£ï¼šèƒ½ç¼“è§£ 94% - 97% çš„æ—¶åºä¾§ä¿¡é“æ”»å‡»ï¼›  
- æ€§èƒ½æå‡ï¼šä¸æŒ‰ç”¨æˆ·éš”ç¦»æ–¹æ¡ˆç›¸æ¯”ï¼Œåœ¨ä¸åŒLLMå’Œè´Ÿè½½ä¸‹ï¼ŒTTFTæœ€å¤šæå‡ 40.58%ï¼Œååé‡æœ€å¤šæå‡ 2.66 å€ï¼›åœ¨ Qwen3 - 235B æ¨¡å‹ä¸Šï¼Œç¼“å­˜å¯¼è‡´çš„ TTFT å¼€é”€ä» 50.41% é™è‡³ 11.74%ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
- éšç§ä¸æ€§èƒ½ååŒè®¾è®¡ï¼šæ‰“ç ´â€œéšç§ä¿æŠ¤å¿…ç„¶ç‰ºç‰²æ€§èƒ½â€çš„å›ºæœ‰è®¤çŸ¥ï¼Œé€šè¿‡â€œé€‰æ‹©æ€§å…±äº«â€æ€è·¯ï¼Œåœ¨å…³é”®è·¯å¾„ï¼ˆç¼“å­˜å¤ç”¨ï¼‰ä¸­åµŒå…¥éšç§æ£€æµ‹ä¸éš”ç¦»é€»è¾‘ï¼Œä¸ºäº‘æœåŠ¡ç­‰å¤šç§Ÿæˆ·LLMéƒ¨ç½²æä¾›æ¶æ„çº§å‚è€ƒï¼›  
- æ··åˆæ£€æµ‹èŒƒå¼ï¼šè§„åˆ™ + æ·±åº¦å­¦ä¹  + ä¸Šä¸‹æ–‡éªŒè¯çš„åˆ†å±‚æ£€æµ‹ï¼Œä¸ºâ€œä½å»¶è¿Ÿ + é«˜ç²¾åº¦â€çš„å†…å®¹å±æ€§åˆ¤åˆ«æä¾›äº†å·¥ç¨‹åŒ–è½åœ°æ¨¡æ¿ï¼Œå¯è¿ç§»è‡³å…¶ä»–éœ€å†…å®¹æ•æ„Ÿåˆ¤å®šçš„åœºæ™¯ï¼ˆå¦‚æ•°æ®è„±æ•ã€è®¿é—®æ§åˆ¶ï¼‰ï¼›  
- å¼‚æ„å­˜å‚¨ä¸‹çš„ç¼“å­˜ç´¢å¼•ï¼šç»Ÿä¸€åŸºæ•°æ ‘å¯¹å¤šä»‹è´¨å­˜å‚¨çš„é€‚é…ç®¡ç†ï¼Œä¸ºå¤§æ¨¡å‹æ—¶ä»£â€œå†…å­˜åˆ†å±‚è°ƒåº¦ + ç¼“å­˜é«˜æ•ˆå¤ç”¨â€æä¾›äº†å¯æ‰©å±•çš„æŠ€æœ¯è·¯çº¿ï¼ŒåŠ©åŠ›å¤æ‚ç¡¬ä»¶ç¯å¢ƒä¸‹çš„æ€§èƒ½ä¼˜åŒ–ã€‚

## from-trial-and-error-to-improvement--a-systematic-analysis-of-llm-exploration-mechanisms-in-rlvr
### Abstract
Reinforcement learning with verifiable rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of large language
models (LLMs). Unlike traditional RL approaches, RLVR leverages rule-based
feedback to guide LLMs in generating and refining complex reasoning chains -- a
process critically dependent on effective exploration strategies. While prior
work has demonstrated RLVR's empirical success, the fundamental mechanisms
governing LLMs' exploration behaviors remain underexplored. This technical
report presents a systematic investigation of exploration capacities in RLVR,
covering four main aspects: (1) exploration space shaping, where we develop
quantitative metrics to characterize LLMs' capability boundaries; (2)
entropy-performance exchange, analyzed across training stages, individual
instances, and token-level patterns; and (3) RL performance optimization,
examining methods to effectively translate exploration gains into measurable
improvements. By unifying previously identified insights with new empirical
evidence, this work aims to provide a foundational framework for advancing RLVR
systems.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ä»è¯•é”™åˆ°æ”¹è¿›ï¼šRLVRä¸­LLMæ¢ç´¢æœºåˆ¶çš„ç³»ç»Ÿæ€§åˆ†æ

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¼ºåŒ–å­¦ä¹ ç»“åˆå¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰å·²æˆä¸ºå¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†èƒ½åŠ›çš„æœ‰åŠ›èŒƒå¼ã€‚ä¸ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒRLVRåˆ©ç”¨åŸºäºè§„åˆ™çš„åé¦ˆå¼•å¯¼LLMsç”Ÿæˆå’Œä¼˜åŒ–å¤æ‚æ¨ç†é“¾ï¼Œè€Œè¿™ä¸€è¿‡ç¨‹é«˜åº¦ä¾èµ–æœ‰æ•ˆçš„æ¢ç´¢ç­–ç•¥ã€‚å°½ç®¡å…ˆå‰å·¥ä½œå·²å±•ç¤ºRLVRçš„å®è¯æˆåŠŸï¼Œä½†LLMsæ¢ç´¢è¡Œä¸ºèƒŒåçš„åŸºæœ¬æœºåˆ¶ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨å¯¹RLVRä¸­çš„æ¢ç´¢èƒ½åŠ›å±•å¼€ç³»ç»Ÿæ€§ç ”ç©¶ï¼Œä¸ºæ¨è¿›RLVRç³»ç»Ÿæä¾›åŸºç¡€æ¡†æ¶ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæ¢ç´¢ç©ºé—´å¡‘é€ 
ç ”ç©¶å¦‚ä½•æ„å»ºLLMsçš„æ¢ç´¢ç©ºé—´ï¼Œæå‡ºå®šé‡æŒ‡æ ‡æ¥åˆ»ç”»å…¶èƒ½åŠ›è¾¹ç•Œï¼Œç¡®å®šåœ¨å®é™…LLMç”Ÿæˆçº¦æŸä¸‹å¯è§£å†³ä¸ä¸å¯è§£å†³çš„é—®é¢˜ï¼Œè¿˜å¯¹æ¯”äº†SFTå’ŒRLè¿™ä¸¤ç§ä¸»è¦è®­ç»ƒåæ–¹æ³•å¯¹LLMæ¢ç´¢èƒ½åŠ›å’Œæ•´ä½“æ€§èƒ½çš„å½±å“ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç†µ - æ€§èƒ½äº¤äº’åˆ†æ
æ¢ç©¶ä½œä¸ºæ¢ç´¢èƒ½åŠ›å…³é”®æŒ‡æ ‡çš„ç†µä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„å…³ç³»ï¼Œåˆ†æå»¶ä¼¸åˆ°é˜¶æ®µçº§åŠ¨æ€ã€å®ä¾‹çº§æ•ˆç‡å’Œæ ‡è®°çº§æ˜¾è‘—æ€§è¿™ä¸‰ä¸ªå±‚é¢çš„å¤šç²’åº¦å®è¯æ£€éªŒï¼Œæ¶µç›–è®­ç»ƒé˜¶æ®µã€å•ä¸ªå®ä¾‹ä»¥åŠæ ‡è®°çº§æ¨¡å¼ç­‰ç»´åº¦ã€‚
ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå¼ºåŒ–å­¦ä¹ æ€§èƒ½ä¼˜åŒ–æ¢ç´¢
æ¢è®¨æå‡æ¨ç†èƒ½åŠ›çš„æ–¹æ³•ï¼Œèšç„¦äºæ‰©å±•æ¢ç´¢èƒ½åŠ›å’Œå¢å¼ºæ€§èƒ½è½¬æ¢æ•ˆç‡è¿™ä¸¤ä¸ªä¸»è¦æ–¹é¢ã€‚å›é¡¾å¢å¼ºLLMsæ¢ç´¢èƒ½åŠ›çš„æœ€æ–°è¿›å±•ï¼Œè¿˜é€šè¿‡å®éªŒç ”ç©¶è®­ç»ƒä¸­å¦‚ä½•ä¿æŒPass@kæ€§èƒ½å¹¶æå‡ºä¸¤ç§æå‡RLæ•ˆç‡çš„ç®€å•æ–¹æ³•ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
æ–‡ä¸­å€ŸåŠ©Pass@kç­‰æŒ‡æ ‡å¯¹LLMsæ¢ç´¢èƒ½åŠ›å±•å¼€é‡åŒ–åˆ†æï¼ŒPass@k metricèƒ½è¯„ä¼°LLMsåœ¨kæ¬¡å°è¯•å†…è§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œå…¶æ— åä¼°è®¡æ–¹æ³•å¯ç¨³å®šè¯„ä¼°æ¨¡å‹èƒ½åŠ›ï¼Œè¿˜é€šè¿‡è¯¥æŒ‡æ ‡ç¡®å®šæ¨¡å‹æ¢ç´¢èƒ½åŠ›çš„æé™ï¼Œè¯†åˆ«k - rolloutä¸å¯è§£å†³çš„é—®é¢˜ç­‰ï¼ˆæ–‡ä¸­å®éªŒéƒ¨åˆ†è™½æœªå®Œå…¨å±•å¼€å‘ˆç°æœ€ç»ˆæ•°å€¼ç±»ç»“æœï¼Œä½†ä»æ–¹æ³•é€»è¾‘ä¸Šä¸ºæ¢ç´¢æœºåˆ¶åˆ†ææä¾›äº†æœ‰æ•ˆæ‰‹æ®µä¸æ–¹å‘ï¼‰ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. æ–¹æ³•å±‚é¢ï¼šæå‡ºçš„æ¢ç´¢ç©ºé—´å¡‘é€ ã€ç†µ - æ€§èƒ½äº¤äº’ã€æ€§èƒ½æå‡ç­‰ç»´åº¦çš„åˆ†ææ–¹æ³•ï¼Œä¸ºåç»­ç ”ç©¶LLMsåœ¨RLVRä¸­çš„æ¢ç´¢æœºåˆ¶æä¾›äº†ç³»ç»Ÿæ¡†æ¶ï¼Œåç»­å·¥ä½œå¯åŸºäºæ­¤æ¡†æ¶è¿›ä¸€æ­¥æ·±å…¥æ¢ç©¶ä¸åŒåœºæ™¯ä¸‹LLMsçš„è¡¨ç°ã€‚
2. æŒ‡æ ‡å±‚é¢ï¼šPass@k metricåŠå…¶æ— åä¼°è®¡çš„åº”ç”¨ï¼Œä¸ºé‡åŒ–LLMsæ¢ç´¢èƒ½åŠ›æä¾›äº†æœ‰æ•ˆå·¥å…·ï¼Œåœ¨è¯„ä¼°æ¨¡å‹æ¨ç†èƒ½åŠ›è¾¹ç•Œç­‰ä»»åŠ¡ä¸­å…·æœ‰å€Ÿé‰´ä»·å€¼ï¼Œå¯ç”¨äºå…¶ä»–ç›¸å…³LLMæ¨ç†èƒ½åŠ›è¯„ä¼°åœºæ™¯ã€‚
3. ç ”ç©¶æ€è·¯å±‚é¢ï¼šæ•´åˆæ–‡çŒ®ç»¼è¿°ä¸ä¸¥æ ¼å®è¯åˆ†æçš„ç ”ç©¶æ–¹æ³•ï¼Œä¸ºè¯¥é¢†åŸŸä¹ƒè‡³å…¶ä»–AIå­é¢†åŸŸçš„ç ”ç©¶æä¾›äº†èŒƒä¾‹ï¼Œæœ‰åŠ©äºæ¨åŠ¨æ›´ç³»ç»Ÿå…¨é¢çš„AIæŠ€æœ¯æœºåˆ¶ç ”ç©¶ã€‚

## assessing-and-mitigating-data-memorization-risks-in-fine-tuned-large-language-models
### Abstract
Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse natural language processing tasks, but their tendency to memorize
training data poses significant privacy risks, particularly during fine-tuning
processes. This paper presents a comprehensive empirical analysis of data
memorization in fine-tuned LLMs and introduces a novel multi-layered privacy
protection framework. Through controlled experiments on modern LLM
architectures including GPT-2, Phi-3, and Gemma-2, we demonstrate that
fine-tuning with repeated sensitive data increases privacy leakage rates from
baseline levels of 0-5% to 60-75%, representing a 64.2% average increase across
tested models. We propose and rigorously evaluate four complementary privacy
protection methods: semantic data deduplication, differential privacy during
generation, entropy-based filtering, and pattern-based content filtering. Our
experimental results show that these techniques can reduce data leakage to 0%
while maintaining 94.7% of original model utility.
### ğŸŒŸ è®ºæ–‡è§£è¯» | æ­ç§˜å¾®è°ƒå¤§æ¨¡å‹çš„æ•°æ®è®°å¿†é£é™©ï¼šè¯„ä¼°ä¸ç¼“è§£ä¹‹é“

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å„é¢†åŸŸå±•ç°å“è¶Šèƒ½åŠ›çš„åŒæ—¶ï¼Œå…¶å¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†å€¾å‘å¸¦æ¥äº†ä¸¥é‡éšç§é£é™©ï¼Œå°¤å…¶æ˜¯å¾®è°ƒé˜¶æ®µã€‚ç›®å‰é’ˆå¯¹å¾®è°ƒLLMsä¸­æ•°æ®è®°å¿†çš„ç³»ç»Ÿé‡åŒ–ä¸ç¼“è§£æ–¹æ³•å­˜åœ¨æ˜¾è‘—ç¼ºå£ï¼šè¿‡å¾€ç ”ç©¶å¤šèšç„¦å¤§è§„æ¨¡é¢„è®­ç»ƒé˜¶æ®µçš„è®°å¿†é—®é¢˜ï¼Œè€Œé’ˆå¯¹æ›´å°ã€å¯èƒ½æ›´æ•æ„Ÿçš„å¾®è°ƒæ•°æ®é›†ç›¸å…³é£é™©ç ”ç©¶ä¸è¶³ï¼›åŒæ—¶ç¼ºä¹èƒ½å¹³è¡¡å®‰å…¨ä¸æ•ˆç”¨çš„å®ç”¨éšç§ä¿æŠ¤å·¥å…·ï¼Œä¸”éšç€å¾®è°ƒLLMsåœ¨æ•æ„Ÿé¢†åŸŸéƒ¨ç½²å¢å¤šã€ç›‘ç®¡è¦æ±‚è¶‹ä¸¥ï¼Œè¿™äº›é—®é¢˜æ„ˆå‘å…³é”®ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨å¡«è¡¥è¿™äº›ç©ºç™½ï¼Œæä¾›é‡åŒ–è®°å¿†é£é™©ã€å®ç°æœ‰æ•ˆéšç§ä¿æŠ¤ä¸éƒ¨ç½²å·¥å…·çš„ç»¼åˆæ–¹æ¡ˆã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šå…¨é¢çš„å®è¯åˆ†æ  
é¦–æ¬¡å¯¹ç°ä»£å¾®è°ƒLLMsçš„è®°å¿†ç‡å¼€å±•ç³»ç»Ÿå®šé‡åˆ†æï¼Œé€‰å–GPT - 2ã€Phi - 3 - miniã€Gemma - 2 - 2Bç­‰ä¸åŒè§„æ¨¡ä¸è®¾è®¡ç†å¿µçš„æ¨¡å‹ï¼Œæ­ç¤ºå‡ºå¾®è°ƒä½¿è®°å¿†ç‡å¹³å‡æå‡64.2%è¿™ä¸€è§„å¾‹ï¼Œå±•ç°å¤šæ¶æ„ä¸‹çš„ä¸€è‡´æ¨¡å¼ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæ–°é¢–çš„å¤šå±‚éšç§ä¿æŠ¤æ¡†æ¶  
æå‡ºå¹¶ä¸¥æ ¼è¯„ä¼°å››ç§äº’è¡¥çš„éšç§ä¿æŠ¤æ–¹æ³•ï¼šè¯­ä¹‰æ•°æ®å»é‡ï¼Œå‡å°‘é‡å¤æ•æ„Ÿæ•°æ®å¯¹è®°å¿†çš„å½±å“ï¼›ç”Ÿæˆæ—¶çš„å·®åˆ†éšç§ï¼Œåœ¨ç”Ÿæˆç¯èŠ‚å¼•å…¥å¯æ§å™ªå£°ä¿éšœéšç§ï¼›åŸºäºç†µçš„è¿‡æ»¤ï¼Œåˆ©ç”¨ç†µè¡¡é‡ä¿¡æ¯ä¸ç¡®å®šæ€§æ¥ç­›é€‰å†…å®¹ï¼›åŸºäºæ¨¡å¼çš„å†…å®¹è¿‡æ»¤ï¼Œè¯†åˆ«å¹¶å¤„ç†æ•æ„Ÿæ¨¡å¼ä¿¡æ¯ã€‚è¿™äº›æ–¹æ³•ååŒä½œç”¨ï¼Œåœ¨å®Œå…¨æ¶ˆé™¤æ•°æ®æ³„æ¼çš„åŒæ—¶ä¿æŒ94.7%çš„åŸå§‹æ¨¡å‹æ•ˆç”¨ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå¯å¤ç°çš„ç ”ç©¶åŸºç¡€è®¾æ–½  
å‘å¸ƒå…¨é¢çš„å¼€æºå·¥å…·ä¸å®éªŒæ¡†æ¶ï¼Œè®©ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…èƒ½å¤Ÿè¯„ä¼°è‡ªèº«æ¨¡å‹çš„è®°å¿†é£é™©ï¼Œä¸ºLLMéšç§ç ”ç©¶æä¾›åŸºç¡€æ”¯æ’‘ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹4ï¼šå®ç”¨çš„éƒ¨ç½²æŒ‡å—  
ä¸ºåœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å¾®è°ƒLLMsçš„ä»ä¸šè€…æä¾›åŸºäºè¯æ®çš„å»ºè®®ï¼Œæ¶µç›–é£é™©è¯„ä¼°æ¡†æ¶ä¸å®æ–½ç­–ç•¥ï¼ŒåŠ©åŠ›å®‰å…¨éƒ¨ç½²ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨GPT - 2ã€Phi - 3ã€Gemma - 2ç­‰ç°ä»£LLMæ¶æ„ä¸Šçš„å—æ§å®éªŒè¡¨æ˜ï¼šä½¿ç”¨é‡å¤æ•æ„Ÿæ•°æ®å¾®è°ƒæ—¶ï¼Œéšç§æ³„æ¼ç‡ä»åŸºçº¿æ°´å¹³çš„0 - 5%æå‡è‡³60 - 75%ï¼›è€Œé‡‡ç”¨æå‡ºçš„å››ç§éšç§ä¿æŠ¤æŠ€æœ¯åï¼Œæ•°æ®æ³„æ¼å¯é™è‡³0%ï¼ŒåŒæ—¶ç»´æŒ94.7%çš„åŸå§‹æ¨¡å‹æ•ˆç”¨ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. ç ”ç©¶æ€è·¯ä¸Šï¼Œé’ˆå¯¹è¡Œä¸šç—›ç‚¹ï¼ˆéšç§é£é™©ï¼‰å¼€å±•ç³»ç»Ÿé‡åŒ–ä¸ç¼“è§£ç ”ç©¶ï¼Œä¸ºåç»­åŒç±»éšç§ã€å®‰å…¨ç›¸å…³ç ”ç©¶æä¾›äº†ä»é—®é¢˜å®šä¹‰åˆ°æ–¹æ³•éªŒè¯çš„å®Œæ•´èŒƒå¼ã€‚  
2. æŠ€æœ¯æ–¹æ³•ä¸Šï¼Œæå‡ºçš„å¤šå±‚éšç§ä¿æŠ¤æ¡†æ¶æ•´åˆå¤šç§æŠ€æœ¯ï¼Œä¸ºå¹³è¡¡éšç§ä¸æ¨¡å‹æ•ˆç”¨æä¾›äº†å®ç”¨æ–¹æ¡ˆï¼Œå„æŠ€æœ¯æ¨¡å—ï¼ˆå¦‚è¯­ä¹‰å»é‡ã€å·®åˆ†éšç§ç­‰ï¼‰ä¹Ÿå¯åœ¨å…¶ä»–éšç§ä¿æŠ¤åœºæ™¯ä¸­å€Ÿé‰´æ€è·¯ã€‚  
3. å·¥ç¨‹å®è·µä¸Šï¼Œå¼€æºå·¥å…·ä¸å®éªŒæ¡†æ¶é™ä½äº†è¡Œä¸šå†…è¯„ä¼°è®°å¿†é£é™©çš„é—¨æ§›ï¼Œéƒ¨ç½²æŒ‡å—ä¸ºä¼ä¸šåœ¨æ•æ„Ÿåœºæ™¯è½åœ°å¾®è°ƒLLMsæä¾›åˆè§„ã€å®‰å…¨å‚è€ƒï¼Œæ¨åŠ¨è´Ÿè´£ä»»AIçš„å‘å±•ã€‚

## bridging-classical-and-quantum-computing-for-next-generation-language-models
### Abstract
Integrating Large Language Models (LLMs) with quantum computing is a critical
challenge, hindered by the severe constraints of Noisy Intermediate-Scale
Quantum (NISQ) devices, including barren plateaus and limited coherence.
Current approaches often fail due to static quantum-classical partitioning. We
introduce Adaptive Quantum-Classical Fusion (AQCF), the first framework to
bridge this gap through dynamic, quantum-classical co-design. AQCF's core
principle is real-time adaptation: it analyzes input complexity to orchestrate
seamless transitions between classical and quantum processing. The framework
features three key innovations: (1) entropy-driven adaptive circuits that
circumvent barren plateaus; (2) quantum memory banks that unify classical
attention with quantum state-based similarity retrieval; and (3) intelligent
fusion controllers that allocate tasks for optimal performance. This
architecture maintains full compatibility with classical Transformers while
progressively incorporating quantum advantages. Experiments on sentiment
analysis demonstrate that AQCF achieves competitive performance, significantly
improves quantum resource efficiency, and operates successfully within typical
NISQ constraints. By providing a seamless integration pathway, AQCF offers both
immediate practical value on current quantum hardware and a clear evolution
path toward mature Quantum LLMs.
### ğŸŒŸ è®ºæ–‡è§£è¯» | ä¸ºä¸‹ä¸€ä»£è¯­è¨€æ¨¡å‹æ¶èµ·ç»å…¸ä¸é‡å­è®¡ç®—çš„æ¡¥æ¢

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
Transformeræ¶æ„åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å–å¾—äº†å˜é©æ€§æˆåŠŸï¼Œé‡å¡‘äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œä½†å‘é‡å­è®¡ç®—é©±åŠ¨çš„ä¸‹ä¸€ä»£è¯­è¨€æ¨¡å‹è¿‡æ¸¡ä»é¢ä¸´æŒ‘æˆ˜ã€‚é‡å­è®¡ç®—è™½æœ‰æŒ‡æ•°çº§ä¼˜åŠ¿æ½œåŠ›ï¼Œç„¶è€Œç»å…¸æ·±åº¦å­¦ä¹ ä¸é‡å­è®¡ç®—èŒƒå¼é—´å­˜åœ¨é¸¿æ²Ÿï¼Œç‰¹åˆ«æ˜¯æœ‰å™ªå£°ä¸­ç­‰è§„æ¨¡é‡å­ï¼ˆNISQï¼‰è®¾å¤‡å­˜åœ¨ barren plateausï¼ˆ barren plateau æŒ‡é‡å­ç”µè·¯è®­ç»ƒä¸­æ¢¯åº¦æŒ‡æ•°çº§æ¶ˆå¤±è‡´è®­ç»ƒä¸å¯è¡Œï¼‰ã€ qubit ç›¸å¹²æ€§æœ‰é™ã€ç”µè·¯æ·±åº¦å—é™ç­‰ä¸¥è‹›çº¦æŸã€‚ç°æœ‰é‡å­è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆQNLPï¼‰æ–¹æ³•ä¹Ÿå­˜åœ¨ä¸è¶³ï¼šå…¨é‡å­æ¨¡å‹èˆå¼ƒç»å…¸æ¶æ„ï¼Œä¸¢å¤±Transformeræ ¸å¿ƒè‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸”ç”µè·¯æ·±åº¦éšåºåˆ—é•¿åº¦æ‰©å±•å·®ï¼›å˜åˆ†é‡å­ç®—æ³•ï¼ˆVQAsï¼‰ç”¨å›ºå®šæ¶æ„ï¼Œæ— æ³•ä¾ä»»åŠ¡åŠ¨æ€æ¡¥æ¥ç»å…¸ä¸é‡å­å¤„ç†ï¼Œè¿˜å— barren plateau å›°æ‰°ï¼›æ··åˆé‡å­ - ç»å…¸æ¨¡å‹é‡‡ç”¨é™æ€åˆ’åˆ†ç­–ç•¥ï¼Œæœªå°†äºŒè€…ä½œä¸ºé›†æˆç³»ç»Ÿç»Ÿä¸€éƒ¨åˆ†ã€‚æ‰€ä»¥éœ€è¦æ–°æ¡†æ¶æ— ç¼åè°ƒä¸¤ç§è®¡ç®—èŒƒå¼ï¼Œå‘æŒ¥ä¼˜åŠ¿ã€å‡è½»å±€é™ï¼Œä¸ºè¯­è¨€æ¨¡å‹æ¶èµ·ç»å…¸ä¸é‡å­è®¡ç®—çš„æ¡¥æ¢ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡ºç†µé©±åŠ¨çš„è‡ªé€‚åº”é‡å­ç”µè·¯æ¶æ„  
è¯¥æ¶æ„é€šè¿‡å¯å˜æ·±åº¦é‡å­ç”µè·¯æ¡¥æ¥ç»å…¸ä¸é‡å­æ³¨æ„åŠ›æœºåˆ¶ã€‚æ¡†æ¶å®æ—¶åˆ†æè¾“å…¥å¤æ‚åº¦ï¼ˆä¾ç†µåˆ¤æ–­ï¼Œä½ç†µå¯¹åº”ç®€å•è¯­è¨€æ¨¡å¼ï¼Œé«˜ç†µå¯¹åº”å¤æ‚è¯­ä¹‰å…³ç³»ï¼‰ï¼Œåœ¨ç»å…¸å’Œé‡å­å¤„ç†é—´åè°ƒæ— ç¼è¿‡æ¸¡ã€‚å¤„ç†ä½ç†µç®€å•è¯­è¨€æ¨¡å¼æ—¶ä»¥ç»å…¸æ¨¡å¼ä¸ºä¸»ã€å°‘é‡å­å¢å¼ºï¼›é¢å¯¹é«˜ç†µã€ç»å…¸Transformeré‡è®¡ç®—ç“¶é¢ˆçš„å¤æ‚è¯­ä¹‰å…³ç³»ï¼Œé€šè¿‡ç²¾å¿ƒæ ¡å‡†çš„çº ç¼ æ¨¡å¼é€æ­¥çº³å…¥é‡å­èµ„æºï¼Œè¿˜èƒ½è§„é¿ barren plateaus é—®é¢˜ï¼Œåœ¨ NISQ çº¦æŸä¸‹å®ç°æ— ç¼é›†æˆã€‚

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¼•å…¥é‡å­å­˜å‚¨åº“ï¼ˆquantum memory banksï¼‰  
å°†ç»å…¸é”®å€¼æ³¨æ„åŠ›ä¸åŸºäºé‡å­æ€çš„ç›¸ä¼¼æ€§æ£€ç´¢ç›¸ç»Ÿä¸€ï¼Œåˆ›å»ºäº†ä¸€ä¸ªç»å…¸å’Œé‡å­å¤„ç†å™¨éƒ½èƒ½è®¿é—®å’Œæ“ä½œçš„å…±äº«è¡¨ç¤ºæ¡†æ¶ï¼Œä¸ºä¸¤ç§èŒƒå¼æ­å»ºäº†å…±åŒçš„è¡¨ç¤ºç©ºé—´ï¼ŒåŠ©åŠ›ä¿¡æ¯äº¤äº’ä¸ååŒã€‚

ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šå¼€å‘æ™ºèƒ½é‡å­ - ç»å…¸èåˆæœºåˆ¶  
åœ¨ç»å…¸å’Œé‡å­å¤„ç†å™¨ä¹‹é—´å»ºç«‹åŒå‘ä¿¡æ¯æµï¼Œè®©ä¸¤ç§è®¡ç®—èŒƒå¼å¤„ç†å„è‡ªå¤©ç„¶æ“…é•¿çš„ä»»åŠ¡ï¼Œä¿éšœè·¨ç»å…¸ - é‡å­è¾¹ç•Œçš„è®¡ç®—ä¸€è‡´æ€§ï¼Œåœ¨å®ç°æœ‰ç«äº‰åŠ›æ€§èƒ½çš„åŒæ—¶ï¼Œå¼€åˆ›ä¸‹ä¸€ä»£è¯­è¨€æ¨¡å‹æ‰€éœ€çš„æ¶æ„æ¨¡å¼ã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAQCF å®ç°äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—æå‡äº†é‡å­èµ„æºæ•ˆç‡ï¼Œä¸”èƒ½åœ¨å…¸å‹ NISQ çº¦æŸä¸‹æˆåŠŸè¿è¡Œï¼Œè¯æ˜äº†åœ¨å½“å‰ç¡¬ä»¶ä¸Šç»å…¸ä¸é‡å­è®¡ç®—å®ç”¨é›†æˆçš„å¯è¡Œæ€§ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»æŠ€æœ¯åˆ›æ–°è§’åº¦ï¼Œç†µé©±åŠ¨è‡ªé€‚åº”ã€é‡å­å­˜å‚¨åº“ã€æ™ºèƒ½èåˆæœºåˆ¶ç­‰è®¾è®¡æ€è·¯ï¼Œä¸ºè·¨èŒƒå¼ï¼ˆç»å…¸ - é‡å­ï¼‰çš„æ¨¡å‹èåˆæä¾›äº†æ–°çš„æ¨¡å—è®¾è®¡å‚è€ƒï¼Œæ¯”å¦‚å¦‚ä½•ä¾æ®æ•°æ®ç‰¹å¾åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºã€å¦‚ä½•æ„å»ºå…±äº«è¡¨ç¤ºç©ºé—´ç­‰ï¼›ä»å‘å±•è·¯å¾„çœ‹ï¼ŒAQCF ä¸ºä»å½“ä¸‹ç»å…¸LLMsåˆ°æœªæ¥é‡å­å¢å¼ºæ¨¡å‹æ­å»ºäº†æ— ç¼é›†æˆè·¯å¾„ï¼Œæ—¢åœ¨å½“å‰é‡å­ç¡¬ä»¶ä¸Šæœ‰å³æ—¶å®ç”¨ä»·å€¼ï¼Œåˆä¸ºé‡å­æŠ€æœ¯æˆç†Ÿåè¿ˆå‘å®Œæ•´é‡å­å¤§è¯­è¨€æ¨¡å‹ï¼ˆQuantum LLMsï¼‰æ˜ç¡®äº†æ¼”è¿›æ–¹å‘ï¼Œä¸ºé¢†åŸŸå†…åç»­æ¢ç´¢ç»å…¸ä¸é‡å­ç»“åˆçš„æ¨¡å‹æä¾›äº†æ¶æ„è®¾è®¡å’Œå‘å±•è·¯çº¿ä¸Šçš„å€Ÿé‰´ã€‚ 

## amft--aligning-llm-reasoners-by-meta-learning-the-optimal-imitation-exploration-balance
### Abstract
Large Language Models (LLMs) are typically fine-tuned for reasoning tasks
through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by
Reinforcement Learning (RL), a process fraught with catastrophic forgetting and
suboptimal trade-offs between imitation and exploration. Recent single-stage
methods attempt to unify SFT and RL using heuristics, but lack a principled
mechanism for dynamically balancing the two paradigms. In this paper, we
reframe this challenge through the theoretical lens of \textbf{implicit
rewards}, viewing SFT and RL not as distinct methods but as complementary
reward signals. We introduce \textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel
single-stage algorithm that learns the optimal balance between SFT's implicit,
path-level reward and RL's explicit, outcome-based reward. The core of AMFT is
a \textbf{meta-gradient adaptive weight controller} that treats the SFT-RL
balance as a learnable parameter, dynamically optimizing it to maximize
long-term task performance. This forward-looking approach, regularized by
policy entropy for stability, autonomously discovers an effective training
curriculum. We conduct a comprehensive evaluation on challenging benchmarks
spanning mathematical reasoning, abstract visual reasoning (General Points),
and vision-language navigation (V-IRL). AMFT consistently establishes a new
state-of-the-art and demonstrats superior generalization on out-of-distribution
(OOD) tasks. Ablation studies and training dynamic analysis confirm that the
meta-learning controller is crucial for AMFT's stability, sample efficiency,
and performance, offering a more principled and effective paradigm for LLM
alignment. Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.
### ğŸŒŸ è®ºæ–‡è§£è¯» | AMFTï¼šå…ƒå­¦ä¹ æœ€ä¼˜æ¨¡ä»¿-æ¢ç´¢å¹³è¡¡ï¼Œå¯¹é½å¤§æ¨¡å‹æ¨ç†èƒ½åŠ›

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†ä»»åŠ¡å¾®è°ƒæ—¶ï¼Œå¸¸ç”¨â€œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰+å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰â€ä¸¤é˜¶æ®µ pipelineï¼Œä½†å­˜åœ¨è¯¸å¤šé—®é¢˜ï¼šä¸€æ˜¯é˜¶æ®µé—´ç›®æ ‡çªå˜æ˜“å¼•å‘ç¾éš¾æ€§é—å¿˜ï¼›äºŒæ˜¯æ¨¡ä»¿ï¼ˆSFTï¼‰ä¸æ¢ç´¢ï¼ˆRLï¼‰é—´çš„æƒè¡¡ä¸å¤Ÿç†æƒ³ã€‚è¿‘å¹´å•é˜¶æ®µæ–¹æ³•å°è¯•æ•´åˆ SFT å’Œ RLï¼Œå´ä¾èµ–å¯å‘å¼è§„åˆ™ï¼Œç¼ºä¹åŠ¨æ€å¹³è¡¡äºŒè€…çš„åŸåˆ™æ€§æœºåˆ¶ã€‚åŸºäºæ­¤ï¼Œè®ºæ–‡ä»**éšå¼å¥–åŠ±**ç†è®ºè§†è§’é‡æ–°å®¡è§†è¯¥æŒ‘æˆ˜ï¼Œå°† SFT å’Œ RL è§†ä¸ºäº’è¡¥å¥–åŠ±ä¿¡å·ï¼Œæå‡º Adaptive Meta Fine - Tuningï¼ˆAMFTï¼‰æ–¹æ³•ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šé‡æ–°æ¡†æ¶é—®é¢˜ä¸ç»Ÿä¸€è§†è§’  
æŠŠ SFT å’Œ RL ä»â€œä¸åŒå­¦ä¹ èŒƒå¼â€é‡æ–°å®šä¹‰ä¸ºâ€œäº’è¡¥å¥–åŠ±ä¿¡å·â€ã€‚SFT ä¼˜åŒ–éšå¼ã€è·¯å¾„çº§å¥–åŠ±ï¼ˆé¼“åŠ±ç±»äººæ¨ç†ç»“æ„ï¼‰ï¼ŒRL ä¼˜åŒ–æ˜¾å¼ã€åŸºäºç»“æœçš„å¥–åŠ±ï¼ˆç„å‡†æ­£ç¡®æ€§ï¼‰ï¼Œæ ¸å¿ƒæŒ‘æˆ˜è½¬åŒ–ä¸ºå­¦ä¹ ä¸¤ç§äº’è¡¥å¥–åŠ±ä¿¡å·çš„æœ€ä¼˜ç»„åˆã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šæå‡º AMFT ç®—æ³•ä¸å…ƒæ¢¯åº¦è‡ªé€‚åº”æƒé‡æ§åˆ¶å™¨  
AMFT æ˜¯å•é˜¶æ®µç®—æ³•ï¼Œæ ¸å¿ƒä¸º**å…ƒæ¢¯åº¦è‡ªé€‚åº”æƒé‡æ§åˆ¶å™¨**ã€‚è¯¥æ§åˆ¶å™¨å°† SFT - RL å¹³è¡¡è§†ä¸ºå¯å­¦ä¹ å‚æ•° Î¼ï¼Œå€ŸåŠ©å…ƒä¼˜åŒ–ç­–ç•¥ï¼ŒåŸºäºé•¿æœŸéªŒè¯ç›®æ ‡è®¡ç®—çš„å…ƒæ¢¯åº¦æ›´æ–° Î¼ï¼Œä»¥æ­¤å­¦ä¹ åŠ¨æ€è®­ç»ƒè¯¾ç¨‹æ¥æœ€å¤§åŒ–æœ€ç»ˆä»»åŠ¡æ€§èƒ½ã€‚ç›´è§‚æ¥çœ‹ï¼Œç­–ç•¥ä¸ç¨³å®šæ—¶ä¼˜å…ˆ SFT éšå¼å¥–åŠ±é”šå®šåˆç†æ¨ç†æ¨¡å¼ï¼›æ¨¡å‹èƒ½åŠ›æå‡åï¼Œè½¬å‘ RL æ˜¾å¼å¥–åŠ±é¼“åŠ±æ¢ç´¢æ›´ä¼˜è§£ã€‚åŒæ—¶ï¼Œç”¨ç­–ç•¥ç†µæ­£åˆ™åŒ–ä¿éšœç¨³å®šæ€§ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨æ•°å­¦æ¨ç†ã€æŠ½è±¡è§†è§‰æ¨ç†ï¼ˆGeneral Pointsï¼‰ã€è§†è§‰ - è¯­è¨€å¯¼èˆªï¼ˆV - IRLï¼‰ç­‰å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒAMFT æŒç»­åˆ·æ–°å½“å‰æœ€ä¼˜ï¼ˆSOTAï¼‰ï¼Œä¸”åœ¨åˆ†å¸ƒå¤–ï¼ˆOODï¼‰ä»»åŠ¡ä¸Šæ³›åŒ–æ€§æ›´å¼ºã€‚æ¶ˆèå®éªŒä¸è®­ç»ƒåŠ¨æ€åˆ†æè¯å®ï¼Œå…ƒå­¦ä¹ æ§åˆ¶å™¨å¯¹ AMFT çš„ç¨³å®šæ€§ã€æ ·æœ¬æ•ˆç‡å’Œæ€§èƒ½è‡³å…³é‡è¦ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. è§†è§’åˆ›æ–°ï¼šä»éšå¼å¥–åŠ±è§’åº¦ç»Ÿä¸€ SFT å’Œ RL ç†è§£ï¼Œä¸ºå¤§æ¨¡å‹å¯¹é½æä¾›æ–°ç†è®ºè§†è§’ï¼Œè·³å‡ºå°†äºŒè€…è§†ä¸ºä¸åŒèŒƒå¼çš„ä¼ ç»Ÿæ€ç»´ã€‚  
2. æ–¹æ³•åˆ›æ–°ï¼šå…ƒæ¢¯åº¦è‡ªé€‚åº”æƒé‡æ§åˆ¶å™¨çš„è®¾è®¡ï¼Œä¸ºåŠ¨æ€å¹³è¡¡æ¨¡ä»¿ä¸æ¢ç´¢æä¾›äº†åŸåˆ™æ€§ã€å‰ç»æ€§çš„ä¼˜åŒ–æ–¹å¼ï¼Œç›¸æ¯”è¿‡å¾€å¯å‘å¼ã€ååº”å¼æœºåˆ¶æ›´å…·ä¼˜åŠ¿ï¼Œåç»­å¤§æ¨¡å‹å¤šé˜¶æ®µå¾®è°ƒæˆ–æ•´åˆä¼˜åŒ–æ–¹å‘å¯å€Ÿé‰´æ­¤åŠ¨æ€å¹³è¡¡æ€è·¯ã€‚  
3. å®éªŒå…¨é¢æ€§ï¼šè·¨å¤šé¢†åŸŸï¼ˆæ•°å­¦ã€è§†è§‰ã€è§†è§‰ - è¯­è¨€ï¼‰åŸºå‡†æµ‹è¯•éªŒè¯æ–¹æ³•æ™®é€‚æ€§ï¼Œä¸ºç›¸å…³ä»»åŠ¡çš„æ¨¡å‹ä¼˜åŒ–æä¾›äº†æœ‰æ•ˆå‚è€ƒèŒƒå¼ï¼Œåç»­åœ¨å¤æ‚å¤šæ¨¡æ€æˆ–ç¨€ç–å¥–åŠ±åœºæ™¯ä¸‹çš„æ¨¡å‹è®­ç»ƒå¯å‚è€ƒå…¶å®éªŒè®¾è®¡ä¸æ–¹æ³•åº”ç”¨æ€è·¯ã€‚  
4. å¼€æºä¼˜åŠ¿ï¼šä»£ç å¼€æºï¼ˆhttps://github.com/hlxtsyj/AMFTï¼‰ï¼Œä¾¿äºç¤¾åŒºåŸºäºæ­¤æ–¹æ³•è¿›ä¸€æ­¥ç ”ç©¶ä¸æ”¹è¿›ï¼Œæ¨åŠ¨é¢†åŸŸå‘å±•ã€‚

## bixse--improving-dense-retrieval-via-probabilistic-graded-relevance-distillation
### Abstract
Neural sentence embedding models for dense retrieval typically rely on binary
relevance labels, treating query-document pairs as either relevant or
irrelevant. However, real-world relevance often exists on a continuum, and
recent advances in large language models (LLMs) have made it feasible to scale
the generation of fine-grained graded relevance labels. In this work, we
propose BiXSE, a simple and effective pointwise training method that optimizes
binary cross-entropy (BCE) over LLM-generated graded relevance scores. BiXSE
interprets these scores as probabilistic targets, enabling granular supervision
from a single labeled query-document pair per query. Unlike pairwise or
listwise losses that require multiple annotated comparisons per query, BiXSE
achieves strong performance with reduced annotation and compute costs by
leveraging in-batch negatives. Extensive experiments across sentence embedding
(MMTEB) and retrieval benchmarks (BEIR, TREC-DL) show that BiXSE consistently
outperforms softmax-based contrastive learning (InfoNCE), and matches or
exceeds strong pairwise ranking baselines when trained on LLM-supervised data.
BiXSE offers a robust, scalable alternative for training dense retrieval models
as graded relevance supervision becomes increasingly accessible.
### ğŸŒŸ è®ºæ–‡è§£è¯» | BiXSEï¼šå€ŸåŠ©æ¦‚ç‡åŒ–åˆ†çº§ç›¸å…³æ€§è’¸é¦æå‡ dense retrieval æ€§èƒ½

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
åœ¨ dense retrieval é¢†åŸŸï¼Œç”¨äºè®­ç»ƒå¥å­åµŒå…¥æ¨¡å‹çš„ä¼ ç»Ÿæ–¹æ³•ä¾èµ–**äºŒå…ƒç›¸å…³æ€§æ ‡ç­¾**ï¼ŒæŠŠæŸ¥è¯¢ - æ–‡æ¡£å¯¹ç®€å•åˆ’åˆ†ä¸ºç›¸å…³æˆ–ä¸ç›¸å…³ã€‚ä½†ç°å®ä¸­ç›¸å…³æ€§æ˜¯è¿ç»­æ¸å˜çš„ï¼Œè¿™ç§äºŒå…ƒåˆ’åˆ†å­˜åœ¨å±€é™ï¼šä¸€æ–¹é¢ï¼Œéƒ¨åˆ†ç›¸å…³çš„æ–‡æ¡£ä¼šè¢«å½“ä½œå®Œå…¨ä¸ç›¸å…³å¤„ç†ï¼Œé€ æˆè®­ç»ƒæ•°æ®é‡Œçš„â€œå‡é˜´æ€§â€é—®é¢˜ï¼›å¦ä¸€æ–¹é¢ï¼Œäººå·¥æ ‡æ³¨ç»†ç²’åº¦çš„åˆ†çº§ç›¸å…³æ€§æˆæœ¬å¾ˆé«˜ï¼Œé™åˆ¶äº†æ•°æ®é›†è§„æ¨¡ã€‚è€Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•è®©å¤§è§„æ¨¡ç”Ÿæˆç»†ç²’åº¦åˆ†çº§ç›¸å…³æ€§æ ‡ç­¾æˆä¸ºå¯èƒ½ï¼Œå› æ­¤éœ€è¦æ–°æ–¹æ³•åˆ©ç”¨è¿™äº›æ ‡ç­¾ä¼˜åŒ– dense retrieval æ¨¡å‹ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šæå‡º BiXSE è®­ç»ƒæ–¹æ³•  
BiXSE æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„**ç‚¹å‘ï¼ˆpointwiseï¼‰è®­ç»ƒæ–¹æ³•**ï¼Œå®ƒé’ˆå¯¹ LLM ç”Ÿæˆçš„åˆ†çº§ç›¸å…³æ€§åˆ†æ•°ä¼˜åŒ–äºŒå…ƒäº¤å‰ç†µï¼ˆBCEï¼‰æŸå¤±ã€‚å°†åˆ†çº§ç›¸å…³æ€§åˆ†æ•°è§£è¯»ä¸º [0,1] èŒƒå›´å†…çš„æ¦‚ç‡ç›®æ ‡ï¼Œä»¥æ­¤ä½“ç°ä»å®Œå…¨ä¸ç›¸å…³ï¼ˆ0ï¼‰åˆ°ç»å¯¹ç›¸å…³ï¼ˆ1ï¼‰çš„è¿ç»­ç›¸å…³æ€§ï¼Œè®©æ¯ä¸ªæŸ¥è¯¢ä»…ç”¨å•ä¸ªå¸¦æ ‡ç­¾çš„æŸ¥è¯¢ - æ–‡æ¡£å¯¹å°±èƒ½è·å¾—ç»†ç²’åº¦ç›‘ç£ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç»“åˆ batch å†…è´Ÿæ ·æœ¬é™ä½æˆæœ¬  
ä¸åŒäº pairwise æˆ– listwise æŸå¤±éœ€è¦æ¯ä¸ªæŸ¥è¯¢å¯¹åº”å¤šä¸ªå¸¦æ ‡æ³¨çš„æ¯”è¾ƒæ ·æœ¬ï¼ŒBiXSE å€ŸåŠ© **in - batch negatives**ï¼ˆæ‰¹å†…è´Ÿæ ·æœ¬ï¼‰ï¼Œåœ¨æ¯ä¸ªæŸ¥è¯¢ä»…ç”¨å•ä¸ªæ ‡æ³¨å¯¹çš„æƒ…å†µä¸‹å®ç°è‰¯å¥½æ€§èƒ½ï¼ŒåŒæ—¶å‡å°‘äº†æ ‡æ³¨å’Œè®¡ç®—æˆæœ¬ã€‚  


### ğŸ“ˆ å®éªŒç»“æœ
åœ¨å¥å­åµŒå…¥åŸºå‡†ï¼ˆMMTEBï¼‰å’Œæ£€ç´¢åŸºå‡†ï¼ˆBEIRã€TREC - DLï¼‰ä¸Šå¼€å±•å¤§é‡å®éªŒï¼Œç»“æœæ˜¾ç¤ºï¼š  
- BiXSE æŒç»­è¶…è¶ŠåŸºäº softmax çš„å¯¹æ¯”å­¦ä¹ ï¼ˆInfoNCEï¼‰æ–¹æ³•ï¼›  
- åœ¨ LLM ç›‘ç£æ•°æ®ä¸Šè®­ç»ƒæ—¶ï¼ŒBiXSE èƒ½åŒ¹é…ç”šè‡³è¶…è¿‡å¼ºå¤§çš„ pairwise æ’åºåŸºçº¿ï¼›  
- ä¸ InfoNCE ç›¸æ¯”ï¼ŒBiXSE å¯¹æ ‡ç­¾å™ªå£°å±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼ˆå¦‚åœ¨æ¨¡æ‹Ÿæ ‡ç­¾ç¿»è½¬å®éªŒä¸­æ€§èƒ½æ›´ä¼˜ï¼‰ï¼›  
- åœ¨å¤šè¯­è¨€ã€ä¸åŒæ¨¡å‹è§„æ¨¡åœºæ™¯ä¸‹ï¼ˆå¦‚ QWEN2.5 ç³»åˆ—æ¨¡å‹ï¼‰ï¼ŒBiXSE ä¹Ÿå±•ç°å‡ºä¼˜åŠ¿ï¼Œèƒ½é€¼è¿‘æ›´å¤§è§„æ¨¡é›¶æ ·æœ¬ LLM æ’åºå™¨çš„æ€§èƒ½ã€‚  


### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. åˆ©ç”¨ LLM ç”Ÿæˆç»†ç²’åº¦æ ‡ç­¾çš„æ€è·¯ï¼šå€ŸåŠ© LLM è§„æ¨¡åŒ–ç”Ÿæˆåˆ†çº§ç›¸å…³æ€§æ ‡ç­¾ï¼Œä¸º dense retrieval æ¨¡å‹æä¾›æ›´ç»†ç²’åº¦ç›‘ç£ä¿¡å·ï¼Œçªç ´ä¼ ç»ŸäºŒå…ƒæ ‡ç­¾å±€é™ï¼›  
2. ç‚¹å‘è®­ç»ƒèŒƒå¼çš„ä»·å€¼ï¼šBiXSE è¯æ˜ç‚¹å‘è®­ç»ƒåœ¨åˆ©ç”¨åˆ†çº§æ ‡ç­¾æ—¶èƒ½ä»¥æ›´ä½æ ‡æ³¨æˆæœ¬å®ç°å¼ºæ€§èƒ½ï¼Œä¸ºåç»­æ£€ç´¢æ¨¡å‹è®­ç»ƒèŒƒå¼æä¾›æ–°æ–¹å‘ï¼›  
3. é²æ£’æ€§è®¾è®¡ï¼šé€šè¿‡å°†åˆ†çº§åˆ†æ•°è½¬åŒ–ä¸ºæ¦‚ç‡å¹¶ç»“åˆ in - batch negativesï¼Œæå‡æ¨¡å‹å¯¹å™ªå£°å’Œæ•°æ®åˆ†å¸ƒå˜åŒ–çš„é€‚åº”èƒ½åŠ›ï¼Œè¿™ç§é²æ£’æ€§ä¼˜åŒ–æ€è·¯å¯è¿ç§»åˆ°å…¶ä»–éœ€è¦å¤„ç†å™ªå£°æ ‡ç­¾æˆ–ä¸å®Œç¾ç›‘ç£çš„ä»»åŠ¡ä¸­ã€‚  

## conformal-sets-in-multiple-choice-question-answering-under-black-box-settings-with-provable-coverage-guarantees
### Abstract
Large Language Models (LLMs) have shown remarkable progress in
multiple-choice question answering (MCQA), but their inherent unreliability,
such as hallucination and overconfidence, limits their application in high-risk
domains. To address this, we propose a frequency-based uncertainty
quantification method under black-box settings, leveraging conformal prediction
(CP) to ensure provable coverage guarantees. Our approach involves multiple
independent samplings of the model's output distribution for each input, with
the most frequent sample serving as a reference to calculate predictive entropy
(PE). Experimental evaluations across six LLMs and four datasets (MedMCQA,
MedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms
logit-based PE in distinguishing between correct and incorrect predictions, as
measured by AUROC. Furthermore, the method effectively controls the empirical
miscoverage rate under user-specified risk levels, validating that sampling
frequency can serve as a viable substitute for logit-based probabilities in
black-box scenarios. This work provides a distribution-free model-agnostic
framework for reliable uncertainty quantification in MCQA with guaranteed
coverage, enhancing the trustworthiness of LLMs in practical applications.
### ğŸŒŸ è®ºæ–‡è§£è¯» | é»‘ç›’åœºæ™¯ä¸‹å¸¦å¯è¯æ˜è¦†ç›–ä¿è¯çš„å¤šé€‰é—®ç­” conformal é›†åˆæ–¹æ³•

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šé€‰é—®ç­”ï¼ˆMCQAï¼‰ä»»åŠ¡ä¸­å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†å¹»è§‰ã€è¿‡åº¦è‡ªä¿¡ç­‰å›ºæœ‰ä¸å¯é æ€§é™åˆ¶äº†å…¶åœ¨åŒ»ç–—ã€é‡‘èç­‰é«˜é£é™©é¢†åŸŸçš„åº”ç”¨ã€‚ä¼ ç»ŸåŸºäº logit çš„ä¸ç¡®å®šæ€§é‡åŒ–åœ¨é»‘ç›’åœºæ™¯ä¸‹å­˜åœ¨å±€é™ï¼Œè€Œ conformal predictionï¼ˆCPï¼‰è™½èƒ½æä¾›å¯é ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œä½†éœ€é€‚é…é»‘ç›’è®¾å®šä¸‹ LLM è¾“å‡ºçš„ç‰¹ç‚¹ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨æå‡ºé»‘ç›’åœºæ™¯ä¸‹åŸºäºé¢‘ç‡çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ï¼Œåˆ©ç”¨ CP ç¡®ä¿å¯è¯æ˜çš„è¦†ç›–ä¿è¯ï¼Œæå‡ LLM åœ¨ MCQA ä»»åŠ¡ä¸­çš„å¯ä¿¡åº¦ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šåŸºäºé¢‘ç‡çš„ä¸ç¡®å®šæ€§é‡åŒ–æ€è·¯  
é’ˆå¯¹æ¯ä¸ªè¾“å…¥ï¼Œå¯¹æ¨¡å‹è¾“å‡ºåˆ†å¸ƒè¿›è¡Œå¤šæ¬¡ç‹¬ç«‹é‡‡æ ·ï¼Œä»¥æœ€é¢‘ç¹å‡ºç°çš„æ ·æœ¬ï¼ˆæ¨¡æ€è¾“å‡ºï¼‰æ›¿ä»£ä¼ ç»ŸåŸºäºæœ€å¤§æ¦‚ç‡ï¼ˆlogit ç±»ï¼‰çš„ç‚¹é¢„æµ‹ä½œä¸ºå‚è€ƒï¼Œè®¡ç®—é¢„æµ‹ç†µï¼ˆPEï¼‰ã€‚é€šè¿‡å¤šæ¬¡é‡‡æ ·çš„è¾“å‡ºå˜å¼‚æ€§åæ˜ æ¨¡å‹å¯¹ç‰¹å®šè¾“å…¥çš„é¢„æµ‹ç½®ä¿¡åº¦ï¼Œæ ·æœ¬åœ¨æ¨¡æ€å‘¨å›´é›†ä¸­åº¦é«˜åˆ™ä¸ç¡®å®šæ€§ä½ï¼Œåˆ†æ•£åˆ™ä¸ç¡®å®šæ€§é«˜ã€‚  

ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šç»“åˆ conformal prediction ä¿éšœè¦†ç›–æ€§  
å€ŸåŠ© conformal prediction æ¡†æ¶ï¼Œåœ¨ä¸å‡è®¾æ•°æ®åˆ†å¸ƒçš„å‰æä¸‹ï¼ŒåŸºäºâ€œé conformity åˆ†æ•°â€å¯¹æ–°æŸ¥è¯¢å½¢æˆé¢„æµ‹é›†åˆï¼Œç¡®ä¿é¢„æµ‹é›†åˆåŒ…å«çœŸå®å€¼çš„ç”¨æˆ·æŒ‡å®šè¦†ç›–æ¦‚ç‡ï¼Œä¸ºé»‘ç›’åœºæ™¯ä¸‹ LLM çš„ MCQA é¢„æµ‹æä¾›åˆ†å¸ƒæ— å…³ã€éæ¸è¿‘çš„é£é™©æ§åˆ¶ä¸å¯é æ€§ä¿è¯ã€‚  

### ğŸ“ˆ å®éªŒç»“æœ
å®éªŒè¦†ç›– 6 ä¸ª LLM å’Œ 4 ä¸ªæ•°æ®é›†ï¼ˆMedMCQAã€MedQAã€MMLUã€MMLU - Proï¼‰ï¼Œä» AUROC æŒ‡æ ‡çœ‹ï¼ŒåŸºäºé¢‘ç‡çš„ PE åœ¨åŒºåˆ†æ¨¡å‹æ­£ç¡®ä¸é”™è¯¯é¢„æµ‹ä¸Šè¡¨ç°ä¼˜äºåŸºäº logit çš„ PEï¼ˆå¦‚ Qwen2.5 - 3B - Instruct æ¨¡å‹ + MedMCQA æ•°æ®é›†ç»„åˆä¸­ï¼Œé¢‘ç‡æ³• AUROC æ¯” logit æ³•é«˜ 2%ï¼‰ï¼›åœ¨ç”¨æˆ·æŒ‡å®šé£é™©æ°´å¹³ä¸‹ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæ§åˆ¶ç»éªŒæ€§â€œè¯¯è¦†ç›–ç‡â€ï¼ŒéªŒè¯äº†é»‘ç›’åœºæ™¯ä¸‹é‡‡æ ·é¢‘ç‡å¯ä½œä¸ºåŸºäº logit æ¦‚ç‡çš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆç”¨äºä¸ç¡®å®šæ€§é‡åŒ–ã€‚  

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
1. æ–¹æ³•å±‚é¢ï¼šæå‡ºçš„é»‘ç›’åœºæ™¯ä¸‹åŸºäºé¢‘ç‡çš„ä¸ç¡®å®šæ€§é‡åŒ– + CP æ¡†æ¶ï¼Œä¸º MCQA ä»»åŠ¡æä¾›äº† distribution - freeã€æ¨¡å‹æ— å…³çš„å¯é ä¸ç¡®å®šæ€§é‡åŒ–èŒƒå¼ï¼Œå¯æ¨å¹¿åˆ°å…¶ä»–é»‘ç›’ AI ç³»ç»Ÿçš„ä¸ç¡®å®šæ€§è¯„ä¼°åœºæ™¯ã€‚  
2. å®éªŒè®¾è®¡ï¼šå¤šæ¨¡å‹ã€å¤šæ•°æ®é›†çš„å…¨é¢å®éªŒéªŒè¯æ€è·¯ï¼Œä¸ºåç»­ç±»ä¼¼å¯é æ€§è¯„ä¼°ç ”ç©¶æä¾›äº†å‚è€ƒèŒƒå¼ï¼Œèƒ½å¸®åŠ©ç ”ç©¶è€…æ›´ç³»ç»Ÿåœ°å¯¹æ¯”ä¸åŒä¸ç¡®å®šæ€§é‡åŒ–ç­–ç•¥ã€‚  
3. åº”ç”¨ä»·å€¼ï¼šé’ˆå¯¹é«˜é£é™©é¢†åŸŸ LLM å¯é æ€§ä¸è¶³çš„ç—›ç‚¹ï¼Œæä¾›äº†æå‡å¯ä¿¡åº¦çš„æŠ€æœ¯è·¯å¾„ï¼ŒåŠ©åŠ› LLM åœ¨åŒ»ç–—ã€é‡‘èç­‰é¢†åŸŸæ›´å®‰å…¨åœ°è½åœ°ã€‚

## sonar-llm--autoregressive-transformer-that-thinks-in-sentence-embeddings-and-speaks-in-tokens
### Abstract
The recently proposed Large Concept Model (LCM) generates text by predicting
a sequence of sentence-level embeddings and training with either mean-squared
error or diffusion objectives. We present SONAR-LLM, a decoder-only transformer
that "thinks" in the same continuous SONAR embedding space, yet is supervised
through token-level cross-entropy propagated via the frozen SONAR decoder. This
hybrid objective retains the semantic abstraction of LCM while eliminating its
diffusion sampler and restoring a likelihood-based training signal. Across
model sizes from 39M to 1.3B parameters, SONAR-LLM attains competitive
generation quality. We report scaling trends, ablations, benchmark results, and
release the complete training code and all pretrained checkpoints to foster
reproducibility and future research.
### ğŸŒŸ è®ºæ–‡è§£è¯» | SONAR - LLMï¼šåœ¨å¥åµŒå…¥ä¸­æ€è€ƒï¼Œä»¥tokensè¡¨è¾¾çš„è‡ªå›å½’Transformer

### ğŸ“Œ èƒŒæ™¯ç—›ç‚¹/æœ¬æ–‡åŠ¨æœº
å½“å‰å¤šæ•°è‡ªå›å½’è¯­è¨€æ¨¡å‹é€tokenå­¦ä¹ ï¼Œè™½è®­ç»ƒè¯„ä¼°ç®€å•ï¼Œä½†é•¿åºåˆ—ç”Ÿæˆæ—¶ååé‡æˆç“¶é¢ˆã€‚Metaæå‡ºçš„Large Concept Modelï¼ˆLCMï¼‰é€šè¿‡é¢„æµ‹å¥å­çº§åµŒå…¥è½¨è¿¹è§£å†³å»¶è¿Ÿé—®é¢˜ï¼Œå´å› ç§»é™¤tokençº§ä¼¼ç„¶è€Œè®©ä¼˜åŒ–ä¸ç¨³å®šã€‚æœ¬æ–‡æ—¨åœ¨ä¿ç•™LCMâ€œåŸºäºå¥åµŒå…¥æ€è€ƒâ€ä¼˜åŠ¿çš„åŒæ—¶ï¼Œåˆ©ç”¨äº¤å‰ç†µå­¦ä¹ çš„ä¼˜ç‚¹ï¼Œæå‡ºSONAR - LLMæ¨¡å‹ã€‚

### ğŸš€ æ ¸å¿ƒæ–¹æ³•ï¼ˆä»‹ç»æœ¬æ–‡çš„å‡ ä¸ªåˆ›æ–°ç‚¹ï¼‰
ğŸ’¡ åˆ›æ–°ç‚¹1ï¼šTokenæ„ŸçŸ¥çš„åµŒå…¥ç›®æ ‡  
å¼•å…¥ä¸€ç§è®­ç»ƒç›®æ ‡ï¼Œé€šè¿‡å†»ç»“çš„SONARè§£ç å™¨åå‘ä¼ æ’­tokençº§äº¤å‰ç†µï¼Œä½¿è¿ç»­é¢„æµ‹ä¸ç¦»æ•£ç›®æ ‡å¯¹é½ã€‚å³å…ˆé¢„æµ‹SONARå¥åµŒå…¥ï¼Œå†é€šè¿‡å†»ç»“çš„SONARè§£ç å™¨å°†æŸå¤±ä¼ æ’­åˆ°å•ä¸ªtokenï¼ŒæŠŠè¿ç»­æ¨ç†å’Œç¦»æ•£ç›‘ç£è€¦åˆèµ·æ¥ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹2ï¼šå¤šç»´åº¦åˆ†æä¸å¼€æºå‘å¸ƒ  
è¿›è¡Œç¼©æ”¾å®šå¾‹åˆ†æï¼Œä¸ºä¸åŒæ¨¡å‹è§„æ¨¡çš„éªŒè¯æŸå¤±æä¾›è¯¦ç»†çš„ç¼©æ”¾å®šå¾‹æ‹Ÿåˆï¼Œé‡åŒ–LLMã€LCMså’ŒSONAR - LLMæ¶æ„çš„ç¼©æ”¾æŒ‡æ•°ï¼›åœ¨æ‘˜è¦ä»»åŠ¡ä¸Šå¯¹æ¯”æ¨¡å‹æ€§èƒ½ï¼Œå±•ç¤ºSONAR - LLMåŒ¹é…æˆ–è¶…è¶Šå…¶ä»–å¥å­çº§æ–¹æ³•ï¼›åˆ†ææ¨ç†æ•ˆç‡ï¼Œä»ç†è®ºä¸Šåˆ†ææ¨ç†FLOPsï¼Œè¡¨æ˜åœ¨é•¿åºåˆ—ä¸ŠSONAR - LLMæ¯”æ ‡å‡†LLMè®¡ç®—æ•ˆç‡æ›´é«˜ï¼›åŒæ—¶å…¬å¼€æ‰€æœ‰è®­ç»ƒä»£ç ã€è¯„ä¼°è„šæœ¬å’Œæ¨¡å‹ checkpointï¼Œä¿ƒè¿›åç»­ç ”ç©¶ã€‚  
ğŸ’¡ åˆ›æ–°ç‚¹3ï¼šç‹¬ç‰¹çš„æ¨¡å‹æ¶æ„ä¸è®­ç»ƒæ¨ç†æœºåˆ¶  
SONAR - LLMæ˜¯ä»…è§£ç å™¨çš„è‡ªå›å½’Transformerï¼Œåœ¨SONARå¥åµŒå…¥ç©ºé—´æ“ä½œä¸”ç”¨tokençº§äº¤å‰ç†µç›‘ç£ã€‚æ–‡æœ¬å…ˆç»åˆ†å¥ã€SONARç¼–ç å™¨å¾—åˆ°å¥åµŒå…¥ï¼Œæ¨¡å‹æ ¹æ®å‰ç¼€å¥åµŒå…¥é¢„æµ‹ä¸‹ä¸€å¥åµŒå…¥ï¼Œå†ç”¨å†»ç»“çš„SONARè§£ç å™¨è§£ç ã€‚æ¨ç†æ—¶é€šè¿‡ç‰¹æ®Šçš„â€œEnd of sequence.â€å¥åµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦æˆ–å¥å­æ•°ä¸Šé™æ¥ç»ˆæ­¢ç”Ÿæˆã€‚

### ğŸ“ˆ å®éªŒç»“æœ
åœ¨æ¨¡å‹è§„æ¨¡ä»39Måˆ°1.3Bå‚æ•°èŒƒå›´å†…ï¼ŒSONAR - LLMå®ç°äº†æœ‰ç«äº‰åŠ›çš„ç”Ÿæˆè´¨é‡ã€‚ç¼©æ”¾å®šå¾‹åˆ†æå±•ç¤ºäº†ä¸åŒæ¨¡å‹ï¼ˆLLMã€MSE LCMã€Diffusion LCMã€SONAR - LLMï¼‰åœ¨ä¸åŒå‚æ•°è§„æ¨¡ä¸‹çš„éªŒè¯æŸå¤±åŠ¨æ€ï¼ŒSONAR - LLMåœ¨ä¿ç•™è¯­ä¹‰æŠ½è±¡åŒæ—¶æœ‰è‰¯å¥½çš„æŸå¤±è¡¨ç°ï¼›æ‘˜è¦ä»»åŠ¡ï¼ˆXSumå’ŒCNN/DMåŸºå‡†ï¼‰ä¸Šï¼Œå…¶æ€§èƒ½åŒ¹é…æˆ–è¶…è¿‡å…¶ä»–å¥å­çº§æ–¹æ³•ï¼›æ¨ç†FLOPsç†è®ºåˆ†ææ˜¾ç¤ºåœ¨é•¿åºåˆ—ä¸Šæ¯”æ ‡å‡†LLMè®¡ç®—æ•ˆç‡æ›´ä¼˜ã€‚

### ğŸ’¬ å¯å€Ÿé‰´ä¹‹å¤„
ä»æ–¹æ³•åˆ›æ–°çœ‹ï¼Œå°†è¿ç»­å¥åµŒå…¥é¢„æµ‹ä¸ç¦»æ•£tokenç›‘ç£ç»“åˆçš„æ€è·¯ï¼Œä¸ºè§£å†³é•¿åºåˆ—ç”Ÿæˆç“¶é¢ˆå’Œä¼˜åŒ–ä¸ç¨³å®šæ€§æä¾›äº†æ–°æ–¹å‘ï¼Œå¯å¯å‘åç»­è¯­è¨€æ¨¡å‹åœ¨è®­ç»ƒç›®æ ‡å’Œç›‘ç£æ–¹å¼ä¸Šçš„åˆ›æ–°ï¼›ä»åˆ†æç»´åº¦çœ‹ï¼Œå¯¹ç¼©æ”¾å®šå¾‹ã€æ¨ç†æ•ˆç‡ç­‰å¤šç»´åº¦çš„åˆ†ææ–¹å¼ï¼Œä¸ºæ¨¡å‹æ€§èƒ½è¯„ä¼°å’Œå¯¹æ¯”æä¾›äº†å…¨é¢çš„å‚è€ƒèŒƒå¼ï¼›ä»å¼€æºè§’åº¦ï¼Œå…¬å¼€ä»£ç å’Œé¢„è®­ç»ƒ checkpoint æœ‰åˆ©äºæ•´ä¸ªç¤¾åŒºåŸºäºæ­¤è¿›è¡Œå¤ç°å’Œè¿›ä¸€æ­¥ç ”ç©¶ï¼Œæ¨åŠ¨é¢†åŸŸå‘å±•ã€‚

