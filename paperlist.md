43. **[25/06] Customizing Speech Recognition Model with Large Language Model Feedback**

**[**[Paper](http://arxiv.org/pdf/2506.11091v1)] [[Code/Page](http://localhost:8501/)] [[TLDR/Notes](http://localhost:8501/#customizing-speech-recognition-model-with-large-language-model-feedback)]

44. **[25/06] Flattery, Fluff, and Fog: Diagnosing and Mitigating Idiosyncratic Biases in Preference Models**

**[**[Paper](http://arxiv.org/pdf/2506.05339v2)] [[Code/Page](http://localhost:8501/)] [[TLDR/Notes](http://localhost:8501/#flattery--fluff--and-fog--diagnosing-and-mitigating-idiosyncratic-biases-in-preference-models)]

45. **[25/06] A Smooth Sea Never Made a Skilled SAILORSAILOR: Robust Imitation via Learning to Search**

**[**[Paper](http://arxiv.org/pdf/2506.05294v1)] [[Code/Page](https://github.com/arnavkj1995/SAILOR)] [[TLDR/Notes](http://localhost:8501/#a-smooth-sea-never-made-a-skilled-$%5Ctexttt%7Bsailor%7D$--robust-imitation-via-learning-to-search)]

46. **[25/06] RewardAnything: Generalizable Principle-Following Reward Models**

**[**[Paper](http://arxiv.org/pdf/2506.03637v2)] [[Code/Page](http://localhost:8501/)] [[TLDR/Notes](http://localhost:8501/#rewardanything--generalizable-principle-following-reward-models)]

47. **[25/06] DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models**

**[**[Paper](http://arxiv.org/pdf/2506.03517v1)] [[Code/Page](http://localhost:8501/)] [[TLDR/Notes](http://localhost:8501/#densedpo--fine-grained-temporal-preference-optimization-for-video-diffusion-models)]

48. **[25/06] AUTOCIRCUIT-RL: Reinforcement Learning-Driven LLM for Automated Circuit Topology Generation**

**[**[Paper](http://arxiv.org/pdf/2506.03122v1)] [[Code/Page](http://localhost:8501/)] [[TLDR/Notes](http://localhost:8501/#autocircuit-rl--reinforcement-learning-driven-llm-for-automated-circuit-topology-generation)]

49. **[25/06] BadReward: Clean-Label Poisoning of Reward Models in Text-to-Image RLHF**

**[**[Paper](http://arxiv.org/pdf/2506.03234v1)] [[Code/Page](http://localhost:8501/)] [[TLDR/Notes](http://localhost:8501/#badreward--clean-label-poisoning-of-reward-models-in-text-to-image-rlhf)]

50. **[25/06] Smoothed Preference Optimization via ReNoise Inversion for Aligning Diffusion Models with Varied Human Preferences**

**[**[Paper](http://arxiv.org/pdf/2506.02698v2)] [[Code/Page](https://jaydenlyh.github.io/SmPO-project-page/)] [[TLDR/Notes](http://localhost:8501/#smoothed-preference-optimization-via-renoise-inversion-for-aligning-diffusion-models-with-varied-human-preferences)]
