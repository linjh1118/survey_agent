#!/usr/bin/env python3
"""
ç”Ÿæˆç”¨äºå±•ç¤ºçš„JSONæ•°æ®æ–‡ä»¶
å°†ç¼“å­˜çš„è®ºæ–‡æ•°æ®è½¬æ¢ä¸ºé™æ€ç½‘é¡µå¯ä»¥ä½¿ç”¨çš„æ ¼å¼
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any

def load_cached_papers() -> Dict[str, Any]:
    """åŠ è½½æ‰€æœ‰ç¼“å­˜çš„è®ºæ–‡æ•°æ®"""
    cache_files = [
        'cache/paper_summaries.json',
        'cache/demo_papers.json',
        'cache/demo_reports.json'
    ]
    
    all_papers = {}
    
    for cache_file in cache_files:
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        all_papers.update(data)
                        print(f"âœ… å·²åŠ è½½ {cache_file}: {len(data)} ç¯‡è®ºæ–‡")
                    else:
                        print(f"âš ï¸  è·³è¿‡ {cache_file}: æ ¼å¼ä¸æ­£ç¡®")
            except Exception as e:
                print(f"âŒ åŠ è½½ {cache_file} å¤±è´¥: {e}")
        else:
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {cache_file}")
    
    return all_papers

def process_papers_for_display(papers_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """å¤„ç†è®ºæ–‡æ•°æ®ä¸ºå±•ç¤ºæ ¼å¼"""
    display_papers = []
    
    for arxiv_id, paper_info in papers_data.items():
        # å¤„ç†ä¸åŒçš„æ•°æ®ç»“æ„
        if 'title' in paper_info and 'summary' in paper_info:
            # æ ‡å‡†æ ¼å¼
            processed_paper = {
                'arxiv_id': paper_info.get('arxiv_id', arxiv_id),
                'title': paper_info['title'],
                'summary': paper_info['summary'],
                'cached_at': format_date(paper_info.get('cached_at', '')),
                'content_hash': paper_info.get('content_hash', ''),
                'model_info': paper_info.get('model_info', {'provider': 'unknown', 'model_name': 'unknown'})
            }
            display_papers.append(processed_paper)
        else:
            print(f"âš ï¸  è·³è¿‡æ ¼å¼ä¸æ­£ç¡®çš„è®ºæ–‡: {arxiv_id}")
    
    # æŒ‰ç¼“å­˜æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
    display_papers.sort(key=lambda x: x['cached_at'], reverse=True)
    
    return display_papers

def format_date(date_str: str) -> str:
    """æ ¼å¼åŒ–æ—¥æœŸå­—ç¬¦ä¸²"""
    try:
        if date_str:
            # å°è¯•è§£æISOæ ¼å¼çš„æ—¥æœŸ
            dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            return dt.strftime('%Y-%m-%d %H:%M')
        else:
            return 'æœªçŸ¥æ—¶é—´'
    except:
        return date_str[:16] if len(date_str) >= 16 else date_str

def generate_display_json():
    """ç”Ÿæˆç”¨äºå±•ç¤ºçš„JSONæ–‡ä»¶"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆå±•ç¤ºæ•°æ®...")
    
    # åŠ è½½ç¼“å­˜çš„è®ºæ–‡æ•°æ®
    papers_data = load_cached_papers()
    print(f"ğŸ“š æ€»å…±åŠ è½½ {len(papers_data)} ç¯‡è®ºæ–‡")
    
    if not papers_data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è®ºæ–‡æ•°æ®")
        return
    
    # å¤„ç†æ•°æ®
    display_papers = process_papers_for_display(papers_data)
    print(f"âœ… å¤„ç†å®Œæˆ {len(display_papers)} ç¯‡æœ‰æ•ˆè®ºæ–‡")
    
    # ç”Ÿæˆå±•ç¤ºæ•°æ®
    display_data = {
        'generated_at': datetime.now().isoformat(),
        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M'),
        'total_papers': len(display_papers),
        'papers': display_papers
    }
    
    # ç¡®ä¿docsç›®å½•å­˜åœ¨
    os.makedirs('docs', exist_ok=True)
    
    # å†™å…¥æ–‡ä»¶
    output_file = 'docs/papers_display.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(display_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ‰ å±•ç¤ºæ•°æ®å·²ç”Ÿæˆ: {output_file}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - è®ºæ–‡æ€»æ•°: {display_data['total_papers']}")
    print(f"   - ç”Ÿæˆæ—¶é—´: {display_data['last_updated']}")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹è®ºæ–‡ä¿¡æ¯
    if display_papers:
        print(f"\nğŸ“„ ç¤ºä¾‹è®ºæ–‡:")
        for i, paper in enumerate(display_papers[:3]):
            print(f"   {i+1}. [{paper['arxiv_id']}] {paper['title'][:60]}...")

if __name__ == '__main__':
    generate_display_json()